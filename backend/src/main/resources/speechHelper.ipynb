{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXbkJSUMGVTZ",
    "outputId": "f569b734-60d9-4239-d507-39a5dc6940a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjdbDugARDG-",
    "outputId": "6c900f58-5895-474e-94ae-f27e07cfa6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.6)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.0.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RXe3XpTiRdhF"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "data, sampling_rate = librosa.load('/content/drive/My Drive/Audio_Speech_Actors_01-24/Actor_01/03-01-01-01-01-01-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "yKgWOlCPSIva",
    "outputId": "33974c6e-27c2-4f80-b45d-74afc7ad769d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['display']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7f7536369bd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "% pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gQ9OA8niz0t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jw4OX6iti0jK"
   },
   "source": [
    "Feature extraction using d tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUJetfVvSUWP",
    "outputId": "444c4cda-5e58-4404-8de5-276356db1474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data loaded. Loading time: 425.0565321445465 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#path = '/content/drive/My Drive/Audio_Speech_Actors_01-24/Actor_01/'\n",
    "#path = '/content/drive/My Drive/Speech/AudioFiles/Actor_01/'\n",
    "path = '/content/drive/My Drive/Speech/'\n",
    "lst = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "  for file in files:\n",
    "      try:\n",
    "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
    "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
    "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
    "        file = int(file[7:8]) - 1 \n",
    "        #print(file)\n",
    "        arr = mfccs, file\n",
    "        #print(arr)\n",
    "        lst.append(arr)\n",
    "        #print(lst)\n",
    "      # If the file is not valid, skip it\n",
    "      except ValueError:\n",
    "        continue\n",
    "\n",
    "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6oj8WiBs1W8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CuCEX7YASp-J"
   },
   "outputs": [],
   "source": [
    "\n",
    "X, y = zip(*lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlPNxlyFSuM5",
    "outputId": "9efde272-89bf-4f85-ce41-28e50939a4ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1440, 40), (1440,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kxOjz68jSyLh"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "X_name = 'X.joblib'\n",
    "y_name = 'y.joblib'\n",
    "save_dir = '/content/drive/My Drive/Model/'\n",
    "\n",
    "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
    "savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "or9NqPPUYyii"
   },
   "outputs": [],
   "source": [
    "X = joblib.load('/content/drive/My Drive/Model/X.joblib')\n",
    "y = joblib.load('/content/drive/My Drive/Model/y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "V-qX1qyJZdTa"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "af-3cJJuZhSn"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ASTEhcssZkY3",
    "outputId": "f7583d55-013c-4e67-b26a-9e61e0abbd45"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-804be5c9bba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                        random_state=None, splitter='best')\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'min_impurity_split'"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwgjI_R8aDuQ",
    "outputId": "d7fab2ec-16ad-4bcf-9c77-d0facc3d074a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='random')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keg-cezJaHLC"
   },
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9tYrhyD0RbU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "gqlD0hU2aKoa",
    "outputId": "886ed363-c015-44bd-a820-3c7a9b0361c4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a950aae27142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGtgxs6wi8GZ"
   },
   "source": [
    "Feature extraction using Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "g5A5SxxUaa_x"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PK1hp0CcaeC0"
   },
   "outputs": [],
   "source": [
    "# gini criterion\n",
    "rforest = RandomForestClassifier(criterion=\"entropy\", max_depth=10, max_features=\"log2\", \n",
    "                                 max_leaf_nodes = 100, min_samples_leaf = 3, min_samples_split = 10, \n",
    "                                 n_estimators= 22000, random_state= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHXOsXYhahVM",
    "outputId": "e9da415f-ec70-4035-f90a-1ba2e89fcd46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, max_features='log2',\n",
       "                       max_leaf_nodes=100, min_samples_leaf=3,\n",
       "                       min_samples_split=10, n_estimators=22000,\n",
       "                       random_state=40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1i23UgW-0Tx8"
   },
   "outputs": [],
   "source": [
    "predictions = rforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qO4exJ1bAQf",
    "outputId": "6ed41148-f66e-48c5-ee21-9f587b001839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.45      0.93      0.61        41\n",
      "           2       0.68      0.38      0.49        45\n",
      "           3       0.38      0.35      0.36        34\n",
      "           4       0.69      0.71      0.70        34\n",
      "           5       0.59      0.61      0.60        38\n",
      "           6       0.47      0.53      0.50        34\n",
      "           7       0.63      0.50      0.56        44\n",
      "\n",
      "    accuracy                           0.53       288\n",
      "   macro avg       0.49      0.50      0.48       288\n",
      "weighted avg       0.53      0.53      0.51       288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "lUnVCJ0Js2lM"
   },
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4BTRh40tBCa",
    "outputId": "144a9ff4-52e7-48a7-f4e8-3dff1d1cdb03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1152, 40, 1), (288, 40, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape, x_testcnn.shape\n",
    "#print(X_train.shape[1], X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZx9A2tltBqg",
    "outputId": "150b4142-c151-40cb-a5fc-7c7e5be25f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(40,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same', input_shape=(40,1)))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Conv1D(128, 5,padding='same', input_shape=(40,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.00005, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXfD9CFrucmq",
    "outputId": "2dc46dd0-2957-487f-f185-331f8e3e45b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 40, 128)           768       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 40, 128)           0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 40, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 5, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 5, 128)            82048     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 1, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 1, 128)            82048     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1, 128)            0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,896\n",
      "Trainable params: 165,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "s6Sft-xzukUV"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDJV0Ru6uoft",
    "outputId": "7b65f0bd-43c2-433c-e8d0-489ddda08e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5999 - accuracy: 0.7856 - val_loss: 1.2773 - val_accuracy: 0.5903\n",
      "Epoch 2/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5681 - accuracy: 0.7865 - val_loss: 1.2853 - val_accuracy: 0.5799\n",
      "Epoch 3/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5833 - accuracy: 0.7969 - val_loss: 1.3015 - val_accuracy: 0.5660\n",
      "Epoch 4/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5621 - accuracy: 0.8003 - val_loss: 1.2681 - val_accuracy: 0.6042\n",
      "Epoch 5/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5766 - accuracy: 0.7891 - val_loss: 1.2932 - val_accuracy: 0.5972\n",
      "Epoch 6/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5629 - accuracy: 0.8064 - val_loss: 1.3220 - val_accuracy: 0.5729\n",
      "Epoch 7/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5678 - accuracy: 0.7977 - val_loss: 1.3111 - val_accuracy: 0.5694\n",
      "Epoch 8/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5477 - accuracy: 0.8012 - val_loss: 1.2996 - val_accuracy: 0.5764\n",
      "Epoch 9/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5617 - accuracy: 0.8030 - val_loss: 1.2928 - val_accuracy: 0.5799\n",
      "Epoch 10/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5519 - accuracy: 0.7995 - val_loss: 1.2779 - val_accuracy: 0.5938\n",
      "Epoch 11/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5594 - accuracy: 0.8056 - val_loss: 1.2763 - val_accuracy: 0.6250\n",
      "Epoch 12/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5532 - accuracy: 0.8116 - val_loss: 1.3771 - val_accuracy: 0.5660\n",
      "Epoch 13/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5458 - accuracy: 0.7986 - val_loss: 1.2519 - val_accuracy: 0.5903\n",
      "Epoch 14/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5324 - accuracy: 0.8134 - val_loss: 1.3766 - val_accuracy: 0.5486\n",
      "Epoch 15/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5488 - accuracy: 0.7969 - val_loss: 1.2534 - val_accuracy: 0.6111\n",
      "Epoch 16/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5488 - accuracy: 0.8099 - val_loss: 1.3437 - val_accuracy: 0.5799\n",
      "Epoch 17/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5569 - accuracy: 0.7960 - val_loss: 1.2994 - val_accuracy: 0.6007\n",
      "Epoch 18/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5649 - accuracy: 0.7865 - val_loss: 1.2369 - val_accuracy: 0.5903\n",
      "Epoch 19/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5625 - accuracy: 0.7925 - val_loss: 1.3122 - val_accuracy: 0.5833\n",
      "Epoch 20/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5614 - accuracy: 0.7925 - val_loss: 1.2668 - val_accuracy: 0.6007\n",
      "Epoch 21/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5591 - accuracy: 0.8012 - val_loss: 1.2727 - val_accuracy: 0.5903\n",
      "Epoch 22/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5647 - accuracy: 0.8064 - val_loss: 1.2598 - val_accuracy: 0.5938\n",
      "Epoch 23/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5336 - accuracy: 0.7951 - val_loss: 1.2851 - val_accuracy: 0.5694\n",
      "Epoch 24/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5522 - accuracy: 0.7943 - val_loss: 1.3018 - val_accuracy: 0.5729\n",
      "Epoch 25/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5255 - accuracy: 0.8264 - val_loss: 1.3512 - val_accuracy: 0.5833\n",
      "Epoch 26/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5409 - accuracy: 0.8134 - val_loss: 1.2524 - val_accuracy: 0.6007\n",
      "Epoch 27/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5435 - accuracy: 0.7986 - val_loss: 1.3049 - val_accuracy: 0.5833\n",
      "Epoch 28/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5459 - accuracy: 0.8003 - val_loss: 1.3330 - val_accuracy: 0.5729\n",
      "Epoch 29/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5391 - accuracy: 0.8082 - val_loss: 1.3114 - val_accuracy: 0.5903\n",
      "Epoch 30/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5542 - accuracy: 0.8030 - val_loss: 1.2561 - val_accuracy: 0.5868\n",
      "Epoch 31/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5148 - accuracy: 0.8142 - val_loss: 1.2560 - val_accuracy: 0.5868\n",
      "Epoch 32/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5387 - accuracy: 0.8030 - val_loss: 1.3087 - val_accuracy: 0.5799\n",
      "Epoch 33/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5115 - accuracy: 0.8212 - val_loss: 1.3110 - val_accuracy: 0.5799\n",
      "Epoch 34/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5330 - accuracy: 0.8142 - val_loss: 1.2691 - val_accuracy: 0.5868\n",
      "Epoch 35/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5271 - accuracy: 0.8003 - val_loss: 1.3225 - val_accuracy: 0.5799\n",
      "Epoch 36/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5070 - accuracy: 0.8186 - val_loss: 1.2823 - val_accuracy: 0.5799\n",
      "Epoch 37/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5330 - accuracy: 0.8177 - val_loss: 1.2732 - val_accuracy: 0.6007\n",
      "Epoch 38/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5422 - accuracy: 0.7986 - val_loss: 1.2931 - val_accuracy: 0.5938\n",
      "Epoch 39/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5219 - accuracy: 0.8012 - val_loss: 1.3098 - val_accuracy: 0.6007\n",
      "Epoch 40/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5271 - accuracy: 0.8030 - val_loss: 1.2600 - val_accuracy: 0.6146\n",
      "Epoch 41/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5304 - accuracy: 0.8064 - val_loss: 1.3060 - val_accuracy: 0.5903\n",
      "Epoch 42/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5450 - accuracy: 0.7986 - val_loss: 1.3002 - val_accuracy: 0.5972\n",
      "Epoch 43/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5295 - accuracy: 0.7969 - val_loss: 1.2979 - val_accuracy: 0.6007\n",
      "Epoch 44/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5018 - accuracy: 0.8307 - val_loss: 1.3368 - val_accuracy: 0.5868\n",
      "Epoch 45/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5269 - accuracy: 0.8090 - val_loss: 1.3186 - val_accuracy: 0.5764\n",
      "Epoch 46/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5308 - accuracy: 0.7960 - val_loss: 1.2789 - val_accuracy: 0.6042\n",
      "Epoch 47/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5237 - accuracy: 0.8108 - val_loss: 1.2836 - val_accuracy: 0.5868\n",
      "Epoch 48/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5226 - accuracy: 0.8203 - val_loss: 1.3903 - val_accuracy: 0.5694\n",
      "Epoch 49/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5078 - accuracy: 0.8160 - val_loss: 1.2649 - val_accuracy: 0.5799\n",
      "Epoch 50/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5059 - accuracy: 0.8108 - val_loss: 1.3346 - val_accuracy: 0.5660\n",
      "Epoch 51/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5022 - accuracy: 0.8203 - val_loss: 1.3113 - val_accuracy: 0.5938\n",
      "Epoch 52/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5148 - accuracy: 0.8090 - val_loss: 1.2996 - val_accuracy: 0.6007\n",
      "Epoch 53/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5244 - accuracy: 0.8194 - val_loss: 1.3017 - val_accuracy: 0.6146\n",
      "Epoch 54/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5083 - accuracy: 0.8194 - val_loss: 1.3016 - val_accuracy: 0.6042\n",
      "Epoch 55/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5077 - accuracy: 0.8194 - val_loss: 1.2981 - val_accuracy: 0.6042\n",
      "Epoch 56/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5203 - accuracy: 0.8168 - val_loss: 1.3450 - val_accuracy: 0.5729\n",
      "Epoch 57/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4897 - accuracy: 0.8307 - val_loss: 1.2805 - val_accuracy: 0.5833\n",
      "Epoch 58/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5343 - accuracy: 0.8125 - val_loss: 1.2819 - val_accuracy: 0.5833\n",
      "Epoch 59/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5342 - accuracy: 0.8003 - val_loss: 1.3637 - val_accuracy: 0.5833\n",
      "Epoch 60/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4965 - accuracy: 0.8186 - val_loss: 1.2963 - val_accuracy: 0.5903\n",
      "Epoch 61/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4756 - accuracy: 0.8281 - val_loss: 1.3001 - val_accuracy: 0.5799\n",
      "Epoch 62/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4806 - accuracy: 0.8247 - val_loss: 1.2925 - val_accuracy: 0.6007\n",
      "Epoch 63/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5109 - accuracy: 0.8229 - val_loss: 1.3899 - val_accuracy: 0.5590\n",
      "Epoch 64/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5046 - accuracy: 0.8082 - val_loss: 1.3345 - val_accuracy: 0.5660\n",
      "Epoch 65/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5066 - accuracy: 0.8142 - val_loss: 1.3167 - val_accuracy: 0.5972\n",
      "Epoch 66/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4843 - accuracy: 0.8455 - val_loss: 1.3034 - val_accuracy: 0.5764\n",
      "Epoch 67/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4850 - accuracy: 0.8385 - val_loss: 1.2909 - val_accuracy: 0.5903\n",
      "Epoch 68/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4786 - accuracy: 0.8194 - val_loss: 1.3195 - val_accuracy: 0.5729\n",
      "Epoch 69/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5088 - accuracy: 0.8203 - val_loss: 1.2893 - val_accuracy: 0.6007\n",
      "Epoch 70/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.5124 - accuracy: 0.8151 - val_loss: 1.3346 - val_accuracy: 0.5660\n",
      "Epoch 71/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5014 - accuracy: 0.8203 - val_loss: 1.2814 - val_accuracy: 0.5799\n",
      "Epoch 72/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4994 - accuracy: 0.8229 - val_loss: 1.3281 - val_accuracy: 0.5833\n",
      "Epoch 73/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4881 - accuracy: 0.8299 - val_loss: 1.2769 - val_accuracy: 0.6007\n",
      "Epoch 74/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4793 - accuracy: 0.8307 - val_loss: 1.3445 - val_accuracy: 0.5903\n",
      "Epoch 75/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4915 - accuracy: 0.8177 - val_loss: 1.3034 - val_accuracy: 0.5938\n",
      "Epoch 76/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4815 - accuracy: 0.8377 - val_loss: 1.2831 - val_accuracy: 0.6111\n",
      "Epoch 77/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4820 - accuracy: 0.8151 - val_loss: 1.3254 - val_accuracy: 0.5833\n",
      "Epoch 78/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4855 - accuracy: 0.8342 - val_loss: 1.2957 - val_accuracy: 0.5903\n",
      "Epoch 79/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4933 - accuracy: 0.8108 - val_loss: 1.2661 - val_accuracy: 0.5938\n",
      "Epoch 80/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4696 - accuracy: 0.8325 - val_loss: 1.3075 - val_accuracy: 0.5833\n",
      "Epoch 81/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4811 - accuracy: 0.8351 - val_loss: 1.3074 - val_accuracy: 0.5833\n",
      "Epoch 82/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4879 - accuracy: 0.8377 - val_loss: 1.3294 - val_accuracy: 0.5938\n",
      "Epoch 83/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4982 - accuracy: 0.8125 - val_loss: 1.2877 - val_accuracy: 0.5868\n",
      "Epoch 84/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4783 - accuracy: 0.8342 - val_loss: 1.3125 - val_accuracy: 0.5833\n",
      "Epoch 85/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4928 - accuracy: 0.8238 - val_loss: 1.2680 - val_accuracy: 0.5903\n",
      "Epoch 86/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4795 - accuracy: 0.8255 - val_loss: 1.2764 - val_accuracy: 0.6042\n",
      "Epoch 87/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4953 - accuracy: 0.8247 - val_loss: 1.3615 - val_accuracy: 0.5764\n",
      "Epoch 88/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4476 - accuracy: 0.8403 - val_loss: 1.4122 - val_accuracy: 0.5486\n",
      "Epoch 89/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4733 - accuracy: 0.8316 - val_loss: 1.3061 - val_accuracy: 0.5868\n",
      "Epoch 90/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4350 - accuracy: 0.8455 - val_loss: 1.3051 - val_accuracy: 0.5938\n",
      "Epoch 91/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4697 - accuracy: 0.8351 - val_loss: 1.3887 - val_accuracy: 0.5903\n",
      "Epoch 92/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4505 - accuracy: 0.8385 - val_loss: 1.3583 - val_accuracy: 0.5868\n",
      "Epoch 93/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4757 - accuracy: 0.8108 - val_loss: 1.2706 - val_accuracy: 0.5799\n",
      "Epoch 94/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4643 - accuracy: 0.8411 - val_loss: 1.2936 - val_accuracy: 0.6007\n",
      "Epoch 95/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4484 - accuracy: 0.8472 - val_loss: 1.3884 - val_accuracy: 0.5799\n",
      "Epoch 96/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4722 - accuracy: 0.8359 - val_loss: 1.2807 - val_accuracy: 0.6076\n",
      "Epoch 97/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4599 - accuracy: 0.8394 - val_loss: 1.2966 - val_accuracy: 0.5903\n",
      "Epoch 98/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4436 - accuracy: 0.8490 - val_loss: 1.3133 - val_accuracy: 0.5833\n",
      "Epoch 99/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4524 - accuracy: 0.8420 - val_loss: 1.3874 - val_accuracy: 0.6042\n",
      "Epoch 100/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4587 - accuracy: 0.8464 - val_loss: 1.2996 - val_accuracy: 0.5799\n",
      "Epoch 101/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4524 - accuracy: 0.8351 - val_loss: 1.3670 - val_accuracy: 0.6007\n",
      "Epoch 102/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4600 - accuracy: 0.8307 - val_loss: 1.2880 - val_accuracy: 0.6007\n",
      "Epoch 103/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4459 - accuracy: 0.8368 - val_loss: 1.2857 - val_accuracy: 0.5903\n",
      "Epoch 104/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4657 - accuracy: 0.8377 - val_loss: 1.2984 - val_accuracy: 0.6146\n",
      "Epoch 105/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4474 - accuracy: 0.8351 - val_loss: 1.3071 - val_accuracy: 0.6007\n",
      "Epoch 106/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4630 - accuracy: 0.8429 - val_loss: 1.3437 - val_accuracy: 0.6007\n",
      "Epoch 107/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4359 - accuracy: 0.8516 - val_loss: 1.3216 - val_accuracy: 0.5729\n",
      "Epoch 108/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4583 - accuracy: 0.8377 - val_loss: 1.2815 - val_accuracy: 0.5938\n",
      "Epoch 109/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4620 - accuracy: 0.8368 - val_loss: 1.3003 - val_accuracy: 0.5972\n",
      "Epoch 110/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4545 - accuracy: 0.8377 - val_loss: 1.3756 - val_accuracy: 0.5938\n",
      "Epoch 111/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4492 - accuracy: 0.8264 - val_loss: 1.3472 - val_accuracy: 0.5868\n",
      "Epoch 112/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4622 - accuracy: 0.8455 - val_loss: 1.3426 - val_accuracy: 0.6076\n",
      "Epoch 113/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4299 - accuracy: 0.8516 - val_loss: 1.3595 - val_accuracy: 0.5799\n",
      "Epoch 114/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4427 - accuracy: 0.8516 - val_loss: 1.3400 - val_accuracy: 0.5972\n",
      "Epoch 115/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4562 - accuracy: 0.8394 - val_loss: 1.3001 - val_accuracy: 0.6007\n",
      "Epoch 116/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4382 - accuracy: 0.8359 - val_loss: 1.3277 - val_accuracy: 0.5868\n",
      "Epoch 117/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4246 - accuracy: 0.8498 - val_loss: 1.3499 - val_accuracy: 0.5833\n",
      "Epoch 118/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4317 - accuracy: 0.8307 - val_loss: 1.3473 - val_accuracy: 0.5972\n",
      "Epoch 119/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4112 - accuracy: 0.8490 - val_loss: 1.3339 - val_accuracy: 0.6215\n",
      "Epoch 120/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4467 - accuracy: 0.8385 - val_loss: 1.3245 - val_accuracy: 0.6007\n",
      "Epoch 121/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4096 - accuracy: 0.8542 - val_loss: 1.3546 - val_accuracy: 0.5938\n",
      "Epoch 122/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4354 - accuracy: 0.8472 - val_loss: 1.3466 - val_accuracy: 0.5972\n",
      "Epoch 123/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4204 - accuracy: 0.8481 - val_loss: 1.3667 - val_accuracy: 0.5868\n",
      "Epoch 124/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4446 - accuracy: 0.8403 - val_loss: 1.2972 - val_accuracy: 0.5938\n",
      "Epoch 125/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4169 - accuracy: 0.8498 - val_loss: 1.3062 - val_accuracy: 0.6181\n",
      "Epoch 126/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4364 - accuracy: 0.8411 - val_loss: 1.2943 - val_accuracy: 0.6111\n",
      "Epoch 127/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4418 - accuracy: 0.8446 - val_loss: 1.2825 - val_accuracy: 0.6042\n",
      "Epoch 128/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4412 - accuracy: 0.8368 - val_loss: 1.3504 - val_accuracy: 0.6181\n",
      "Epoch 129/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4095 - accuracy: 0.8429 - val_loss: 1.3896 - val_accuracy: 0.6042\n",
      "Epoch 130/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4202 - accuracy: 0.8490 - val_loss: 1.3367 - val_accuracy: 0.5764\n",
      "Epoch 131/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4197 - accuracy: 0.8585 - val_loss: 1.3499 - val_accuracy: 0.5938\n",
      "Epoch 132/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4015 - accuracy: 0.8655 - val_loss: 1.3350 - val_accuracy: 0.6146\n",
      "Epoch 133/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4270 - accuracy: 0.8490 - val_loss: 1.3356 - val_accuracy: 0.6111\n",
      "Epoch 134/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4350 - accuracy: 0.8472 - val_loss: 1.3420 - val_accuracy: 0.5799\n",
      "Epoch 135/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4255 - accuracy: 0.8559 - val_loss: 1.2998 - val_accuracy: 0.6111\n",
      "Epoch 136/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4236 - accuracy: 0.8568 - val_loss: 1.3420 - val_accuracy: 0.5972\n",
      "Epoch 137/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.4086 - accuracy: 0.8559 - val_loss: 1.3432 - val_accuracy: 0.6076\n",
      "Epoch 138/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4066 - accuracy: 0.8438 - val_loss: 1.3101 - val_accuracy: 0.6111\n",
      "Epoch 139/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4088 - accuracy: 0.8576 - val_loss: 1.3305 - val_accuracy: 0.5764\n",
      "Epoch 140/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4240 - accuracy: 0.8550 - val_loss: 1.3036 - val_accuracy: 0.6076\n",
      "Epoch 141/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4155 - accuracy: 0.8594 - val_loss: 1.3499 - val_accuracy: 0.5903\n",
      "Epoch 142/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4154 - accuracy: 0.8594 - val_loss: 1.3613 - val_accuracy: 0.5903\n",
      "Epoch 143/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4175 - accuracy: 0.8559 - val_loss: 1.3221 - val_accuracy: 0.6007\n",
      "Epoch 144/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4055 - accuracy: 0.8542 - val_loss: 1.3373 - val_accuracy: 0.6146\n",
      "Epoch 145/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4155 - accuracy: 0.8385 - val_loss: 1.2889 - val_accuracy: 0.6146\n",
      "Epoch 146/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4096 - accuracy: 0.8576 - val_loss: 1.3223 - val_accuracy: 0.5938\n",
      "Epoch 147/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3992 - accuracy: 0.8585 - val_loss: 1.3172 - val_accuracy: 0.6042\n",
      "Epoch 148/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4083 - accuracy: 0.8550 - val_loss: 1.4042 - val_accuracy: 0.6007\n",
      "Epoch 149/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4140 - accuracy: 0.8490 - val_loss: 1.3307 - val_accuracy: 0.6007\n",
      "Epoch 150/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.3956 - accuracy: 0.8715 - val_loss: 1.3198 - val_accuracy: 0.6007\n",
      "Epoch 151/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4025 - accuracy: 0.8594 - val_loss: 1.3851 - val_accuracy: 0.6007\n",
      "Epoch 152/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4238 - accuracy: 0.8368 - val_loss: 1.3459 - val_accuracy: 0.5903\n",
      "Epoch 153/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3911 - accuracy: 0.8620 - val_loss: 1.3506 - val_accuracy: 0.6007\n",
      "Epoch 154/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4107 - accuracy: 0.8464 - val_loss: 1.3153 - val_accuracy: 0.6111\n",
      "Epoch 155/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4032 - accuracy: 0.8576 - val_loss: 1.3458 - val_accuracy: 0.5938\n",
      "Epoch 156/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3845 - accuracy: 0.8637 - val_loss: 1.3103 - val_accuracy: 0.6042\n",
      "Epoch 157/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3822 - accuracy: 0.8646 - val_loss: 1.3724 - val_accuracy: 0.5938\n",
      "Epoch 158/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3802 - accuracy: 0.8637 - val_loss: 1.3742 - val_accuracy: 0.5903\n",
      "Epoch 159/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4010 - accuracy: 0.8576 - val_loss: 1.3911 - val_accuracy: 0.5556\n",
      "Epoch 160/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3868 - accuracy: 0.8663 - val_loss: 1.3195 - val_accuracy: 0.6076\n",
      "Epoch 161/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3862 - accuracy: 0.8663 - val_loss: 1.4757 - val_accuracy: 0.5868\n",
      "Epoch 162/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3846 - accuracy: 0.8602 - val_loss: 1.4251 - val_accuracy: 0.5938\n",
      "Epoch 163/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3901 - accuracy: 0.8620 - val_loss: 1.3990 - val_accuracy: 0.5764\n",
      "Epoch 164/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3878 - accuracy: 0.8585 - val_loss: 1.3102 - val_accuracy: 0.6076\n",
      "Epoch 165/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3603 - accuracy: 0.8811 - val_loss: 1.3587 - val_accuracy: 0.5972\n",
      "Epoch 166/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3932 - accuracy: 0.8672 - val_loss: 1.3201 - val_accuracy: 0.6042\n",
      "Epoch 167/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3862 - accuracy: 0.8611 - val_loss: 1.3684 - val_accuracy: 0.5799\n",
      "Epoch 168/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3834 - accuracy: 0.8750 - val_loss: 1.4043 - val_accuracy: 0.5903\n",
      "Epoch 169/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.3770 - accuracy: 0.8620 - val_loss: 1.3386 - val_accuracy: 0.6111\n",
      "Epoch 170/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3843 - accuracy: 0.8620 - val_loss: 1.3465 - val_accuracy: 0.5729\n",
      "Epoch 171/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.4120 - accuracy: 0.8507 - val_loss: 1.3282 - val_accuracy: 0.5903\n",
      "Epoch 172/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3771 - accuracy: 0.8715 - val_loss: 1.3586 - val_accuracy: 0.6076\n",
      "Epoch 173/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3798 - accuracy: 0.8663 - val_loss: 1.3669 - val_accuracy: 0.5972\n",
      "Epoch 174/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3717 - accuracy: 0.8707 - val_loss: 1.3806 - val_accuracy: 0.5764\n",
      "Epoch 175/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3925 - accuracy: 0.8481 - val_loss: 1.3775 - val_accuracy: 0.5868\n",
      "Epoch 176/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3601 - accuracy: 0.8724 - val_loss: 1.3136 - val_accuracy: 0.6111\n",
      "Epoch 177/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3612 - accuracy: 0.8819 - val_loss: 1.3577 - val_accuracy: 0.6007\n",
      "Epoch 178/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3698 - accuracy: 0.8741 - val_loss: 1.3777 - val_accuracy: 0.5868\n",
      "Epoch 179/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3790 - accuracy: 0.8715 - val_loss: 1.3627 - val_accuracy: 0.6007\n",
      "Epoch 180/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3693 - accuracy: 0.8750 - val_loss: 1.3505 - val_accuracy: 0.6007\n",
      "Epoch 181/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3736 - accuracy: 0.8707 - val_loss: 1.3590 - val_accuracy: 0.6146\n",
      "Epoch 182/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3631 - accuracy: 0.8663 - val_loss: 1.3537 - val_accuracy: 0.6007\n",
      "Epoch 183/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3625 - accuracy: 0.8733 - val_loss: 1.3922 - val_accuracy: 0.5868\n",
      "Epoch 184/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3735 - accuracy: 0.8655 - val_loss: 1.3503 - val_accuracy: 0.6111\n",
      "Epoch 185/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3619 - accuracy: 0.8750 - val_loss: 1.3162 - val_accuracy: 0.6042\n",
      "Epoch 186/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3787 - accuracy: 0.8715 - val_loss: 1.3104 - val_accuracy: 0.6042\n",
      "Epoch 187/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3768 - accuracy: 0.8724 - val_loss: 1.3798 - val_accuracy: 0.6215\n",
      "Epoch 188/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3619 - accuracy: 0.8741 - val_loss: 1.3626 - val_accuracy: 0.6250\n",
      "Epoch 189/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3800 - accuracy: 0.8689 - val_loss: 1.3180 - val_accuracy: 0.6111\n",
      "Epoch 190/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.3597 - accuracy: 0.8689 - val_loss: 1.3791 - val_accuracy: 0.5868\n",
      "Epoch 191/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3746 - accuracy: 0.8611 - val_loss: 1.4092 - val_accuracy: 0.5833\n",
      "Epoch 192/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3573 - accuracy: 0.8828 - val_loss: 1.4078 - val_accuracy: 0.6042\n",
      "Epoch 193/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3590 - accuracy: 0.8715 - val_loss: 1.3681 - val_accuracy: 0.5938\n",
      "Epoch 194/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3641 - accuracy: 0.8698 - val_loss: 1.3099 - val_accuracy: 0.6042\n",
      "Epoch 195/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3543 - accuracy: 0.8793 - val_loss: 1.3475 - val_accuracy: 0.6146\n",
      "Epoch 196/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3653 - accuracy: 0.8828 - val_loss: 1.4117 - val_accuracy: 0.5729\n",
      "Epoch 197/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3684 - accuracy: 0.8689 - val_loss: 1.3308 - val_accuracy: 0.5903\n",
      "Epoch 198/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3700 - accuracy: 0.8707 - val_loss: 1.4015 - val_accuracy: 0.6007\n",
      "Epoch 199/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3548 - accuracy: 0.8741 - val_loss: 1.3659 - val_accuracy: 0.6111\n",
      "Epoch 200/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3568 - accuracy: 0.8785 - val_loss: 1.4374 - val_accuracy: 0.5694\n",
      "Epoch 201/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3631 - accuracy: 0.8698 - val_loss: 1.3575 - val_accuracy: 0.6007\n",
      "Epoch 202/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3526 - accuracy: 0.8802 - val_loss: 1.3803 - val_accuracy: 0.5799\n",
      "Epoch 203/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3499 - accuracy: 0.8767 - val_loss: 1.3717 - val_accuracy: 0.5972\n",
      "Epoch 204/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3422 - accuracy: 0.8802 - val_loss: 1.3244 - val_accuracy: 0.6111\n",
      "Epoch 205/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.3622 - accuracy: 0.8637 - val_loss: 1.3700 - val_accuracy: 0.6042\n",
      "Epoch 206/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.3447 - accuracy: 0.8802 - val_loss: 1.3319 - val_accuracy: 0.6250\n",
      "Epoch 207/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3562 - accuracy: 0.8819 - val_loss: 1.3680 - val_accuracy: 0.6042\n",
      "Epoch 208/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3251 - accuracy: 0.8898 - val_loss: 1.3686 - val_accuracy: 0.6076\n",
      "Epoch 209/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3466 - accuracy: 0.8776 - val_loss: 1.3619 - val_accuracy: 0.5972\n",
      "Epoch 210/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3555 - accuracy: 0.8776 - val_loss: 1.3367 - val_accuracy: 0.6007\n",
      "Epoch 211/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3545 - accuracy: 0.8715 - val_loss: 1.3353 - val_accuracy: 0.5938\n",
      "Epoch 212/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3415 - accuracy: 0.8863 - val_loss: 1.3698 - val_accuracy: 0.6181\n",
      "Epoch 213/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.8802 - val_loss: 1.4220 - val_accuracy: 0.5938\n",
      "Epoch 214/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3332 - accuracy: 0.8854 - val_loss: 1.3684 - val_accuracy: 0.6042\n",
      "Epoch 215/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3530 - accuracy: 0.8715 - val_loss: 1.3584 - val_accuracy: 0.6042\n",
      "Epoch 216/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3453 - accuracy: 0.8811 - val_loss: 1.3815 - val_accuracy: 0.6042\n",
      "Epoch 217/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.3394 - accuracy: 0.8776 - val_loss: 1.3787 - val_accuracy: 0.6146\n",
      "Epoch 218/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3445 - accuracy: 0.8837 - val_loss: 1.3542 - val_accuracy: 0.6250\n",
      "Epoch 219/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3314 - accuracy: 0.8802 - val_loss: 1.3994 - val_accuracy: 0.5660\n",
      "Epoch 220/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3208 - accuracy: 0.8889 - val_loss: 1.3980 - val_accuracy: 0.5938\n",
      "Epoch 221/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3429 - accuracy: 0.8776 - val_loss: 1.4196 - val_accuracy: 0.5903\n",
      "Epoch 222/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.3367 - accuracy: 0.8802 - val_loss: 1.3783 - val_accuracy: 0.6146\n",
      "Epoch 223/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3259 - accuracy: 0.8741 - val_loss: 1.3399 - val_accuracy: 0.6111\n",
      "Epoch 224/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3287 - accuracy: 0.8845 - val_loss: 1.3805 - val_accuracy: 0.5972\n",
      "Epoch 225/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.3467 - accuracy: 0.8750 - val_loss: 1.3864 - val_accuracy: 0.6042\n",
      "Epoch 226/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3516 - accuracy: 0.8811 - val_loss: 1.3729 - val_accuracy: 0.6146\n",
      "Epoch 227/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.3329 - accuracy: 0.8819 - val_loss: 1.3671 - val_accuracy: 0.6181\n",
      "Epoch 228/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3329 - accuracy: 0.8828 - val_loss: 1.4384 - val_accuracy: 0.5903\n",
      "Epoch 229/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3220 - accuracy: 0.8863 - val_loss: 1.4550 - val_accuracy: 0.6111\n",
      "Epoch 230/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3510 - accuracy: 0.8741 - val_loss: 1.3992 - val_accuracy: 0.6007\n",
      "Epoch 231/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3304 - accuracy: 0.8932 - val_loss: 1.4679 - val_accuracy: 0.6042\n",
      "Epoch 232/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3233 - accuracy: 0.8819 - val_loss: 1.3859 - val_accuracy: 0.5868\n",
      "Epoch 233/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3466 - accuracy: 0.8681 - val_loss: 1.4265 - val_accuracy: 0.6111\n",
      "Epoch 234/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3378 - accuracy: 0.8750 - val_loss: 1.4360 - val_accuracy: 0.5903\n",
      "Epoch 235/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3293 - accuracy: 0.8854 - val_loss: 1.3607 - val_accuracy: 0.6076\n",
      "Epoch 236/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3268 - accuracy: 0.8802 - val_loss: 1.3698 - val_accuracy: 0.6042\n",
      "Epoch 237/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.3150 - accuracy: 0.8932 - val_loss: 1.3739 - val_accuracy: 0.5833\n",
      "Epoch 238/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3218 - accuracy: 0.8915 - val_loss: 1.4109 - val_accuracy: 0.5972\n",
      "Epoch 239/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3273 - accuracy: 0.8785 - val_loss: 1.4183 - val_accuracy: 0.5938\n",
      "Epoch 240/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3043 - accuracy: 0.8976 - val_loss: 1.3721 - val_accuracy: 0.5972\n",
      "Epoch 241/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3182 - accuracy: 0.8837 - val_loss: 1.4566 - val_accuracy: 0.5729\n",
      "Epoch 242/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3248 - accuracy: 0.8906 - val_loss: 1.3948 - val_accuracy: 0.5938\n",
      "Epoch 243/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3114 - accuracy: 0.8863 - val_loss: 1.3765 - val_accuracy: 0.6111\n",
      "Epoch 244/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3262 - accuracy: 0.8915 - val_loss: 1.3248 - val_accuracy: 0.6146\n",
      "Epoch 245/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3196 - accuracy: 0.8924 - val_loss: 1.3626 - val_accuracy: 0.6076\n",
      "Epoch 246/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3275 - accuracy: 0.8828 - val_loss: 1.4212 - val_accuracy: 0.5903\n",
      "Epoch 247/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3273 - accuracy: 0.8811 - val_loss: 1.3804 - val_accuracy: 0.6076\n",
      "Epoch 248/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.3231 - accuracy: 0.8880 - val_loss: 1.3783 - val_accuracy: 0.6146\n",
      "Epoch 249/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3255 - accuracy: 0.8854 - val_loss: 1.3455 - val_accuracy: 0.6042\n",
      "Epoch 250/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3422 - accuracy: 0.8828 - val_loss: 1.3894 - val_accuracy: 0.5833\n",
      "Epoch 251/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3104 - accuracy: 0.8984 - val_loss: 1.3398 - val_accuracy: 0.6007\n",
      "Epoch 252/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3451 - accuracy: 0.8750 - val_loss: 1.3531 - val_accuracy: 0.5868\n",
      "Epoch 253/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3181 - accuracy: 0.8941 - val_loss: 1.3888 - val_accuracy: 0.5799\n",
      "Epoch 254/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3205 - accuracy: 0.8863 - val_loss: 1.3536 - val_accuracy: 0.6250\n",
      "Epoch 255/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2976 - accuracy: 0.8932 - val_loss: 1.3783 - val_accuracy: 0.6111\n",
      "Epoch 256/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3089 - accuracy: 0.8932 - val_loss: 1.4278 - val_accuracy: 0.5938\n",
      "Epoch 257/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3013 - accuracy: 0.8924 - val_loss: 1.4013 - val_accuracy: 0.6111\n",
      "Epoch 258/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3094 - accuracy: 0.8950 - val_loss: 1.3500 - val_accuracy: 0.6042\n",
      "Epoch 259/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3216 - accuracy: 0.8872 - val_loss: 1.4384 - val_accuracy: 0.6042\n",
      "Epoch 260/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3337 - accuracy: 0.8793 - val_loss: 1.3983 - val_accuracy: 0.6250\n",
      "Epoch 261/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3048 - accuracy: 0.8958 - val_loss: 1.3327 - val_accuracy: 0.6007\n",
      "Epoch 262/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2925 - accuracy: 0.8950 - val_loss: 1.3954 - val_accuracy: 0.5868\n",
      "Epoch 263/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2928 - accuracy: 0.8941 - val_loss: 1.3796 - val_accuracy: 0.6007\n",
      "Epoch 264/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3282 - accuracy: 0.8854 - val_loss: 1.3756 - val_accuracy: 0.6181\n",
      "Epoch 265/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2999 - accuracy: 0.9028 - val_loss: 1.3388 - val_accuracy: 0.6285\n",
      "Epoch 266/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3056 - accuracy: 0.8906 - val_loss: 1.3730 - val_accuracy: 0.6250\n",
      "Epoch 267/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.3007 - accuracy: 0.8967 - val_loss: 1.4539 - val_accuracy: 0.5972\n",
      "Epoch 268/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2948 - accuracy: 0.9028 - val_loss: 1.3532 - val_accuracy: 0.6215\n",
      "Epoch 269/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3013 - accuracy: 0.8872 - val_loss: 1.4530 - val_accuracy: 0.6007\n",
      "Epoch 270/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3039 - accuracy: 0.9054 - val_loss: 1.4077 - val_accuracy: 0.6146\n",
      "Epoch 271/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3079 - accuracy: 0.8924 - val_loss: 1.3911 - val_accuracy: 0.6285\n",
      "Epoch 272/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3096 - accuracy: 0.8880 - val_loss: 1.4520 - val_accuracy: 0.6111\n",
      "Epoch 273/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2814 - accuracy: 0.8976 - val_loss: 1.4318 - val_accuracy: 0.5903\n",
      "Epoch 274/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2880 - accuracy: 0.9002 - val_loss: 1.5130 - val_accuracy: 0.5903\n",
      "Epoch 275/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2900 - accuracy: 0.8958 - val_loss: 1.4197 - val_accuracy: 0.5972\n",
      "Epoch 276/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3101 - accuracy: 0.8941 - val_loss: 1.4742 - val_accuracy: 0.6007\n",
      "Epoch 277/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2956 - accuracy: 0.8976 - val_loss: 1.4601 - val_accuracy: 0.5868\n",
      "Epoch 278/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.3000 - accuracy: 0.8941 - val_loss: 1.4206 - val_accuracy: 0.6181\n",
      "Epoch 279/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2975 - accuracy: 0.8950 - val_loss: 1.4013 - val_accuracy: 0.6007\n",
      "Epoch 280/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2866 - accuracy: 0.9123 - val_loss: 1.3911 - val_accuracy: 0.6250\n",
      "Epoch 281/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.3101 - accuracy: 0.8915 - val_loss: 1.4210 - val_accuracy: 0.5938\n",
      "Epoch 282/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2941 - accuracy: 0.9054 - val_loss: 1.4382 - val_accuracy: 0.6076\n",
      "Epoch 283/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2845 - accuracy: 0.9054 - val_loss: 1.4642 - val_accuracy: 0.6181\n",
      "Epoch 284/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2868 - accuracy: 0.9036 - val_loss: 1.4605 - val_accuracy: 0.6076\n",
      "Epoch 285/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2955 - accuracy: 0.9028 - val_loss: 1.4209 - val_accuracy: 0.6007\n",
      "Epoch 286/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3041 - accuracy: 0.8889 - val_loss: 1.4513 - val_accuracy: 0.6181\n",
      "Epoch 287/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2896 - accuracy: 0.9028 - val_loss: 1.4634 - val_accuracy: 0.6285\n",
      "Epoch 288/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3093 - accuracy: 0.8889 - val_loss: 1.3879 - val_accuracy: 0.6319\n",
      "Epoch 289/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2901 - accuracy: 0.9019 - val_loss: 1.4356 - val_accuracy: 0.5972\n",
      "Epoch 290/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2722 - accuracy: 0.9054 - val_loss: 1.4339 - val_accuracy: 0.6111\n",
      "Epoch 291/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2772 - accuracy: 0.9036 - val_loss: 1.4088 - val_accuracy: 0.6042\n",
      "Epoch 292/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2960 - accuracy: 0.8993 - val_loss: 1.4501 - val_accuracy: 0.5972\n",
      "Epoch 293/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2769 - accuracy: 0.9062 - val_loss: 1.4326 - val_accuracy: 0.5938\n",
      "Epoch 294/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2802 - accuracy: 0.9036 - val_loss: 1.4734 - val_accuracy: 0.5833\n",
      "Epoch 295/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.3051 - accuracy: 0.8932 - val_loss: 1.3874 - val_accuracy: 0.6146\n",
      "Epoch 296/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2783 - accuracy: 0.9045 - val_loss: 1.3723 - val_accuracy: 0.6285\n",
      "Epoch 297/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2859 - accuracy: 0.9019 - val_loss: 1.4312 - val_accuracy: 0.6042\n",
      "Epoch 298/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2875 - accuracy: 0.9097 - val_loss: 1.4566 - val_accuracy: 0.6146\n",
      "Epoch 299/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2764 - accuracy: 0.9071 - val_loss: 1.4444 - val_accuracy: 0.6111\n",
      "Epoch 300/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2849 - accuracy: 0.8984 - val_loss: 1.4641 - val_accuracy: 0.5799\n",
      "Epoch 301/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3190 - accuracy: 0.8837 - val_loss: 1.3924 - val_accuracy: 0.6181\n",
      "Epoch 302/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.3055 - accuracy: 0.8906 - val_loss: 1.3889 - val_accuracy: 0.6076\n",
      "Epoch 303/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2734 - accuracy: 0.9045 - val_loss: 1.3919 - val_accuracy: 0.6146\n",
      "Epoch 304/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2893 - accuracy: 0.8984 - val_loss: 1.4825 - val_accuracy: 0.5694\n",
      "Epoch 305/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2723 - accuracy: 0.9054 - val_loss: 1.4377 - val_accuracy: 0.5868\n",
      "Epoch 306/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2829 - accuracy: 0.9028 - val_loss: 1.4134 - val_accuracy: 0.6181\n",
      "Epoch 307/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2777 - accuracy: 0.9080 - val_loss: 1.3840 - val_accuracy: 0.6181\n",
      "Epoch 308/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2797 - accuracy: 0.9062 - val_loss: 1.4677 - val_accuracy: 0.6042\n",
      "Epoch 309/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2745 - accuracy: 0.9028 - val_loss: 1.3925 - val_accuracy: 0.6042\n",
      "Epoch 310/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2606 - accuracy: 0.9106 - val_loss: 1.5131 - val_accuracy: 0.5903\n",
      "Epoch 311/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2732 - accuracy: 0.9010 - val_loss: 1.4554 - val_accuracy: 0.6181\n",
      "Epoch 312/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2860 - accuracy: 0.9010 - val_loss: 1.4745 - val_accuracy: 0.5903\n",
      "Epoch 313/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2717 - accuracy: 0.9089 - val_loss: 1.3703 - val_accuracy: 0.6007\n",
      "Epoch 314/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2426 - accuracy: 0.9167 - val_loss: 1.4493 - val_accuracy: 0.5938\n",
      "Epoch 315/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2619 - accuracy: 0.9089 - val_loss: 1.4287 - val_accuracy: 0.6111\n",
      "Epoch 316/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2847 - accuracy: 0.9002 - val_loss: 1.4259 - val_accuracy: 0.5868\n",
      "Epoch 317/1300\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.2844 - accuracy: 0.8915 - val_loss: 1.4532 - val_accuracy: 0.6111\n",
      "Epoch 318/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2652 - accuracy: 0.9167 - val_loss: 1.4406 - val_accuracy: 0.5868\n",
      "Epoch 319/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2825 - accuracy: 0.9036 - val_loss: 1.4215 - val_accuracy: 0.6042\n",
      "Epoch 320/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2607 - accuracy: 0.9036 - val_loss: 1.3949 - val_accuracy: 0.6250\n",
      "Epoch 321/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2845 - accuracy: 0.8958 - val_loss: 1.4435 - val_accuracy: 0.6076\n",
      "Epoch 322/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2674 - accuracy: 0.9097 - val_loss: 1.5477 - val_accuracy: 0.6146\n",
      "Epoch 323/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2579 - accuracy: 0.9054 - val_loss: 1.4295 - val_accuracy: 0.6181\n",
      "Epoch 324/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2731 - accuracy: 0.9141 - val_loss: 1.4159 - val_accuracy: 0.6076\n",
      "Epoch 325/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2630 - accuracy: 0.8993 - val_loss: 1.4253 - val_accuracy: 0.5903\n",
      "Epoch 326/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2589 - accuracy: 0.9123 - val_loss: 1.5145 - val_accuracy: 0.6076\n",
      "Epoch 327/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2858 - accuracy: 0.8976 - val_loss: 1.4457 - val_accuracy: 0.5799\n",
      "Epoch 328/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2646 - accuracy: 0.9062 - val_loss: 1.4246 - val_accuracy: 0.6076\n",
      "Epoch 329/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2782 - accuracy: 0.9036 - val_loss: 1.4136 - val_accuracy: 0.6042\n",
      "Epoch 330/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2809 - accuracy: 0.9019 - val_loss: 1.4573 - val_accuracy: 0.6285\n",
      "Epoch 331/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2780 - accuracy: 0.9036 - val_loss: 1.4158 - val_accuracy: 0.5938\n",
      "Epoch 332/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2663 - accuracy: 0.9054 - val_loss: 1.4428 - val_accuracy: 0.6076\n",
      "Epoch 333/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2541 - accuracy: 0.9054 - val_loss: 1.4253 - val_accuracy: 0.6250\n",
      "Epoch 334/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2288 - accuracy: 0.9227 - val_loss: 1.4972 - val_accuracy: 0.5938\n",
      "Epoch 335/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2836 - accuracy: 0.9002 - val_loss: 1.4539 - val_accuracy: 0.6076\n",
      "Epoch 336/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2594 - accuracy: 0.9106 - val_loss: 1.4359 - val_accuracy: 0.6042\n",
      "Epoch 337/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2585 - accuracy: 0.9236 - val_loss: 1.4992 - val_accuracy: 0.5972\n",
      "Epoch 338/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2759 - accuracy: 0.9123 - val_loss: 1.5818 - val_accuracy: 0.6007\n",
      "Epoch 339/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2437 - accuracy: 0.9193 - val_loss: 1.4901 - val_accuracy: 0.6042\n",
      "Epoch 340/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2904 - accuracy: 0.9002 - val_loss: 1.4067 - val_accuracy: 0.6111\n",
      "Epoch 341/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2609 - accuracy: 0.9089 - val_loss: 1.4687 - val_accuracy: 0.6146\n",
      "Epoch 342/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2539 - accuracy: 0.9106 - val_loss: 1.5093 - val_accuracy: 0.5972\n",
      "Epoch 343/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2489 - accuracy: 0.9132 - val_loss: 1.4582 - val_accuracy: 0.5938\n",
      "Epoch 344/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2662 - accuracy: 0.9089 - val_loss: 1.4575 - val_accuracy: 0.6215\n",
      "Epoch 345/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2417 - accuracy: 0.9141 - val_loss: 1.3751 - val_accuracy: 0.6181\n",
      "Epoch 346/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2690 - accuracy: 0.9149 - val_loss: 1.4224 - val_accuracy: 0.6146\n",
      "Epoch 347/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2471 - accuracy: 0.9141 - val_loss: 1.3996 - val_accuracy: 0.5868\n",
      "Epoch 348/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2554 - accuracy: 0.9097 - val_loss: 1.3734 - val_accuracy: 0.6076\n",
      "Epoch 349/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2346 - accuracy: 0.9175 - val_loss: 1.4368 - val_accuracy: 0.6111\n",
      "Epoch 350/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2653 - accuracy: 0.9097 - val_loss: 1.4152 - val_accuracy: 0.6319\n",
      "Epoch 351/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2578 - accuracy: 0.8993 - val_loss: 1.4764 - val_accuracy: 0.5972\n",
      "Epoch 352/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2450 - accuracy: 0.9201 - val_loss: 1.5068 - val_accuracy: 0.5903\n",
      "Epoch 353/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2549 - accuracy: 0.9062 - val_loss: 1.4974 - val_accuracy: 0.6007\n",
      "Epoch 354/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2602 - accuracy: 0.9158 - val_loss: 1.4763 - val_accuracy: 0.5938\n",
      "Epoch 355/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2632 - accuracy: 0.9115 - val_loss: 1.4244 - val_accuracy: 0.6111\n",
      "Epoch 356/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2231 - accuracy: 0.9297 - val_loss: 1.4725 - val_accuracy: 0.6146\n",
      "Epoch 357/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2487 - accuracy: 0.9054 - val_loss: 1.5145 - val_accuracy: 0.6146\n",
      "Epoch 358/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2430 - accuracy: 0.9106 - val_loss: 1.4609 - val_accuracy: 0.6146\n",
      "Epoch 359/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2325 - accuracy: 0.9219 - val_loss: 1.4977 - val_accuracy: 0.5903\n",
      "Epoch 360/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2421 - accuracy: 0.9115 - val_loss: 1.4226 - val_accuracy: 0.6181\n",
      "Epoch 361/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2395 - accuracy: 0.9141 - val_loss: 1.4045 - val_accuracy: 0.6215\n",
      "Epoch 362/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2462 - accuracy: 0.9184 - val_loss: 1.4486 - val_accuracy: 0.5833\n",
      "Epoch 363/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2533 - accuracy: 0.9149 - val_loss: 1.4077 - val_accuracy: 0.6215\n",
      "Epoch 364/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2342 - accuracy: 0.9280 - val_loss: 1.4752 - val_accuracy: 0.5972\n",
      "Epoch 365/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2445 - accuracy: 0.9201 - val_loss: 1.4512 - val_accuracy: 0.5903\n",
      "Epoch 366/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2369 - accuracy: 0.9253 - val_loss: 1.4213 - val_accuracy: 0.6076\n",
      "Epoch 367/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2652 - accuracy: 0.9158 - val_loss: 1.4260 - val_accuracy: 0.6215\n",
      "Epoch 368/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2386 - accuracy: 0.9219 - val_loss: 1.5131 - val_accuracy: 0.6181\n",
      "Epoch 369/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2369 - accuracy: 0.9201 - val_loss: 1.4883 - val_accuracy: 0.6181\n",
      "Epoch 370/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2458 - accuracy: 0.9132 - val_loss: 1.4380 - val_accuracy: 0.6181\n",
      "Epoch 371/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2379 - accuracy: 0.9158 - val_loss: 1.4928 - val_accuracy: 0.5938\n",
      "Epoch 372/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2323 - accuracy: 0.9227 - val_loss: 1.5099 - val_accuracy: 0.6111\n",
      "Epoch 373/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2439 - accuracy: 0.9184 - val_loss: 1.4665 - val_accuracy: 0.6076\n",
      "Epoch 374/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2338 - accuracy: 0.9280 - val_loss: 1.4364 - val_accuracy: 0.6181\n",
      "Epoch 375/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2386 - accuracy: 0.9097 - val_loss: 1.5743 - val_accuracy: 0.5938\n",
      "Epoch 376/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2468 - accuracy: 0.9184 - val_loss: 1.4849 - val_accuracy: 0.6146\n",
      "Epoch 377/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2388 - accuracy: 0.9219 - val_loss: 1.5306 - val_accuracy: 0.6007\n",
      "Epoch 378/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2256 - accuracy: 0.9219 - val_loss: 1.4947 - val_accuracy: 0.5903\n",
      "Epoch 379/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2336 - accuracy: 0.9167 - val_loss: 1.4179 - val_accuracy: 0.6181\n",
      "Epoch 380/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2320 - accuracy: 0.9175 - val_loss: 1.5089 - val_accuracy: 0.6111\n",
      "Epoch 381/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2212 - accuracy: 0.9253 - val_loss: 1.4294 - val_accuracy: 0.6007\n",
      "Epoch 382/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2419 - accuracy: 0.9175 - val_loss: 1.4090 - val_accuracy: 0.6181\n",
      "Epoch 383/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2179 - accuracy: 0.9245 - val_loss: 1.4738 - val_accuracy: 0.6181\n",
      "Epoch 384/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2491 - accuracy: 0.9149 - val_loss: 1.4579 - val_accuracy: 0.6076\n",
      "Epoch 385/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2275 - accuracy: 0.9227 - val_loss: 1.4544 - val_accuracy: 0.6285\n",
      "Epoch 386/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2098 - accuracy: 0.9358 - val_loss: 1.4796 - val_accuracy: 0.6146\n",
      "Epoch 387/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2108 - accuracy: 0.9288 - val_loss: 1.4724 - val_accuracy: 0.6007\n",
      "Epoch 388/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2238 - accuracy: 0.9219 - val_loss: 1.3874 - val_accuracy: 0.6285\n",
      "Epoch 389/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2334 - accuracy: 0.9184 - val_loss: 1.5276 - val_accuracy: 0.6146\n",
      "Epoch 390/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2215 - accuracy: 0.9314 - val_loss: 1.4400 - val_accuracy: 0.5868\n",
      "Epoch 391/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2350 - accuracy: 0.9201 - val_loss: 1.4431 - val_accuracy: 0.6111\n",
      "Epoch 392/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2362 - accuracy: 0.9141 - val_loss: 1.3892 - val_accuracy: 0.6458\n",
      "Epoch 393/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2410 - accuracy: 0.9167 - val_loss: 1.5053 - val_accuracy: 0.6042\n",
      "Epoch 394/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2348 - accuracy: 0.9193 - val_loss: 1.4869 - val_accuracy: 0.6215\n",
      "Epoch 395/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1973 - accuracy: 0.9418 - val_loss: 1.4966 - val_accuracy: 0.6007\n",
      "Epoch 396/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2438 - accuracy: 0.9184 - val_loss: 1.5045 - val_accuracy: 0.6181\n",
      "Epoch 397/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2072 - accuracy: 0.9314 - val_loss: 1.5116 - val_accuracy: 0.6146\n",
      "Epoch 398/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2411 - accuracy: 0.9167 - val_loss: 1.4567 - val_accuracy: 0.6285\n",
      "Epoch 399/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2472 - accuracy: 0.9097 - val_loss: 1.4362 - val_accuracy: 0.6250\n",
      "Epoch 400/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2233 - accuracy: 0.9245 - val_loss: 1.4816 - val_accuracy: 0.6146\n",
      "Epoch 401/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2263 - accuracy: 0.9193 - val_loss: 1.4907 - val_accuracy: 0.6007\n",
      "Epoch 402/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2211 - accuracy: 0.9253 - val_loss: 1.5650 - val_accuracy: 0.5938\n",
      "Epoch 403/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2293 - accuracy: 0.9175 - val_loss: 1.5108 - val_accuracy: 0.6111\n",
      "Epoch 404/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2022 - accuracy: 0.9410 - val_loss: 1.4543 - val_accuracy: 0.6111\n",
      "Epoch 405/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2281 - accuracy: 0.9314 - val_loss: 1.5023 - val_accuracy: 0.6042\n",
      "Epoch 406/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2288 - accuracy: 0.9167 - val_loss: 1.5079 - val_accuracy: 0.6146\n",
      "Epoch 407/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2136 - accuracy: 0.9184 - val_loss: 1.5188 - val_accuracy: 0.5972\n",
      "Epoch 408/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2162 - accuracy: 0.9280 - val_loss: 1.4218 - val_accuracy: 0.6285\n",
      "Epoch 409/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2294 - accuracy: 0.9158 - val_loss: 1.4435 - val_accuracy: 0.6111\n",
      "Epoch 410/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2314 - accuracy: 0.9184 - val_loss: 1.5263 - val_accuracy: 0.6146\n",
      "Epoch 411/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2186 - accuracy: 0.9184 - val_loss: 1.5052 - val_accuracy: 0.6007\n",
      "Epoch 412/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2171 - accuracy: 0.9253 - val_loss: 1.4975 - val_accuracy: 0.5938\n",
      "Epoch 413/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2019 - accuracy: 0.9332 - val_loss: 1.4996 - val_accuracy: 0.6250\n",
      "Epoch 414/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2236 - accuracy: 0.9227 - val_loss: 1.4701 - val_accuracy: 0.6285\n",
      "Epoch 415/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2206 - accuracy: 0.9210 - val_loss: 1.4727 - val_accuracy: 0.6354\n",
      "Epoch 416/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1971 - accuracy: 0.9384 - val_loss: 1.4600 - val_accuracy: 0.6215\n",
      "Epoch 417/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2183 - accuracy: 0.9210 - val_loss: 1.4814 - val_accuracy: 0.6285\n",
      "Epoch 418/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2167 - accuracy: 0.9340 - val_loss: 1.5725 - val_accuracy: 0.6146\n",
      "Epoch 419/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2180 - accuracy: 0.9314 - val_loss: 1.5350 - val_accuracy: 0.6076\n",
      "Epoch 420/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2253 - accuracy: 0.9306 - val_loss: 1.4748 - val_accuracy: 0.6076\n",
      "Epoch 421/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2190 - accuracy: 0.9262 - val_loss: 1.4239 - val_accuracy: 0.6181\n",
      "Epoch 422/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2042 - accuracy: 0.9297 - val_loss: 1.5129 - val_accuracy: 0.5972\n",
      "Epoch 423/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.9227 - val_loss: 1.4912 - val_accuracy: 0.6319\n",
      "Epoch 424/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2071 - accuracy: 0.9288 - val_loss: 1.4418 - val_accuracy: 0.6250\n",
      "Epoch 425/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1941 - accuracy: 0.9375 - val_loss: 1.4110 - val_accuracy: 0.6493\n",
      "Epoch 426/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2051 - accuracy: 0.9245 - val_loss: 1.5045 - val_accuracy: 0.6076\n",
      "Epoch 427/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2161 - accuracy: 0.9262 - val_loss: 1.5029 - val_accuracy: 0.6146\n",
      "Epoch 428/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2242 - accuracy: 0.9227 - val_loss: 1.5395 - val_accuracy: 0.6146\n",
      "Epoch 429/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2057 - accuracy: 0.9366 - val_loss: 1.4751 - val_accuracy: 0.6215\n",
      "Epoch 430/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2084 - accuracy: 0.9280 - val_loss: 1.4987 - val_accuracy: 0.6042\n",
      "Epoch 431/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2115 - accuracy: 0.9262 - val_loss: 1.4349 - val_accuracy: 0.6250\n",
      "Epoch 432/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2046 - accuracy: 0.9323 - val_loss: 1.4480 - val_accuracy: 0.6007\n",
      "Epoch 433/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1987 - accuracy: 0.9349 - val_loss: 1.5242 - val_accuracy: 0.6215\n",
      "Epoch 434/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2209 - accuracy: 0.9201 - val_loss: 1.5566 - val_accuracy: 0.6111\n",
      "Epoch 435/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2174 - accuracy: 0.9219 - val_loss: 1.4983 - val_accuracy: 0.6042\n",
      "Epoch 436/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2041 - accuracy: 0.9280 - val_loss: 1.5487 - val_accuracy: 0.6181\n",
      "Epoch 437/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2184 - accuracy: 0.9288 - val_loss: 1.5359 - val_accuracy: 0.6042\n",
      "Epoch 438/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2153 - accuracy: 0.9340 - val_loss: 1.5183 - val_accuracy: 0.6250\n",
      "Epoch 439/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1973 - accuracy: 0.9306 - val_loss: 1.4306 - val_accuracy: 0.5938\n",
      "Epoch 440/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2107 - accuracy: 0.9262 - val_loss: 1.5091 - val_accuracy: 0.6181\n",
      "Epoch 441/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2096 - accuracy: 0.9358 - val_loss: 1.4656 - val_accuracy: 0.6319\n",
      "Epoch 442/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2097 - accuracy: 0.9297 - val_loss: 1.5843 - val_accuracy: 0.6111\n",
      "Epoch 443/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2017 - accuracy: 0.9314 - val_loss: 1.4671 - val_accuracy: 0.6354\n",
      "Epoch 444/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1837 - accuracy: 0.9410 - val_loss: 1.5235 - val_accuracy: 0.6076\n",
      "Epoch 445/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1781 - accuracy: 0.9410 - val_loss: 1.5986 - val_accuracy: 0.6111\n",
      "Epoch 446/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1920 - accuracy: 0.9375 - val_loss: 1.5715 - val_accuracy: 0.6319\n",
      "Epoch 447/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1940 - accuracy: 0.9236 - val_loss: 1.5329 - val_accuracy: 0.6007\n",
      "Epoch 448/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1990 - accuracy: 0.9366 - val_loss: 1.5380 - val_accuracy: 0.6215\n",
      "Epoch 449/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1979 - accuracy: 0.9375 - val_loss: 1.5479 - val_accuracy: 0.6215\n",
      "Epoch 450/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2023 - accuracy: 0.9375 - val_loss: 1.5248 - val_accuracy: 0.6146\n",
      "Epoch 451/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1952 - accuracy: 0.9306 - val_loss: 1.5112 - val_accuracy: 0.6146\n",
      "Epoch 452/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1877 - accuracy: 0.9392 - val_loss: 1.4901 - val_accuracy: 0.6354\n",
      "Epoch 453/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.2035 - accuracy: 0.9236 - val_loss: 1.5154 - val_accuracy: 0.6146\n",
      "Epoch 454/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1840 - accuracy: 0.9453 - val_loss: 1.5183 - val_accuracy: 0.6007\n",
      "Epoch 455/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1990 - accuracy: 0.9375 - val_loss: 1.4691 - val_accuracy: 0.6319\n",
      "Epoch 456/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1915 - accuracy: 0.9384 - val_loss: 1.4880 - val_accuracy: 0.6042\n",
      "Epoch 457/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1976 - accuracy: 0.9236 - val_loss: 1.5257 - val_accuracy: 0.6146\n",
      "Epoch 458/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2010 - accuracy: 0.9314 - val_loss: 1.4675 - val_accuracy: 0.6285\n",
      "Epoch 459/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1946 - accuracy: 0.9401 - val_loss: 1.5907 - val_accuracy: 0.6007\n",
      "Epoch 460/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1966 - accuracy: 0.9340 - val_loss: 1.5238 - val_accuracy: 0.6076\n",
      "Epoch 461/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2025 - accuracy: 0.9297 - val_loss: 1.5270 - val_accuracy: 0.5903\n",
      "Epoch 462/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1986 - accuracy: 0.9306 - val_loss: 1.4887 - val_accuracy: 0.6181\n",
      "Epoch 463/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1911 - accuracy: 0.9366 - val_loss: 1.5014 - val_accuracy: 0.6181\n",
      "Epoch 464/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2091 - accuracy: 0.9253 - val_loss: 1.5180 - val_accuracy: 0.6076\n",
      "Epoch 465/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1932 - accuracy: 0.9358 - val_loss: 1.5152 - val_accuracy: 0.6076\n",
      "Epoch 466/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1928 - accuracy: 0.9314 - val_loss: 1.5888 - val_accuracy: 0.6319\n",
      "Epoch 467/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1812 - accuracy: 0.9410 - val_loss: 1.5125 - val_accuracy: 0.6042\n",
      "Epoch 468/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1781 - accuracy: 0.9418 - val_loss: 1.5070 - val_accuracy: 0.6111\n",
      "Epoch 469/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2102 - accuracy: 0.9236 - val_loss: 1.5778 - val_accuracy: 0.6181\n",
      "Epoch 470/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2264 - accuracy: 0.9184 - val_loss: 1.5740 - val_accuracy: 0.6042\n",
      "Epoch 471/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1941 - accuracy: 0.9384 - val_loss: 1.5115 - val_accuracy: 0.6042\n",
      "Epoch 472/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1840 - accuracy: 0.9349 - val_loss: 1.4423 - val_accuracy: 0.6319\n",
      "Epoch 473/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1849 - accuracy: 0.9384 - val_loss: 1.4970 - val_accuracy: 0.6250\n",
      "Epoch 474/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1816 - accuracy: 0.9366 - val_loss: 1.5900 - val_accuracy: 0.5903\n",
      "Epoch 475/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1889 - accuracy: 0.9280 - val_loss: 1.5897 - val_accuracy: 0.5868\n",
      "Epoch 476/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1988 - accuracy: 0.9332 - val_loss: 1.5693 - val_accuracy: 0.6076\n",
      "Epoch 477/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1836 - accuracy: 0.9427 - val_loss: 1.4401 - val_accuracy: 0.6146\n",
      "Epoch 478/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1781 - accuracy: 0.9418 - val_loss: 1.4051 - val_accuracy: 0.6458\n",
      "Epoch 479/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1866 - accuracy: 0.9340 - val_loss: 1.4735 - val_accuracy: 0.6389\n",
      "Epoch 480/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1825 - accuracy: 0.9332 - val_loss: 1.4925 - val_accuracy: 0.6042\n",
      "Epoch 481/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2118 - accuracy: 0.9262 - val_loss: 1.5375 - val_accuracy: 0.6111\n",
      "Epoch 482/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1698 - accuracy: 0.9436 - val_loss: 1.4796 - val_accuracy: 0.6076\n",
      "Epoch 483/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1680 - accuracy: 0.9401 - val_loss: 1.5153 - val_accuracy: 0.6181\n",
      "Epoch 484/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1793 - accuracy: 0.9358 - val_loss: 1.5069 - val_accuracy: 0.6042\n",
      "Epoch 485/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1741 - accuracy: 0.9418 - val_loss: 1.4764 - val_accuracy: 0.6250\n",
      "Epoch 486/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.2018 - accuracy: 0.9262 - val_loss: 1.4764 - val_accuracy: 0.6181\n",
      "Epoch 487/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1875 - accuracy: 0.9332 - val_loss: 1.4941 - val_accuracy: 0.6285\n",
      "Epoch 488/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1779 - accuracy: 0.9332 - val_loss: 1.4958 - val_accuracy: 0.6285\n",
      "Epoch 489/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1878 - accuracy: 0.9340 - val_loss: 1.6880 - val_accuracy: 0.5868\n",
      "Epoch 490/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1787 - accuracy: 0.9349 - val_loss: 1.5102 - val_accuracy: 0.6181\n",
      "Epoch 491/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1901 - accuracy: 0.9392 - val_loss: 1.5476 - val_accuracy: 0.6285\n",
      "Epoch 492/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1768 - accuracy: 0.9427 - val_loss: 1.5596 - val_accuracy: 0.6146\n",
      "Epoch 493/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1971 - accuracy: 0.9288 - val_loss: 1.4850 - val_accuracy: 0.6111\n",
      "Epoch 494/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1855 - accuracy: 0.9358 - val_loss: 1.5941 - val_accuracy: 0.6076\n",
      "Epoch 495/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1825 - accuracy: 0.9358 - val_loss: 1.4988 - val_accuracy: 0.6285\n",
      "Epoch 496/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1956 - accuracy: 0.9332 - val_loss: 1.6325 - val_accuracy: 0.5972\n",
      "Epoch 497/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1702 - accuracy: 0.9436 - val_loss: 1.5979 - val_accuracy: 0.6111\n",
      "Epoch 498/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1755 - accuracy: 0.9349 - val_loss: 1.5332 - val_accuracy: 0.5972\n",
      "Epoch 499/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1647 - accuracy: 0.9444 - val_loss: 1.5129 - val_accuracy: 0.6354\n",
      "Epoch 500/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1803 - accuracy: 0.9366 - val_loss: 1.5280 - val_accuracy: 0.6181\n",
      "Epoch 501/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1679 - accuracy: 0.9436 - val_loss: 1.4956 - val_accuracy: 0.6285\n",
      "Epoch 502/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1797 - accuracy: 0.9410 - val_loss: 1.5353 - val_accuracy: 0.6215\n",
      "Epoch 503/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1920 - accuracy: 0.9297 - val_loss: 1.5367 - val_accuracy: 0.6146\n",
      "Epoch 504/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1867 - accuracy: 0.9410 - val_loss: 1.6367 - val_accuracy: 0.6076\n",
      "Epoch 505/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1676 - accuracy: 0.9453 - val_loss: 1.5906 - val_accuracy: 0.6215\n",
      "Epoch 506/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1725 - accuracy: 0.9479 - val_loss: 1.5060 - val_accuracy: 0.6389\n",
      "Epoch 507/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1616 - accuracy: 0.9418 - val_loss: 1.5929 - val_accuracy: 0.6250\n",
      "Epoch 508/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1706 - accuracy: 0.9462 - val_loss: 1.5819 - val_accuracy: 0.6215\n",
      "Epoch 509/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1593 - accuracy: 0.9462 - val_loss: 1.5842 - val_accuracy: 0.6181\n",
      "Epoch 510/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1734 - accuracy: 0.9323 - val_loss: 1.6606 - val_accuracy: 0.5903\n",
      "Epoch 511/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1707 - accuracy: 0.9436 - val_loss: 1.5724 - val_accuracy: 0.6146\n",
      "Epoch 512/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1733 - accuracy: 0.9384 - val_loss: 1.4980 - val_accuracy: 0.6215\n",
      "Epoch 513/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1877 - accuracy: 0.9323 - val_loss: 1.5207 - val_accuracy: 0.6111\n",
      "Epoch 514/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1814 - accuracy: 0.9392 - val_loss: 1.4630 - val_accuracy: 0.6319\n",
      "Epoch 515/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1547 - accuracy: 0.9557 - val_loss: 1.6235 - val_accuracy: 0.6076\n",
      "Epoch 516/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1753 - accuracy: 0.9392 - val_loss: 1.5377 - val_accuracy: 0.6111\n",
      "Epoch 517/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1655 - accuracy: 0.9505 - val_loss: 1.6787 - val_accuracy: 0.6181\n",
      "Epoch 518/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1640 - accuracy: 0.9470 - val_loss: 1.6078 - val_accuracy: 0.6007\n",
      "Epoch 519/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1813 - accuracy: 0.9427 - val_loss: 1.6281 - val_accuracy: 0.5868\n",
      "Epoch 520/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1717 - accuracy: 0.9384 - val_loss: 1.4975 - val_accuracy: 0.6250\n",
      "Epoch 521/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1740 - accuracy: 0.9427 - val_loss: 1.5828 - val_accuracy: 0.5903\n",
      "Epoch 522/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1747 - accuracy: 0.9418 - val_loss: 1.5112 - val_accuracy: 0.6354\n",
      "Epoch 523/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1803 - accuracy: 0.9401 - val_loss: 1.6561 - val_accuracy: 0.5972\n",
      "Epoch 524/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1564 - accuracy: 0.9497 - val_loss: 1.5555 - val_accuracy: 0.6076\n",
      "Epoch 525/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1796 - accuracy: 0.9358 - val_loss: 1.6273 - val_accuracy: 0.6319\n",
      "Epoch 526/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1845 - accuracy: 0.9375 - val_loss: 1.4893 - val_accuracy: 0.6250\n",
      "Epoch 527/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1626 - accuracy: 0.9470 - val_loss: 1.5787 - val_accuracy: 0.6215\n",
      "Epoch 528/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1612 - accuracy: 0.9523 - val_loss: 1.4923 - val_accuracy: 0.6181\n",
      "Epoch 529/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1643 - accuracy: 0.9523 - val_loss: 1.5780 - val_accuracy: 0.6076\n",
      "Epoch 530/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1515 - accuracy: 0.9462 - val_loss: 1.6374 - val_accuracy: 0.6215\n",
      "Epoch 531/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1547 - accuracy: 0.9549 - val_loss: 1.7591 - val_accuracy: 0.6042\n",
      "Epoch 532/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1472 - accuracy: 0.9549 - val_loss: 1.6182 - val_accuracy: 0.6146\n",
      "Epoch 533/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1705 - accuracy: 0.9358 - val_loss: 1.5938 - val_accuracy: 0.6354\n",
      "Epoch 534/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1688 - accuracy: 0.9375 - val_loss: 1.6415 - val_accuracy: 0.6007\n",
      "Epoch 535/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1459 - accuracy: 0.9523 - val_loss: 1.6267 - val_accuracy: 0.6215\n",
      "Epoch 536/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1577 - accuracy: 0.9462 - val_loss: 1.6836 - val_accuracy: 0.6146\n",
      "Epoch 537/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1733 - accuracy: 0.9349 - val_loss: 1.5968 - val_accuracy: 0.5868\n",
      "Epoch 538/1300\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.1687 - accuracy: 0.9427 - val_loss: 1.5367 - val_accuracy: 0.6007\n",
      "Epoch 539/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1589 - accuracy: 0.9392 - val_loss: 1.5228 - val_accuracy: 0.6076\n",
      "Epoch 540/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1616 - accuracy: 0.9436 - val_loss: 1.5983 - val_accuracy: 0.6181\n",
      "Epoch 541/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1482 - accuracy: 0.9505 - val_loss: 1.5985 - val_accuracy: 0.6354\n",
      "Epoch 542/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1812 - accuracy: 0.9410 - val_loss: 1.5520 - val_accuracy: 0.6250\n",
      "Epoch 543/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1566 - accuracy: 0.9462 - val_loss: 1.6011 - val_accuracy: 0.5972\n",
      "Epoch 544/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1628 - accuracy: 0.9540 - val_loss: 1.5607 - val_accuracy: 0.6354\n",
      "Epoch 545/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1780 - accuracy: 0.9401 - val_loss: 1.6357 - val_accuracy: 0.6354\n",
      "Epoch 546/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1663 - accuracy: 0.9488 - val_loss: 1.6557 - val_accuracy: 0.6181\n",
      "Epoch 547/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1728 - accuracy: 0.9358 - val_loss: 1.5506 - val_accuracy: 0.6250\n",
      "Epoch 548/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1441 - accuracy: 0.9531 - val_loss: 1.5806 - val_accuracy: 0.6215\n",
      "Epoch 549/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1493 - accuracy: 0.9488 - val_loss: 1.5719 - val_accuracy: 0.6354\n",
      "Epoch 550/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1605 - accuracy: 0.9418 - val_loss: 1.6320 - val_accuracy: 0.6076\n",
      "Epoch 551/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1554 - accuracy: 0.9436 - val_loss: 1.5382 - val_accuracy: 0.5938\n",
      "Epoch 552/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1637 - accuracy: 0.9418 - val_loss: 1.6148 - val_accuracy: 0.5833\n",
      "Epoch 553/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1692 - accuracy: 0.9462 - val_loss: 1.5726 - val_accuracy: 0.6076\n",
      "Epoch 554/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1546 - accuracy: 0.9505 - val_loss: 1.6073 - val_accuracy: 0.6285\n",
      "Epoch 555/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1476 - accuracy: 0.9479 - val_loss: 1.5904 - val_accuracy: 0.6250\n",
      "Epoch 556/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1644 - accuracy: 0.9436 - val_loss: 1.6076 - val_accuracy: 0.5972\n",
      "Epoch 557/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1475 - accuracy: 0.9505 - val_loss: 1.5604 - val_accuracy: 0.6076\n",
      "Epoch 558/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1717 - accuracy: 0.9444 - val_loss: 1.5463 - val_accuracy: 0.6215\n",
      "Epoch 559/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1449 - accuracy: 0.9540 - val_loss: 1.6324 - val_accuracy: 0.6285\n",
      "Epoch 560/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1761 - accuracy: 0.9453 - val_loss: 1.6307 - val_accuracy: 0.6111\n",
      "Epoch 561/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1454 - accuracy: 0.9557 - val_loss: 1.6971 - val_accuracy: 0.6285\n",
      "Epoch 562/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1571 - accuracy: 0.9410 - val_loss: 1.7148 - val_accuracy: 0.6007\n",
      "Epoch 563/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1667 - accuracy: 0.9427 - val_loss: 1.5171 - val_accuracy: 0.6319\n",
      "Epoch 564/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1357 - accuracy: 0.9575 - val_loss: 1.5721 - val_accuracy: 0.6042\n",
      "Epoch 565/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1686 - accuracy: 0.9427 - val_loss: 1.6803 - val_accuracy: 0.6076\n",
      "Epoch 566/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1597 - accuracy: 0.9462 - val_loss: 1.5707 - val_accuracy: 0.6250\n",
      "Epoch 567/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1454 - accuracy: 0.9583 - val_loss: 1.5232 - val_accuracy: 0.6354\n",
      "Epoch 568/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1839 - accuracy: 0.9323 - val_loss: 1.5380 - val_accuracy: 0.6181\n",
      "Epoch 569/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1665 - accuracy: 0.9444 - val_loss: 1.5583 - val_accuracy: 0.6111\n",
      "Epoch 570/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1545 - accuracy: 0.9505 - val_loss: 1.5554 - val_accuracy: 0.6076\n",
      "Epoch 571/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1451 - accuracy: 0.9392 - val_loss: 1.5966 - val_accuracy: 0.6250\n",
      "Epoch 572/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1647 - accuracy: 0.9427 - val_loss: 1.6343 - val_accuracy: 0.5972\n",
      "Epoch 573/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1499 - accuracy: 0.9514 - val_loss: 1.6297 - val_accuracy: 0.6319\n",
      "Epoch 574/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1544 - accuracy: 0.9488 - val_loss: 1.6342 - val_accuracy: 0.6007\n",
      "Epoch 575/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1526 - accuracy: 0.9523 - val_loss: 1.6009 - val_accuracy: 0.6250\n",
      "Epoch 576/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1335 - accuracy: 0.9575 - val_loss: 1.6462 - val_accuracy: 0.5938\n",
      "Epoch 577/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1762 - accuracy: 0.9444 - val_loss: 1.5743 - val_accuracy: 0.6215\n",
      "Epoch 578/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1454 - accuracy: 0.9505 - val_loss: 1.5773 - val_accuracy: 0.6111\n",
      "Epoch 579/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1610 - accuracy: 0.9392 - val_loss: 1.5135 - val_accuracy: 0.6701\n",
      "Epoch 580/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1509 - accuracy: 0.9514 - val_loss: 1.6736 - val_accuracy: 0.6146\n",
      "Epoch 581/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1338 - accuracy: 0.9557 - val_loss: 1.6868 - val_accuracy: 0.6076\n",
      "Epoch 582/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1696 - accuracy: 0.9410 - val_loss: 1.5512 - val_accuracy: 0.6389\n",
      "Epoch 583/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1518 - accuracy: 0.9592 - val_loss: 1.6762 - val_accuracy: 0.6111\n",
      "Epoch 584/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1514 - accuracy: 0.9540 - val_loss: 1.6031 - val_accuracy: 0.6146\n",
      "Epoch 585/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1387 - accuracy: 0.9566 - val_loss: 1.6214 - val_accuracy: 0.6181\n",
      "Epoch 586/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1611 - accuracy: 0.9436 - val_loss: 1.6504 - val_accuracy: 0.6181\n",
      "Epoch 587/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1394 - accuracy: 0.9557 - val_loss: 1.6008 - val_accuracy: 0.6354\n",
      "Epoch 588/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1477 - accuracy: 0.9488 - val_loss: 1.6466 - val_accuracy: 0.5833\n",
      "Epoch 589/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1574 - accuracy: 0.9444 - val_loss: 1.5758 - val_accuracy: 0.6181\n",
      "Epoch 590/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1443 - accuracy: 0.9549 - val_loss: 1.6485 - val_accuracy: 0.6111\n",
      "Epoch 591/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1327 - accuracy: 0.9592 - val_loss: 1.6170 - val_accuracy: 0.6424\n",
      "Epoch 592/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1499 - accuracy: 0.9470 - val_loss: 1.6045 - val_accuracy: 0.6354\n",
      "Epoch 593/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1633 - accuracy: 0.9479 - val_loss: 1.5788 - val_accuracy: 0.6389\n",
      "Epoch 594/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1421 - accuracy: 0.9514 - val_loss: 1.5862 - val_accuracy: 0.6424\n",
      "Epoch 595/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1454 - accuracy: 0.9557 - val_loss: 1.6637 - val_accuracy: 0.6181\n",
      "Epoch 596/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1422 - accuracy: 0.9523 - val_loss: 1.5956 - val_accuracy: 0.6181\n",
      "Epoch 597/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1495 - accuracy: 0.9514 - val_loss: 1.6198 - val_accuracy: 0.6146\n",
      "Epoch 598/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1405 - accuracy: 0.9523 - val_loss: 1.5899 - val_accuracy: 0.6181\n",
      "Epoch 599/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1456 - accuracy: 0.9462 - val_loss: 1.6030 - val_accuracy: 0.6042\n",
      "Epoch 600/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1313 - accuracy: 0.9583 - val_loss: 1.6887 - val_accuracy: 0.6181\n",
      "Epoch 601/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1527 - accuracy: 0.9488 - val_loss: 1.5995 - val_accuracy: 0.6250\n",
      "Epoch 602/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1433 - accuracy: 0.9540 - val_loss: 1.5785 - val_accuracy: 0.6285\n",
      "Epoch 603/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1245 - accuracy: 0.9601 - val_loss: 1.6094 - val_accuracy: 0.6007\n",
      "Epoch 604/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1509 - accuracy: 0.9497 - val_loss: 1.6409 - val_accuracy: 0.6111\n",
      "Epoch 605/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1407 - accuracy: 0.9583 - val_loss: 1.6190 - val_accuracy: 0.6528\n",
      "Epoch 606/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1653 - accuracy: 0.9410 - val_loss: 1.6540 - val_accuracy: 0.6285\n",
      "Epoch 607/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1454 - accuracy: 0.9566 - val_loss: 1.6140 - val_accuracy: 0.6250\n",
      "Epoch 608/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1521 - accuracy: 0.9444 - val_loss: 1.5936 - val_accuracy: 0.6181\n",
      "Epoch 609/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1446 - accuracy: 0.9436 - val_loss: 1.5957 - val_accuracy: 0.6111\n",
      "Epoch 610/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1557 - accuracy: 0.9514 - val_loss: 1.6241 - val_accuracy: 0.6146\n",
      "Epoch 611/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1420 - accuracy: 0.9531 - val_loss: 1.7387 - val_accuracy: 0.6007\n",
      "Epoch 612/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1474 - accuracy: 0.9497 - val_loss: 1.6991 - val_accuracy: 0.5938\n",
      "Epoch 613/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1426 - accuracy: 0.9470 - val_loss: 1.5802 - val_accuracy: 0.6285\n",
      "Epoch 614/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1297 - accuracy: 0.9575 - val_loss: 1.7309 - val_accuracy: 0.5972\n",
      "Epoch 615/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1426 - accuracy: 0.9566 - val_loss: 1.6645 - val_accuracy: 0.6250\n",
      "Epoch 616/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1492 - accuracy: 0.9453 - val_loss: 1.5771 - val_accuracy: 0.6146\n",
      "Epoch 617/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1284 - accuracy: 0.9592 - val_loss: 1.6228 - val_accuracy: 0.6389\n",
      "Epoch 618/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1248 - accuracy: 0.9583 - val_loss: 1.6136 - val_accuracy: 0.6111\n",
      "Epoch 619/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1438 - accuracy: 0.9462 - val_loss: 1.5571 - val_accuracy: 0.6250\n",
      "Epoch 620/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1648 - accuracy: 0.9418 - val_loss: 1.6482 - val_accuracy: 0.6319\n",
      "Epoch 621/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1348 - accuracy: 0.9618 - val_loss: 1.7145 - val_accuracy: 0.6250\n",
      "Epoch 622/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1446 - accuracy: 0.9549 - val_loss: 1.7457 - val_accuracy: 0.5938\n",
      "Epoch 623/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1404 - accuracy: 0.9479 - val_loss: 1.6396 - val_accuracy: 0.6146\n",
      "Epoch 624/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1536 - accuracy: 0.9514 - val_loss: 1.5978 - val_accuracy: 0.6319\n",
      "Epoch 625/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1370 - accuracy: 0.9609 - val_loss: 1.5738 - val_accuracy: 0.6528\n",
      "Epoch 626/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1305 - accuracy: 0.9531 - val_loss: 1.5948 - val_accuracy: 0.6285\n",
      "Epoch 627/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1241 - accuracy: 0.9661 - val_loss: 1.6570 - val_accuracy: 0.6042\n",
      "Epoch 628/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1364 - accuracy: 0.9583 - val_loss: 1.7042 - val_accuracy: 0.6215\n",
      "Epoch 629/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1269 - accuracy: 0.9601 - val_loss: 1.7943 - val_accuracy: 0.5868\n",
      "Epoch 630/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1453 - accuracy: 0.9497 - val_loss: 1.5890 - val_accuracy: 0.6285\n",
      "Epoch 631/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1130 - accuracy: 0.9653 - val_loss: 1.5728 - val_accuracy: 0.6215\n",
      "Epoch 632/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1367 - accuracy: 0.9609 - val_loss: 1.6898 - val_accuracy: 0.6354\n",
      "Epoch 633/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1379 - accuracy: 0.9523 - val_loss: 1.6439 - val_accuracy: 0.6389\n",
      "Epoch 634/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1402 - accuracy: 0.9609 - val_loss: 1.6389 - val_accuracy: 0.6111\n",
      "Epoch 635/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1218 - accuracy: 0.9618 - val_loss: 1.6914 - val_accuracy: 0.6285\n",
      "Epoch 636/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1343 - accuracy: 0.9505 - val_loss: 1.6170 - val_accuracy: 0.6215\n",
      "Epoch 637/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1323 - accuracy: 0.9505 - val_loss: 1.5939 - val_accuracy: 0.6389\n",
      "Epoch 638/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1278 - accuracy: 0.9575 - val_loss: 1.6467 - val_accuracy: 0.6493\n",
      "Epoch 639/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1365 - accuracy: 0.9575 - val_loss: 1.6319 - val_accuracy: 0.6493\n",
      "Epoch 640/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1236 - accuracy: 0.9679 - val_loss: 1.6424 - val_accuracy: 0.6146\n",
      "Epoch 641/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1428 - accuracy: 0.9523 - val_loss: 1.6711 - val_accuracy: 0.6111\n",
      "Epoch 642/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1369 - accuracy: 0.9488 - val_loss: 1.6299 - val_accuracy: 0.6354\n",
      "Epoch 643/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1273 - accuracy: 0.9583 - val_loss: 1.6649 - val_accuracy: 0.6250\n",
      "Epoch 644/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1428 - accuracy: 0.9497 - val_loss: 1.6247 - val_accuracy: 0.6215\n",
      "Epoch 645/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1408 - accuracy: 0.9523 - val_loss: 1.7529 - val_accuracy: 0.6111\n",
      "Epoch 646/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1338 - accuracy: 0.9583 - val_loss: 1.6585 - val_accuracy: 0.6354\n",
      "Epoch 647/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1243 - accuracy: 0.9592 - val_loss: 1.6544 - val_accuracy: 0.6319\n",
      "Epoch 648/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1303 - accuracy: 0.9575 - val_loss: 1.5966 - val_accuracy: 0.6458\n",
      "Epoch 649/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1497 - accuracy: 0.9453 - val_loss: 1.6724 - val_accuracy: 0.6354\n",
      "Epoch 650/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1396 - accuracy: 0.9497 - val_loss: 1.6531 - val_accuracy: 0.6250\n",
      "Epoch 651/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1317 - accuracy: 0.9601 - val_loss: 1.7022 - val_accuracy: 0.6285\n",
      "Epoch 652/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1267 - accuracy: 0.9618 - val_loss: 1.6181 - val_accuracy: 0.6319\n",
      "Epoch 653/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1166 - accuracy: 0.9627 - val_loss: 1.6615 - val_accuracy: 0.6250\n",
      "Epoch 654/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1406 - accuracy: 0.9540 - val_loss: 1.6505 - val_accuracy: 0.6042\n",
      "Epoch 655/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1283 - accuracy: 0.9592 - val_loss: 1.8118 - val_accuracy: 0.5903\n",
      "Epoch 656/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1371 - accuracy: 0.9479 - val_loss: 1.7444 - val_accuracy: 0.6319\n",
      "Epoch 657/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1279 - accuracy: 0.9609 - val_loss: 1.6794 - val_accuracy: 0.6285\n",
      "Epoch 658/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1136 - accuracy: 0.9618 - val_loss: 1.6801 - val_accuracy: 0.6285\n",
      "Epoch 659/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1296 - accuracy: 0.9557 - val_loss: 1.7136 - val_accuracy: 0.6146\n",
      "Epoch 660/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1333 - accuracy: 0.9618 - val_loss: 1.7855 - val_accuracy: 0.6146\n",
      "Epoch 661/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1147 - accuracy: 0.9618 - val_loss: 1.6934 - val_accuracy: 0.6215\n",
      "Epoch 662/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1125 - accuracy: 0.9661 - val_loss: 1.7877 - val_accuracy: 0.6285\n",
      "Epoch 663/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1284 - accuracy: 0.9549 - val_loss: 1.6799 - val_accuracy: 0.6215\n",
      "Epoch 664/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1327 - accuracy: 0.9583 - val_loss: 1.6763 - val_accuracy: 0.6285\n",
      "Epoch 665/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1335 - accuracy: 0.9523 - val_loss: 1.6193 - val_accuracy: 0.6181\n",
      "Epoch 666/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1212 - accuracy: 0.9618 - val_loss: 1.7091 - val_accuracy: 0.6215\n",
      "Epoch 667/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1232 - accuracy: 0.9618 - val_loss: 1.7780 - val_accuracy: 0.6181\n",
      "Epoch 668/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1317 - accuracy: 0.9575 - val_loss: 1.8538 - val_accuracy: 0.5972\n",
      "Epoch 669/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1279 - accuracy: 0.9523 - val_loss: 1.6178 - val_accuracy: 0.6424\n",
      "Epoch 670/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1211 - accuracy: 0.9627 - val_loss: 1.7576 - val_accuracy: 0.6215\n",
      "Epoch 671/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1030 - accuracy: 0.9705 - val_loss: 1.6989 - val_accuracy: 0.6424\n",
      "Epoch 672/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1253 - accuracy: 0.9601 - val_loss: 1.7813 - val_accuracy: 0.6111\n",
      "Epoch 673/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1278 - accuracy: 0.9479 - val_loss: 1.6925 - val_accuracy: 0.6597\n",
      "Epoch 674/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1212 - accuracy: 0.9601 - val_loss: 1.7446 - val_accuracy: 0.6250\n",
      "Epoch 675/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1166 - accuracy: 0.9601 - val_loss: 1.6075 - val_accuracy: 0.6493\n",
      "Epoch 676/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1229 - accuracy: 0.9618 - val_loss: 1.6929 - val_accuracy: 0.6250\n",
      "Epoch 677/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1161 - accuracy: 0.9679 - val_loss: 1.6234 - val_accuracy: 0.6319\n",
      "Epoch 678/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1165 - accuracy: 0.9627 - val_loss: 1.6589 - val_accuracy: 0.6285\n",
      "Epoch 679/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1508 - accuracy: 0.9479 - val_loss: 1.6385 - val_accuracy: 0.6389\n",
      "Epoch 680/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1422 - accuracy: 0.9497 - val_loss: 1.6544 - val_accuracy: 0.6354\n",
      "Epoch 681/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1303 - accuracy: 0.9609 - val_loss: 1.6699 - val_accuracy: 0.6424\n",
      "Epoch 682/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1286 - accuracy: 0.9505 - val_loss: 1.6438 - val_accuracy: 0.6493\n",
      "Epoch 683/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1315 - accuracy: 0.9497 - val_loss: 1.7020 - val_accuracy: 0.6354\n",
      "Epoch 684/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1364 - accuracy: 0.9505 - val_loss: 1.6595 - val_accuracy: 0.6354\n",
      "Epoch 685/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1238 - accuracy: 0.9566 - val_loss: 1.6824 - val_accuracy: 0.6215\n",
      "Epoch 686/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1124 - accuracy: 0.9583 - val_loss: 1.6624 - val_accuracy: 0.6319\n",
      "Epoch 687/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1161 - accuracy: 0.9618 - val_loss: 1.6740 - val_accuracy: 0.5972\n",
      "Epoch 688/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1441 - accuracy: 0.9540 - val_loss: 1.6564 - val_accuracy: 0.6458\n",
      "Epoch 689/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1191 - accuracy: 0.9557 - val_loss: 1.6321 - val_accuracy: 0.6389\n",
      "Epoch 690/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1326 - accuracy: 0.9540 - val_loss: 1.6744 - val_accuracy: 0.6146\n",
      "Epoch 691/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1167 - accuracy: 0.9644 - val_loss: 1.6572 - val_accuracy: 0.6250\n",
      "Epoch 692/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1282 - accuracy: 0.9583 - val_loss: 1.6589 - val_accuracy: 0.6111\n",
      "Epoch 693/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0992 - accuracy: 0.9679 - val_loss: 1.6266 - val_accuracy: 0.6250\n",
      "Epoch 694/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1032 - accuracy: 0.9688 - val_loss: 1.8427 - val_accuracy: 0.6181\n",
      "Epoch 695/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1029 - accuracy: 0.9705 - val_loss: 1.8427 - val_accuracy: 0.5938\n",
      "Epoch 696/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1160 - accuracy: 0.9644 - val_loss: 1.6245 - val_accuracy: 0.6319\n",
      "Epoch 697/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1247 - accuracy: 0.9575 - val_loss: 1.6769 - val_accuracy: 0.6146\n",
      "Epoch 698/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1277 - accuracy: 0.9531 - val_loss: 1.6998 - val_accuracy: 0.6250\n",
      "Epoch 699/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1168 - accuracy: 0.9618 - val_loss: 1.7176 - val_accuracy: 0.5903\n",
      "Epoch 700/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1196 - accuracy: 0.9609 - val_loss: 1.7092 - val_accuracy: 0.6250\n",
      "Epoch 701/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1195 - accuracy: 0.9670 - val_loss: 1.7028 - val_accuracy: 0.6215\n",
      "Epoch 702/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1196 - accuracy: 0.9592 - val_loss: 1.7060 - val_accuracy: 0.6319\n",
      "Epoch 703/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1070 - accuracy: 0.9609 - val_loss: 1.6894 - val_accuracy: 0.6597\n",
      "Epoch 704/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1149 - accuracy: 0.9583 - val_loss: 1.7085 - val_accuracy: 0.6111\n",
      "Epoch 705/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1093 - accuracy: 0.9670 - val_loss: 1.6590 - val_accuracy: 0.6493\n",
      "Epoch 706/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1174 - accuracy: 0.9575 - val_loss: 1.6222 - val_accuracy: 0.6319\n",
      "Epoch 707/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1280 - accuracy: 0.9557 - val_loss: 1.6554 - val_accuracy: 0.6181\n",
      "Epoch 708/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1043 - accuracy: 0.9670 - val_loss: 1.7911 - val_accuracy: 0.6111\n",
      "Epoch 709/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1230 - accuracy: 0.9583 - val_loss: 1.6782 - val_accuracy: 0.6042\n",
      "Epoch 710/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1294 - accuracy: 0.9627 - val_loss: 1.6757 - val_accuracy: 0.6042\n",
      "Epoch 711/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1285 - accuracy: 0.9609 - val_loss: 1.6265 - val_accuracy: 0.6319\n",
      "Epoch 712/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1013 - accuracy: 0.9731 - val_loss: 1.6270 - val_accuracy: 0.6458\n",
      "Epoch 713/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1192 - accuracy: 0.9635 - val_loss: 1.6349 - val_accuracy: 0.6354\n",
      "Epoch 714/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1098 - accuracy: 0.9627 - val_loss: 1.7867 - val_accuracy: 0.6076\n",
      "Epoch 715/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0970 - accuracy: 0.9731 - val_loss: 1.6983 - val_accuracy: 0.6319\n",
      "Epoch 716/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1122 - accuracy: 0.9601 - val_loss: 1.7854 - val_accuracy: 0.6042\n",
      "Epoch 717/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1072 - accuracy: 0.9670 - val_loss: 1.6427 - val_accuracy: 0.6424\n",
      "Epoch 718/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1243 - accuracy: 0.9627 - val_loss: 1.8180 - val_accuracy: 0.6007\n",
      "Epoch 719/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1313 - accuracy: 0.9566 - val_loss: 1.7337 - val_accuracy: 0.6181\n",
      "Epoch 720/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1307 - accuracy: 0.9583 - val_loss: 1.8426 - val_accuracy: 0.6181\n",
      "Epoch 721/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1259 - accuracy: 0.9635 - val_loss: 1.7078 - val_accuracy: 0.6319\n",
      "Epoch 722/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1123 - accuracy: 0.9653 - val_loss: 1.7551 - val_accuracy: 0.6250\n",
      "Epoch 723/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1005 - accuracy: 0.9722 - val_loss: 1.7498 - val_accuracy: 0.6354\n",
      "Epoch 724/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1067 - accuracy: 0.9644 - val_loss: 1.6883 - val_accuracy: 0.6146\n",
      "Epoch 725/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1113 - accuracy: 0.9653 - val_loss: 1.8132 - val_accuracy: 0.6319\n",
      "Epoch 726/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0961 - accuracy: 0.9644 - val_loss: 1.8936 - val_accuracy: 0.5903\n",
      "Epoch 727/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1114 - accuracy: 0.9627 - val_loss: 1.7393 - val_accuracy: 0.6215\n",
      "Epoch 728/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1191 - accuracy: 0.9609 - val_loss: 1.6152 - val_accuracy: 0.6319\n",
      "Epoch 729/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1101 - accuracy: 0.9618 - val_loss: 1.6456 - val_accuracy: 0.6181\n",
      "Epoch 730/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1254 - accuracy: 0.9609 - val_loss: 1.7977 - val_accuracy: 0.6389\n",
      "Epoch 731/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0961 - accuracy: 0.9722 - val_loss: 1.8050 - val_accuracy: 0.6181\n",
      "Epoch 732/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1162 - accuracy: 0.9609 - val_loss: 1.8221 - val_accuracy: 0.5868\n",
      "Epoch 733/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1106 - accuracy: 0.9618 - val_loss: 1.7175 - val_accuracy: 0.6285\n",
      "Epoch 734/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1019 - accuracy: 0.9696 - val_loss: 1.6281 - val_accuracy: 0.6285\n",
      "Epoch 735/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1176 - accuracy: 0.9592 - val_loss: 1.6894 - val_accuracy: 0.6354\n",
      "Epoch 736/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1120 - accuracy: 0.9601 - val_loss: 1.9390 - val_accuracy: 0.6111\n",
      "Epoch 737/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1316 - accuracy: 0.9549 - val_loss: 1.8265 - val_accuracy: 0.6076\n",
      "Epoch 738/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1140 - accuracy: 0.9644 - val_loss: 1.6852 - val_accuracy: 0.6424\n",
      "Epoch 739/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1152 - accuracy: 0.9627 - val_loss: 1.7258 - val_accuracy: 0.6424\n",
      "Epoch 740/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1004 - accuracy: 0.9661 - val_loss: 1.6549 - val_accuracy: 0.6389\n",
      "Epoch 741/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1043 - accuracy: 0.9653 - val_loss: 1.6357 - val_accuracy: 0.6424\n",
      "Epoch 742/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0954 - accuracy: 0.9670 - val_loss: 1.7459 - val_accuracy: 0.6319\n",
      "Epoch 743/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1129 - accuracy: 0.9592 - val_loss: 1.7782 - val_accuracy: 0.6285\n",
      "Epoch 744/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1096 - accuracy: 0.9661 - val_loss: 1.8372 - val_accuracy: 0.6493\n",
      "Epoch 745/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1083 - accuracy: 0.9618 - val_loss: 1.7538 - val_accuracy: 0.6424\n",
      "Epoch 746/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0930 - accuracy: 0.9714 - val_loss: 1.8331 - val_accuracy: 0.6111\n",
      "Epoch 747/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1082 - accuracy: 0.9688 - val_loss: 1.8005 - val_accuracy: 0.6181\n",
      "Epoch 748/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1164 - accuracy: 0.9661 - val_loss: 1.7940 - val_accuracy: 0.6042\n",
      "Epoch 749/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9644 - val_loss: 1.7614 - val_accuracy: 0.6319\n",
      "Epoch 750/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1186 - accuracy: 0.9575 - val_loss: 1.8317 - val_accuracy: 0.6146\n",
      "Epoch 751/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0969 - accuracy: 0.9748 - val_loss: 1.7915 - val_accuracy: 0.6146\n",
      "Epoch 752/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0884 - accuracy: 0.9722 - val_loss: 1.7400 - val_accuracy: 0.6146\n",
      "Epoch 753/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1021 - accuracy: 0.9679 - val_loss: 1.9407 - val_accuracy: 0.6389\n",
      "Epoch 754/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1075 - accuracy: 0.9635 - val_loss: 1.7605 - val_accuracy: 0.6146\n",
      "Epoch 755/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1029 - accuracy: 0.9601 - val_loss: 1.7907 - val_accuracy: 0.6076\n",
      "Epoch 756/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1020 - accuracy: 0.9661 - val_loss: 1.7377 - val_accuracy: 0.6215\n",
      "Epoch 757/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0861 - accuracy: 0.9748 - val_loss: 1.8377 - val_accuracy: 0.6250\n",
      "Epoch 758/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1318 - accuracy: 0.9531 - val_loss: 1.8419 - val_accuracy: 0.6146\n",
      "Epoch 759/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0998 - accuracy: 0.9731 - val_loss: 1.7876 - val_accuracy: 0.6319\n",
      "Epoch 760/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1227 - accuracy: 0.9566 - val_loss: 1.7981 - val_accuracy: 0.6111\n",
      "Epoch 761/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0897 - accuracy: 0.9748 - val_loss: 1.8057 - val_accuracy: 0.6042\n",
      "Epoch 762/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1049 - accuracy: 0.9644 - val_loss: 1.8325 - val_accuracy: 0.5799\n",
      "Epoch 763/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1042 - accuracy: 0.9670 - val_loss: 1.7647 - val_accuracy: 0.6146\n",
      "Epoch 764/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1087 - accuracy: 0.9653 - val_loss: 1.7204 - val_accuracy: 0.6424\n",
      "Epoch 765/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1075 - accuracy: 0.9670 - val_loss: 1.7709 - val_accuracy: 0.6215\n",
      "Epoch 766/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1012 - accuracy: 0.9696 - val_loss: 1.7794 - val_accuracy: 0.6181\n",
      "Epoch 767/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1148 - accuracy: 0.9601 - val_loss: 1.8007 - val_accuracy: 0.6076\n",
      "Epoch 768/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0864 - accuracy: 0.9696 - val_loss: 1.8189 - val_accuracy: 0.5903\n",
      "Epoch 769/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1038 - accuracy: 0.9670 - val_loss: 1.7246 - val_accuracy: 0.6319\n",
      "Epoch 770/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1015 - accuracy: 0.9627 - val_loss: 1.6915 - val_accuracy: 0.6146\n",
      "Epoch 771/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1101 - accuracy: 0.9635 - val_loss: 1.6650 - val_accuracy: 0.6354\n",
      "Epoch 772/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0928 - accuracy: 0.9714 - val_loss: 1.6933 - val_accuracy: 0.6285\n",
      "Epoch 773/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1207 - accuracy: 0.9618 - val_loss: 1.8241 - val_accuracy: 0.6146\n",
      "Epoch 774/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0941 - accuracy: 0.9670 - val_loss: 1.7298 - val_accuracy: 0.6424\n",
      "Epoch 775/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1055 - accuracy: 0.9644 - val_loss: 1.7278 - val_accuracy: 0.6632\n",
      "Epoch 776/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1033 - accuracy: 0.9670 - val_loss: 1.7486 - val_accuracy: 0.6285\n",
      "Epoch 777/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0916 - accuracy: 0.9722 - val_loss: 1.7675 - val_accuracy: 0.6285\n",
      "Epoch 778/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0979 - accuracy: 0.9688 - val_loss: 1.8482 - val_accuracy: 0.6250\n",
      "Epoch 779/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1036 - accuracy: 0.9601 - val_loss: 1.7431 - val_accuracy: 0.6146\n",
      "Epoch 780/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0959 - accuracy: 0.9688 - val_loss: 1.8887 - val_accuracy: 0.6007\n",
      "Epoch 781/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1143 - accuracy: 0.9670 - val_loss: 1.7752 - val_accuracy: 0.6389\n",
      "Epoch 782/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1077 - accuracy: 0.9635 - val_loss: 1.8062 - val_accuracy: 0.6319\n",
      "Epoch 783/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1108 - accuracy: 0.9583 - val_loss: 1.7440 - val_accuracy: 0.6354\n",
      "Epoch 784/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1026 - accuracy: 0.9644 - val_loss: 1.7700 - val_accuracy: 0.6354\n",
      "Epoch 785/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0920 - accuracy: 0.9696 - val_loss: 1.7868 - val_accuracy: 0.6389\n",
      "Epoch 786/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1081 - accuracy: 0.9705 - val_loss: 1.8482 - val_accuracy: 0.6181\n",
      "Epoch 787/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0931 - accuracy: 0.9696 - val_loss: 1.7495 - val_accuracy: 0.6250\n",
      "Epoch 788/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0974 - accuracy: 0.9661 - val_loss: 1.9395 - val_accuracy: 0.6319\n",
      "Epoch 789/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1093 - accuracy: 0.9644 - val_loss: 1.6973 - val_accuracy: 0.6146\n",
      "Epoch 790/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0832 - accuracy: 0.9740 - val_loss: 1.8730 - val_accuracy: 0.6146\n",
      "Epoch 791/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0977 - accuracy: 0.9696 - val_loss: 1.8919 - val_accuracy: 0.6007\n",
      "Epoch 792/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1071 - accuracy: 0.9653 - val_loss: 1.8242 - val_accuracy: 0.6424\n",
      "Epoch 793/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0997 - accuracy: 0.9688 - val_loss: 1.8676 - val_accuracy: 0.6215\n",
      "Epoch 794/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0938 - accuracy: 0.9661 - val_loss: 1.8369 - val_accuracy: 0.6146\n",
      "Epoch 795/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1146 - accuracy: 0.9618 - val_loss: 1.8112 - val_accuracy: 0.6146\n",
      "Epoch 796/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0804 - accuracy: 0.9722 - val_loss: 1.8104 - val_accuracy: 0.6215\n",
      "Epoch 797/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0968 - accuracy: 0.9688 - val_loss: 1.8506 - val_accuracy: 0.6285\n",
      "Epoch 798/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9679 - val_loss: 1.8276 - val_accuracy: 0.6215\n",
      "Epoch 799/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1019 - accuracy: 0.9627 - val_loss: 1.8818 - val_accuracy: 0.6493\n",
      "Epoch 800/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1075 - accuracy: 0.9670 - val_loss: 1.8329 - val_accuracy: 0.6042\n",
      "Epoch 801/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1186 - accuracy: 0.9627 - val_loss: 1.8028 - val_accuracy: 0.6285\n",
      "Epoch 802/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0972 - accuracy: 0.9748 - val_loss: 1.8800 - val_accuracy: 0.6250\n",
      "Epoch 803/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0937 - accuracy: 0.9688 - val_loss: 1.7878 - val_accuracy: 0.6215\n",
      "Epoch 804/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0955 - accuracy: 0.9688 - val_loss: 1.8300 - val_accuracy: 0.6181\n",
      "Epoch 805/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1038 - accuracy: 0.9714 - val_loss: 1.8501 - val_accuracy: 0.6319\n",
      "Epoch 806/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.1106 - accuracy: 0.9627 - val_loss: 1.8326 - val_accuracy: 0.5972\n",
      "Epoch 807/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9670 - val_loss: 1.7473 - val_accuracy: 0.6111\n",
      "Epoch 808/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0857 - accuracy: 0.9731 - val_loss: 1.6957 - val_accuracy: 0.6424\n",
      "Epoch 809/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0926 - accuracy: 0.9679 - val_loss: 1.9380 - val_accuracy: 0.6042\n",
      "Epoch 810/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0914 - accuracy: 0.9748 - val_loss: 1.7536 - val_accuracy: 0.6319\n",
      "Epoch 811/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0886 - accuracy: 0.9696 - val_loss: 1.8123 - val_accuracy: 0.6389\n",
      "Epoch 812/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0900 - accuracy: 0.9722 - val_loss: 1.8220 - val_accuracy: 0.6215\n",
      "Epoch 813/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1020 - accuracy: 0.9644 - val_loss: 1.8300 - val_accuracy: 0.6146\n",
      "Epoch 814/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1021 - accuracy: 0.9644 - val_loss: 1.7784 - val_accuracy: 0.6146\n",
      "Epoch 815/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0732 - accuracy: 0.9800 - val_loss: 1.8300 - val_accuracy: 0.6215\n",
      "Epoch 816/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0991 - accuracy: 0.9661 - val_loss: 1.8054 - val_accuracy: 0.6424\n",
      "Epoch 817/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1014 - accuracy: 0.9688 - val_loss: 1.9346 - val_accuracy: 0.6181\n",
      "Epoch 818/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1032 - accuracy: 0.9627 - val_loss: 1.8353 - val_accuracy: 0.6354\n",
      "Epoch 819/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0964 - accuracy: 0.9688 - val_loss: 1.7564 - val_accuracy: 0.6250\n",
      "Epoch 820/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 1.7421 - val_accuracy: 0.6215\n",
      "Epoch 821/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0889 - accuracy: 0.9800 - val_loss: 1.8098 - val_accuracy: 0.6389\n",
      "Epoch 822/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1110 - accuracy: 0.9644 - val_loss: 1.7891 - val_accuracy: 0.6146\n",
      "Epoch 823/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1190 - accuracy: 0.9601 - val_loss: 1.8593 - val_accuracy: 0.6076\n",
      "Epoch 824/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0753 - accuracy: 0.9818 - val_loss: 1.8802 - val_accuracy: 0.6042\n",
      "Epoch 825/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1066 - accuracy: 0.9661 - val_loss: 1.7010 - val_accuracy: 0.6319\n",
      "Epoch 826/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1044 - accuracy: 0.9670 - val_loss: 1.7216 - val_accuracy: 0.6424\n",
      "Epoch 827/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0867 - accuracy: 0.9714 - val_loss: 1.7911 - val_accuracy: 0.6215\n",
      "Epoch 828/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0830 - accuracy: 0.9722 - val_loss: 1.7077 - val_accuracy: 0.6389\n",
      "Epoch 829/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0874 - accuracy: 0.9688 - val_loss: 1.8415 - val_accuracy: 0.5868\n",
      "Epoch 830/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1147 - accuracy: 0.9635 - val_loss: 1.8611 - val_accuracy: 0.6319\n",
      "Epoch 831/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0918 - accuracy: 0.9670 - val_loss: 1.8508 - val_accuracy: 0.6424\n",
      "Epoch 832/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0914 - accuracy: 0.9679 - val_loss: 1.8869 - val_accuracy: 0.6076\n",
      "Epoch 833/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0893 - accuracy: 0.9679 - val_loss: 1.7449 - val_accuracy: 0.6319\n",
      "Epoch 834/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1066 - accuracy: 0.9688 - val_loss: 1.7708 - val_accuracy: 0.6389\n",
      "Epoch 835/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0980 - accuracy: 0.9714 - val_loss: 1.7473 - val_accuracy: 0.6354\n",
      "Epoch 836/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0884 - accuracy: 0.9731 - val_loss: 1.8265 - val_accuracy: 0.6111\n",
      "Epoch 837/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0892 - accuracy: 0.9731 - val_loss: 1.8569 - val_accuracy: 0.6042\n",
      "Epoch 838/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0794 - accuracy: 0.9800 - val_loss: 1.7737 - val_accuracy: 0.6319\n",
      "Epoch 839/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0718 - accuracy: 0.9757 - val_loss: 1.8722 - val_accuracy: 0.6319\n",
      "Epoch 840/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 1.9201 - val_accuracy: 0.6181\n",
      "Epoch 841/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1092 - accuracy: 0.9618 - val_loss: 1.8431 - val_accuracy: 0.6181\n",
      "Epoch 842/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0767 - accuracy: 0.9731 - val_loss: 1.8302 - val_accuracy: 0.6319\n",
      "Epoch 843/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0970 - accuracy: 0.9670 - val_loss: 1.7495 - val_accuracy: 0.6424\n",
      "Epoch 844/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1072 - accuracy: 0.9644 - val_loss: 1.9575 - val_accuracy: 0.6076\n",
      "Epoch 845/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1095 - accuracy: 0.9670 - val_loss: 1.7577 - val_accuracy: 0.6354\n",
      "Epoch 846/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0833 - accuracy: 0.9748 - val_loss: 1.8006 - val_accuracy: 0.6181\n",
      "Epoch 847/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0883 - accuracy: 0.9740 - val_loss: 1.8615 - val_accuracy: 0.6181\n",
      "Epoch 848/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0826 - accuracy: 0.9783 - val_loss: 1.8808 - val_accuracy: 0.6354\n",
      "Epoch 849/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1091 - accuracy: 0.9635 - val_loss: 1.7847 - val_accuracy: 0.6319\n",
      "Epoch 850/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0836 - accuracy: 0.9774 - val_loss: 1.8022 - val_accuracy: 0.6181\n",
      "Epoch 851/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0994 - accuracy: 0.9705 - val_loss: 1.8337 - val_accuracy: 0.6389\n",
      "Epoch 852/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0992 - accuracy: 0.9653 - val_loss: 1.8019 - val_accuracy: 0.6111\n",
      "Epoch 853/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0999 - accuracy: 0.9714 - val_loss: 1.7799 - val_accuracy: 0.6285\n",
      "Epoch 854/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0912 - accuracy: 0.9757 - val_loss: 1.8422 - val_accuracy: 0.6285\n",
      "Epoch 855/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1044 - accuracy: 0.9635 - val_loss: 1.7496 - val_accuracy: 0.6215\n",
      "Epoch 856/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1035 - accuracy: 0.9661 - val_loss: 1.7977 - val_accuracy: 0.6215\n",
      "Epoch 857/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0805 - accuracy: 0.9714 - val_loss: 1.8860 - val_accuracy: 0.6111\n",
      "Epoch 858/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0733 - accuracy: 0.9809 - val_loss: 1.8666 - val_accuracy: 0.6528\n",
      "Epoch 859/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0868 - accuracy: 0.9740 - val_loss: 1.8134 - val_accuracy: 0.6215\n",
      "Epoch 860/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0779 - accuracy: 0.9757 - val_loss: 1.8558 - val_accuracy: 0.6146\n",
      "Epoch 861/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1148 - accuracy: 0.9609 - val_loss: 1.7850 - val_accuracy: 0.6389\n",
      "Epoch 862/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0764 - accuracy: 0.9783 - val_loss: 2.0150 - val_accuracy: 0.6007\n",
      "Epoch 863/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1060 - accuracy: 0.9653 - val_loss: 1.8836 - val_accuracy: 0.6389\n",
      "Epoch 864/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1020 - accuracy: 0.9705 - val_loss: 1.8931 - val_accuracy: 0.6319\n",
      "Epoch 865/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0772 - accuracy: 0.9792 - val_loss: 1.9045 - val_accuracy: 0.6215\n",
      "Epoch 866/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0963 - accuracy: 0.9661 - val_loss: 1.8063 - val_accuracy: 0.6424\n",
      "Epoch 867/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0715 - accuracy: 0.9774 - val_loss: 1.8891 - val_accuracy: 0.6181\n",
      "Epoch 868/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 1.8383 - val_accuracy: 0.6424\n",
      "Epoch 869/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0862 - accuracy: 0.9696 - val_loss: 1.9159 - val_accuracy: 0.6319\n",
      "Epoch 870/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0995 - accuracy: 0.9705 - val_loss: 1.8807 - val_accuracy: 0.6285\n",
      "Epoch 871/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0971 - accuracy: 0.9592 - val_loss: 1.7821 - val_accuracy: 0.6354\n",
      "Epoch 872/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0900 - accuracy: 0.9757 - val_loss: 1.9043 - val_accuracy: 0.6076\n",
      "Epoch 873/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0914 - accuracy: 0.9644 - val_loss: 1.8981 - val_accuracy: 0.6285\n",
      "Epoch 874/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0864 - accuracy: 0.9731 - val_loss: 1.8914 - val_accuracy: 0.6215\n",
      "Epoch 875/1300\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0832 - accuracy: 0.9748 - val_loss: 1.8255 - val_accuracy: 0.6458\n",
      "Epoch 876/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0949 - accuracy: 0.9679 - val_loss: 1.8684 - val_accuracy: 0.6250\n",
      "Epoch 877/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0884 - accuracy: 0.9670 - val_loss: 1.9580 - val_accuracy: 0.6042\n",
      "Epoch 878/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0852 - accuracy: 0.9688 - val_loss: 1.8919 - val_accuracy: 0.6215\n",
      "Epoch 879/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0880 - accuracy: 0.9731 - val_loss: 1.8204 - val_accuracy: 0.6389\n",
      "Epoch 880/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0772 - accuracy: 0.9766 - val_loss: 1.9507 - val_accuracy: 0.6354\n",
      "Epoch 881/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1040 - accuracy: 0.9688 - val_loss: 1.9726 - val_accuracy: 0.5799\n",
      "Epoch 882/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0955 - accuracy: 0.9661 - val_loss: 1.8002 - val_accuracy: 0.6424\n",
      "Epoch 883/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0821 - accuracy: 0.9748 - val_loss: 1.8380 - val_accuracy: 0.6181\n",
      "Epoch 884/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0813 - accuracy: 0.9705 - val_loss: 1.9546 - val_accuracy: 0.6111\n",
      "Epoch 885/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0919 - accuracy: 0.9696 - val_loss: 1.9098 - val_accuracy: 0.6007\n",
      "Epoch 886/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1015 - accuracy: 0.9679 - val_loss: 1.8216 - val_accuracy: 0.6042\n",
      "Epoch 887/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0927 - accuracy: 0.9679 - val_loss: 1.9092 - val_accuracy: 0.6181\n",
      "Epoch 888/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0777 - accuracy: 0.9714 - val_loss: 1.8654 - val_accuracy: 0.6111\n",
      "Epoch 889/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1002 - accuracy: 0.9696 - val_loss: 1.8529 - val_accuracy: 0.6319\n",
      "Epoch 890/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0913 - accuracy: 0.9688 - val_loss: 1.8280 - val_accuracy: 0.6076\n",
      "Epoch 891/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0808 - accuracy: 0.9731 - val_loss: 1.8513 - val_accuracy: 0.6181\n",
      "Epoch 892/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0973 - accuracy: 0.9670 - val_loss: 1.8147 - val_accuracy: 0.6458\n",
      "Epoch 893/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0777 - accuracy: 0.9731 - val_loss: 1.9406 - val_accuracy: 0.6319\n",
      "Epoch 894/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0887 - accuracy: 0.9705 - val_loss: 1.8552 - val_accuracy: 0.6389\n",
      "Epoch 895/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1067 - accuracy: 0.9679 - val_loss: 1.7718 - val_accuracy: 0.6389\n",
      "Epoch 896/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0661 - accuracy: 0.9818 - val_loss: 1.9372 - val_accuracy: 0.6389\n",
      "Epoch 897/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0670 - accuracy: 0.9818 - val_loss: 1.8710 - val_accuracy: 0.6597\n",
      "Epoch 898/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0926 - accuracy: 0.9679 - val_loss: 1.8824 - val_accuracy: 0.6181\n",
      "Epoch 899/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0743 - accuracy: 0.9722 - val_loss: 1.8687 - val_accuracy: 0.6354\n",
      "Epoch 900/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0911 - accuracy: 0.9705 - val_loss: 1.8074 - val_accuracy: 0.6458\n",
      "Epoch 901/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0791 - accuracy: 0.9714 - val_loss: 1.9105 - val_accuracy: 0.6146\n",
      "Epoch 902/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0748 - accuracy: 0.9740 - val_loss: 1.8376 - val_accuracy: 0.6250\n",
      "Epoch 903/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0861 - accuracy: 0.9766 - val_loss: 1.9578 - val_accuracy: 0.6215\n",
      "Epoch 904/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1041 - accuracy: 0.9714 - val_loss: 1.8877 - val_accuracy: 0.6250\n",
      "Epoch 905/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0809 - accuracy: 0.9792 - val_loss: 1.8906 - val_accuracy: 0.6076\n",
      "Epoch 906/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0798 - accuracy: 0.9792 - val_loss: 1.8494 - val_accuracy: 0.6458\n",
      "Epoch 907/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0819 - accuracy: 0.9722 - val_loss: 1.8482 - val_accuracy: 0.6285\n",
      "Epoch 908/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0839 - accuracy: 0.9714 - val_loss: 1.8306 - val_accuracy: 0.6354\n",
      "Epoch 909/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0861 - accuracy: 0.9670 - val_loss: 1.9202 - val_accuracy: 0.6181\n",
      "Epoch 910/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0716 - accuracy: 0.9757 - val_loss: 1.7798 - val_accuracy: 0.6354\n",
      "Epoch 911/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0735 - accuracy: 0.9766 - val_loss: 1.9097 - val_accuracy: 0.6181\n",
      "Epoch 912/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0850 - accuracy: 0.9644 - val_loss: 1.8607 - val_accuracy: 0.6181\n",
      "Epoch 913/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0817 - accuracy: 0.9722 - val_loss: 1.8612 - val_accuracy: 0.6424\n",
      "Epoch 914/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0732 - accuracy: 0.9835 - val_loss: 1.8207 - val_accuracy: 0.6354\n",
      "Epoch 915/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0826 - accuracy: 0.9722 - val_loss: 1.9157 - val_accuracy: 0.6285\n",
      "Epoch 916/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0759 - accuracy: 0.9774 - val_loss: 1.7990 - val_accuracy: 0.6215\n",
      "Epoch 917/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0826 - accuracy: 0.9748 - val_loss: 1.8480 - val_accuracy: 0.6389\n",
      "Epoch 918/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0765 - accuracy: 0.9731 - val_loss: 1.9782 - val_accuracy: 0.6215\n",
      "Epoch 919/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0752 - accuracy: 0.9740 - val_loss: 1.9074 - val_accuracy: 0.6250\n",
      "Epoch 920/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0720 - accuracy: 0.9757 - val_loss: 1.8388 - val_accuracy: 0.6319\n",
      "Epoch 921/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0857 - accuracy: 0.9757 - val_loss: 1.8406 - val_accuracy: 0.6458\n",
      "Epoch 922/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0843 - accuracy: 0.9722 - val_loss: 1.8589 - val_accuracy: 0.6424\n",
      "Epoch 923/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0867 - accuracy: 0.9722 - val_loss: 1.8732 - val_accuracy: 0.6319\n",
      "Epoch 924/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0775 - accuracy: 0.9679 - val_loss: 1.9075 - val_accuracy: 0.6354\n",
      "Epoch 925/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0873 - accuracy: 0.9757 - val_loss: 1.9958 - val_accuracy: 0.6285\n",
      "Epoch 926/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0810 - accuracy: 0.9731 - val_loss: 2.0673 - val_accuracy: 0.6007\n",
      "Epoch 927/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0701 - accuracy: 0.9809 - val_loss: 1.8063 - val_accuracy: 0.6319\n",
      "Epoch 928/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0867 - accuracy: 0.9705 - val_loss: 1.8712 - val_accuracy: 0.6285\n",
      "Epoch 929/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0850 - accuracy: 0.9766 - val_loss: 1.7880 - val_accuracy: 0.6250\n",
      "Epoch 930/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0833 - accuracy: 0.9792 - val_loss: 1.8863 - val_accuracy: 0.6354\n",
      "Epoch 931/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0807 - accuracy: 0.9766 - val_loss: 1.8881 - val_accuracy: 0.6146\n",
      "Epoch 932/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0703 - accuracy: 0.9757 - val_loss: 1.9415 - val_accuracy: 0.6076\n",
      "Epoch 933/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0993 - accuracy: 0.9661 - val_loss: 2.1215 - val_accuracy: 0.6111\n",
      "Epoch 934/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0610 - accuracy: 0.9809 - val_loss: 1.8967 - val_accuracy: 0.6424\n",
      "Epoch 935/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0774 - accuracy: 0.9696 - val_loss: 1.9827 - val_accuracy: 0.6181\n",
      "Epoch 936/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0805 - accuracy: 0.9661 - val_loss: 1.9113 - val_accuracy: 0.6146\n",
      "Epoch 937/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0723 - accuracy: 0.9740 - val_loss: 1.8644 - val_accuracy: 0.6424\n",
      "Epoch 938/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0883 - accuracy: 0.9740 - val_loss: 1.9002 - val_accuracy: 0.6493\n",
      "Epoch 939/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0785 - accuracy: 0.9748 - val_loss: 1.9389 - val_accuracy: 0.6215\n",
      "Epoch 940/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0614 - accuracy: 0.9809 - val_loss: 1.9305 - val_accuracy: 0.6389\n",
      "Epoch 941/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0773 - accuracy: 0.9766 - val_loss: 1.9150 - val_accuracy: 0.6354\n",
      "Epoch 942/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0750 - accuracy: 0.9696 - val_loss: 1.9229 - val_accuracy: 0.6285\n",
      "Epoch 943/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0948 - accuracy: 0.9722 - val_loss: 1.9094 - val_accuracy: 0.6354\n",
      "Epoch 944/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0740 - accuracy: 0.9792 - val_loss: 1.8734 - val_accuracy: 0.6528\n",
      "Epoch 945/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0708 - accuracy: 0.9740 - val_loss: 2.0040 - val_accuracy: 0.6354\n",
      "Epoch 946/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0788 - accuracy: 0.9740 - val_loss: 1.9442 - val_accuracy: 0.6250\n",
      "Epoch 947/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0693 - accuracy: 0.9792 - val_loss: 1.8582 - val_accuracy: 0.6424\n",
      "Epoch 948/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0616 - accuracy: 0.9826 - val_loss: 1.8922 - val_accuracy: 0.6285\n",
      "Epoch 949/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0761 - accuracy: 0.9740 - val_loss: 1.8954 - val_accuracy: 0.6319\n",
      "Epoch 950/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0816 - accuracy: 0.9757 - val_loss: 1.9405 - val_accuracy: 0.6354\n",
      "Epoch 951/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0991 - accuracy: 0.9688 - val_loss: 1.8650 - val_accuracy: 0.6493\n",
      "Epoch 952/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0801 - accuracy: 0.9748 - val_loss: 1.9075 - val_accuracy: 0.6424\n",
      "Epoch 953/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0760 - accuracy: 0.9740 - val_loss: 1.9542 - val_accuracy: 0.6493\n",
      "Epoch 954/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0912 - accuracy: 0.9714 - val_loss: 1.9709 - val_accuracy: 0.6250\n",
      "Epoch 955/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0638 - accuracy: 0.9826 - val_loss: 1.8199 - val_accuracy: 0.6319\n",
      "Epoch 956/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1026 - accuracy: 0.9688 - val_loss: 1.9004 - val_accuracy: 0.6285\n",
      "Epoch 957/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0840 - accuracy: 0.9688 - val_loss: 1.9800 - val_accuracy: 0.6146\n",
      "Epoch 958/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0679 - accuracy: 0.9818 - val_loss: 1.9012 - val_accuracy: 0.6389\n",
      "Epoch 959/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0736 - accuracy: 0.9757 - val_loss: 1.9445 - val_accuracy: 0.6250\n",
      "Epoch 960/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0822 - accuracy: 0.9705 - val_loss: 1.9106 - val_accuracy: 0.6111\n",
      "Epoch 961/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0761 - accuracy: 0.9722 - val_loss: 1.9460 - val_accuracy: 0.6424\n",
      "Epoch 962/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0651 - accuracy: 0.9766 - val_loss: 1.9942 - val_accuracy: 0.6319\n",
      "Epoch 963/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0914 - accuracy: 0.9731 - val_loss: 1.8882 - val_accuracy: 0.6146\n",
      "Epoch 964/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0785 - accuracy: 0.9722 - val_loss: 1.9079 - val_accuracy: 0.6458\n",
      "Epoch 965/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0703 - accuracy: 0.9783 - val_loss: 1.9268 - val_accuracy: 0.6285\n",
      "Epoch 966/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0685 - accuracy: 0.9800 - val_loss: 1.9945 - val_accuracy: 0.6285\n",
      "Epoch 967/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0641 - accuracy: 0.9826 - val_loss: 2.0035 - val_accuracy: 0.6458\n",
      "Epoch 968/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0728 - accuracy: 0.9714 - val_loss: 1.8831 - val_accuracy: 0.6319\n",
      "Epoch 969/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0835 - accuracy: 0.9731 - val_loss: 1.9855 - val_accuracy: 0.6354\n",
      "Epoch 970/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0779 - accuracy: 0.9774 - val_loss: 1.9091 - val_accuracy: 0.6458\n",
      "Epoch 971/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0711 - accuracy: 0.9757 - val_loss: 1.8816 - val_accuracy: 0.6285\n",
      "Epoch 972/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0747 - accuracy: 0.9722 - val_loss: 1.9490 - val_accuracy: 0.6354\n",
      "Epoch 973/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0819 - accuracy: 0.9714 - val_loss: 1.8182 - val_accuracy: 0.6424\n",
      "Epoch 974/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0621 - accuracy: 0.9826 - val_loss: 1.9208 - val_accuracy: 0.6285\n",
      "Epoch 975/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0822 - accuracy: 0.9757 - val_loss: 1.9563 - val_accuracy: 0.6250\n",
      "Epoch 976/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0617 - accuracy: 0.9826 - val_loss: 1.9222 - val_accuracy: 0.6285\n",
      "Epoch 977/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0881 - accuracy: 0.9670 - val_loss: 1.8389 - val_accuracy: 0.6181\n",
      "Epoch 978/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0806 - accuracy: 0.9731 - val_loss: 1.9138 - val_accuracy: 0.6076\n",
      "Epoch 979/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0837 - accuracy: 0.9696 - val_loss: 2.0214 - val_accuracy: 0.6181\n",
      "Epoch 980/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0858 - accuracy: 0.9740 - val_loss: 1.9003 - val_accuracy: 0.6181\n",
      "Epoch 981/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0622 - accuracy: 0.9792 - val_loss: 1.8910 - val_accuracy: 0.6285\n",
      "Epoch 982/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0611 - accuracy: 0.9800 - val_loss: 1.8289 - val_accuracy: 0.6493\n",
      "Epoch 983/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0751 - accuracy: 0.9792 - val_loss: 2.1435 - val_accuracy: 0.6076\n",
      "Epoch 984/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1028 - accuracy: 0.9714 - val_loss: 1.8578 - val_accuracy: 0.6424\n",
      "Epoch 985/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0635 - accuracy: 0.9774 - val_loss: 1.9091 - val_accuracy: 0.6424\n",
      "Epoch 986/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0847 - accuracy: 0.9705 - val_loss: 1.8587 - val_accuracy: 0.6319\n",
      "Epoch 987/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0777 - accuracy: 0.9722 - val_loss: 1.8764 - val_accuracy: 0.6250\n",
      "Epoch 988/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0723 - accuracy: 0.9774 - val_loss: 1.8929 - val_accuracy: 0.6389\n",
      "Epoch 989/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0771 - accuracy: 0.9748 - val_loss: 1.9230 - val_accuracy: 0.6215\n",
      "Epoch 990/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0637 - accuracy: 0.9809 - val_loss: 1.9196 - val_accuracy: 0.6458\n",
      "Epoch 991/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0533 - accuracy: 0.9835 - val_loss: 1.9350 - val_accuracy: 0.6493\n",
      "Epoch 992/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0823 - accuracy: 0.9766 - val_loss: 1.8310 - val_accuracy: 0.6146\n",
      "Epoch 993/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0822 - accuracy: 0.9705 - val_loss: 1.9575 - val_accuracy: 0.6215\n",
      "Epoch 994/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0465 - accuracy: 0.9887 - val_loss: 1.9925 - val_accuracy: 0.6215\n",
      "Epoch 995/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0614 - accuracy: 0.9800 - val_loss: 1.8199 - val_accuracy: 0.6389\n",
      "Epoch 996/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0624 - accuracy: 0.9818 - val_loss: 1.9171 - val_accuracy: 0.6389\n",
      "Epoch 997/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0734 - accuracy: 0.9757 - val_loss: 1.7929 - val_accuracy: 0.6424\n",
      "Epoch 998/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0752 - accuracy: 0.9696 - val_loss: 1.9796 - val_accuracy: 0.6493\n",
      "Epoch 999/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0610 - accuracy: 0.9792 - val_loss: 1.8664 - val_accuracy: 0.6285\n",
      "Epoch 1000/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0664 - accuracy: 0.9766 - val_loss: 1.9156 - val_accuracy: 0.6458\n",
      "Epoch 1001/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0631 - accuracy: 0.9783 - val_loss: 1.9988 - val_accuracy: 0.6389\n",
      "Epoch 1002/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0653 - accuracy: 0.9766 - val_loss: 2.0866 - val_accuracy: 0.6042\n",
      "Epoch 1003/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0742 - accuracy: 0.9748 - val_loss: 1.9092 - val_accuracy: 0.6424\n",
      "Epoch 1004/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0705 - accuracy: 0.9783 - val_loss: 1.9635 - val_accuracy: 0.6076\n",
      "Epoch 1005/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0713 - accuracy: 0.9766 - val_loss: 1.9022 - val_accuracy: 0.6181\n",
      "Epoch 1006/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0900 - accuracy: 0.9679 - val_loss: 1.9659 - val_accuracy: 0.5972\n",
      "Epoch 1007/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0678 - accuracy: 0.9757 - val_loss: 1.8978 - val_accuracy: 0.6389\n",
      "Epoch 1008/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0604 - accuracy: 0.9818 - val_loss: 1.8670 - val_accuracy: 0.6250\n",
      "Epoch 1009/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0806 - accuracy: 0.9731 - val_loss: 1.8394 - val_accuracy: 0.6458\n",
      "Epoch 1010/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0620 - accuracy: 0.9826 - val_loss: 1.9633 - val_accuracy: 0.6215\n",
      "Epoch 1011/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0721 - accuracy: 0.9809 - val_loss: 1.9985 - val_accuracy: 0.6215\n",
      "Epoch 1012/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0792 - accuracy: 0.9731 - val_loss: 1.8763 - val_accuracy: 0.6215\n",
      "Epoch 1013/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0605 - accuracy: 0.9809 - val_loss: 1.9462 - val_accuracy: 0.6354\n",
      "Epoch 1014/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0848 - accuracy: 0.9740 - val_loss: 1.8906 - val_accuracy: 0.6354\n",
      "Epoch 1015/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0667 - accuracy: 0.9800 - val_loss: 1.9236 - val_accuracy: 0.6493\n",
      "Epoch 1016/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0782 - accuracy: 0.9731 - val_loss: 1.8204 - val_accuracy: 0.6319\n",
      "Epoch 1017/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0607 - accuracy: 0.9826 - val_loss: 1.9714 - val_accuracy: 0.6215\n",
      "Epoch 1018/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0714 - accuracy: 0.9800 - val_loss: 1.8793 - val_accuracy: 0.6458\n",
      "Epoch 1019/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0635 - accuracy: 0.9809 - val_loss: 2.0205 - val_accuracy: 0.5868\n",
      "Epoch 1020/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0753 - accuracy: 0.9757 - val_loss: 1.9745 - val_accuracy: 0.6250\n",
      "Epoch 1021/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0825 - accuracy: 0.9748 - val_loss: 1.9199 - val_accuracy: 0.6181\n",
      "Epoch 1022/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0634 - accuracy: 0.9800 - val_loss: 1.9175 - val_accuracy: 0.6493\n",
      "Epoch 1023/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0569 - accuracy: 0.9835 - val_loss: 2.0130 - val_accuracy: 0.6458\n",
      "Epoch 1024/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0851 - accuracy: 0.9731 - val_loss: 1.9999 - val_accuracy: 0.6458\n",
      "Epoch 1025/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 1.9149 - val_accuracy: 0.6319\n",
      "Epoch 1026/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0604 - accuracy: 0.9818 - val_loss: 1.9777 - val_accuracy: 0.6319\n",
      "Epoch 1027/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0863 - accuracy: 0.9722 - val_loss: 1.9204 - val_accuracy: 0.6146\n",
      "Epoch 1028/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0605 - accuracy: 0.9800 - val_loss: 1.9450 - val_accuracy: 0.6528\n",
      "Epoch 1029/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0744 - accuracy: 0.9731 - val_loss: 2.0045 - val_accuracy: 0.6250\n",
      "Epoch 1030/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0645 - accuracy: 0.9792 - val_loss: 1.9471 - val_accuracy: 0.6354\n",
      "Epoch 1031/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0754 - accuracy: 0.9722 - val_loss: 1.9862 - val_accuracy: 0.6285\n",
      "Epoch 1032/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0734 - accuracy: 0.9731 - val_loss: 1.9743 - val_accuracy: 0.6458\n",
      "Epoch 1033/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0675 - accuracy: 0.9757 - val_loss: 2.0050 - val_accuracy: 0.6354\n",
      "Epoch 1034/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0789 - accuracy: 0.9731 - val_loss: 1.9515 - val_accuracy: 0.6250\n",
      "Epoch 1035/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0620 - accuracy: 0.9783 - val_loss: 1.9949 - val_accuracy: 0.6215\n",
      "Epoch 1036/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0717 - accuracy: 0.9766 - val_loss: 2.0503 - val_accuracy: 0.6597\n",
      "Epoch 1037/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0629 - accuracy: 0.9800 - val_loss: 1.9792 - val_accuracy: 0.6250\n",
      "Epoch 1038/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0699 - accuracy: 0.9757 - val_loss: 1.9787 - val_accuracy: 0.6389\n",
      "Epoch 1039/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0671 - accuracy: 0.9783 - val_loss: 2.0051 - val_accuracy: 0.6389\n",
      "Epoch 1040/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0616 - accuracy: 0.9809 - val_loss: 2.0425 - val_accuracy: 0.6424\n",
      "Epoch 1041/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0644 - accuracy: 0.9783 - val_loss: 1.9969 - val_accuracy: 0.6076\n",
      "Epoch 1042/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0603 - accuracy: 0.9818 - val_loss: 1.9937 - val_accuracy: 0.6493\n",
      "Epoch 1043/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 2.0574 - val_accuracy: 0.6493\n",
      "Epoch 1044/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0807 - accuracy: 0.9740 - val_loss: 2.0625 - val_accuracy: 0.6319\n",
      "Epoch 1045/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0561 - accuracy: 0.9809 - val_loss: 2.0658 - val_accuracy: 0.6424\n",
      "Epoch 1046/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0705 - accuracy: 0.9748 - val_loss: 1.9324 - val_accuracy: 0.6528\n",
      "Epoch 1047/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0665 - accuracy: 0.9792 - val_loss: 1.8954 - val_accuracy: 0.6389\n",
      "Epoch 1048/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0593 - accuracy: 0.9783 - val_loss: 1.9676 - val_accuracy: 0.6389\n",
      "Epoch 1049/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0858 - accuracy: 0.9653 - val_loss: 1.9313 - val_accuracy: 0.6250\n",
      "Epoch 1050/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0707 - accuracy: 0.9766 - val_loss: 1.9914 - val_accuracy: 0.6354\n",
      "Epoch 1051/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0830 - accuracy: 0.9740 - val_loss: 1.9711 - val_accuracy: 0.6354\n",
      "Epoch 1052/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0698 - accuracy: 0.9792 - val_loss: 1.9390 - val_accuracy: 0.6354\n",
      "Epoch 1053/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0518 - accuracy: 0.9826 - val_loss: 2.0861 - val_accuracy: 0.6111\n",
      "Epoch 1054/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0536 - accuracy: 0.9861 - val_loss: 2.0180 - val_accuracy: 0.6354\n",
      "Epoch 1055/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0654 - accuracy: 0.9800 - val_loss: 2.0546 - val_accuracy: 0.6285\n",
      "Epoch 1056/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0722 - accuracy: 0.9757 - val_loss: 2.0636 - val_accuracy: 0.6146\n",
      "Epoch 1057/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0886 - accuracy: 0.9731 - val_loss: 1.9794 - val_accuracy: 0.6146\n",
      "Epoch 1058/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0850 - accuracy: 0.9748 - val_loss: 2.1388 - val_accuracy: 0.6146\n",
      "Epoch 1059/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0696 - accuracy: 0.9731 - val_loss: 1.9584 - val_accuracy: 0.6250\n",
      "Epoch 1060/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0861 - accuracy: 0.9679 - val_loss: 2.0031 - val_accuracy: 0.6458\n",
      "Epoch 1061/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0627 - accuracy: 0.9792 - val_loss: 2.0667 - val_accuracy: 0.6354\n",
      "Epoch 1062/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0699 - accuracy: 0.9757 - val_loss: 2.0497 - val_accuracy: 0.6458\n",
      "Epoch 1063/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0671 - accuracy: 0.9740 - val_loss: 1.9981 - val_accuracy: 0.6215\n",
      "Epoch 1064/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0804 - accuracy: 0.9740 - val_loss: 1.9396 - val_accuracy: 0.6562\n",
      "Epoch 1065/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0847 - accuracy: 0.9740 - val_loss: 2.0907 - val_accuracy: 0.6181\n",
      "Epoch 1066/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0650 - accuracy: 0.9809 - val_loss: 2.0067 - val_accuracy: 0.6354\n",
      "Epoch 1067/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0685 - accuracy: 0.9783 - val_loss: 2.1522 - val_accuracy: 0.5972\n",
      "Epoch 1068/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0705 - accuracy: 0.9766 - val_loss: 2.0477 - val_accuracy: 0.6250\n",
      "Epoch 1069/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0521 - accuracy: 0.9861 - val_loss: 2.0395 - val_accuracy: 0.6250\n",
      "Epoch 1070/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0658 - accuracy: 0.9774 - val_loss: 1.9631 - val_accuracy: 0.6354\n",
      "Epoch 1071/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0729 - accuracy: 0.9774 - val_loss: 1.9240 - val_accuracy: 0.6354\n",
      "Epoch 1072/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0448 - accuracy: 0.9852 - val_loss: 1.9353 - val_accuracy: 0.6250\n",
      "Epoch 1073/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0753 - accuracy: 0.9766 - val_loss: 1.9348 - val_accuracy: 0.6111\n",
      "Epoch 1074/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0598 - accuracy: 0.9818 - val_loss: 1.9828 - val_accuracy: 0.6389\n",
      "Epoch 1075/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0519 - accuracy: 0.9800 - val_loss: 1.9673 - val_accuracy: 0.6389\n",
      "Epoch 1076/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0575 - accuracy: 0.9826 - val_loss: 2.1235 - val_accuracy: 0.6076\n",
      "Epoch 1077/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0560 - accuracy: 0.9826 - val_loss: 2.0766 - val_accuracy: 0.6250\n",
      "Epoch 1078/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0685 - accuracy: 0.9774 - val_loss: 2.1737 - val_accuracy: 0.6181\n",
      "Epoch 1079/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0675 - accuracy: 0.9731 - val_loss: 2.0743 - val_accuracy: 0.6146\n",
      "Epoch 1080/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0620 - accuracy: 0.9826 - val_loss: 1.9106 - val_accuracy: 0.6319\n",
      "Epoch 1081/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0554 - accuracy: 0.9852 - val_loss: 1.9808 - val_accuracy: 0.6354\n",
      "Epoch 1082/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0603 - accuracy: 0.9861 - val_loss: 1.9253 - val_accuracy: 0.6250\n",
      "Epoch 1083/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0576 - accuracy: 0.9835 - val_loss: 2.1210 - val_accuracy: 0.6181\n",
      "Epoch 1084/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0683 - accuracy: 0.9722 - val_loss: 1.9756 - val_accuracy: 0.6319\n",
      "Epoch 1085/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0634 - accuracy: 0.9792 - val_loss: 1.8487 - val_accuracy: 0.6458\n",
      "Epoch 1086/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0643 - accuracy: 0.9818 - val_loss: 1.9621 - val_accuracy: 0.6458\n",
      "Epoch 1087/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0748 - accuracy: 0.9783 - val_loss: 2.0055 - val_accuracy: 0.6389\n",
      "Epoch 1088/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0648 - accuracy: 0.9774 - val_loss: 1.9482 - val_accuracy: 0.6250\n",
      "Epoch 1089/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0529 - accuracy: 0.9852 - val_loss: 2.0813 - val_accuracy: 0.6285\n",
      "Epoch 1090/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0644 - accuracy: 0.9792 - val_loss: 2.1133 - val_accuracy: 0.6181\n",
      "Epoch 1091/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0575 - accuracy: 0.9792 - val_loss: 2.2312 - val_accuracy: 0.6076\n",
      "Epoch 1092/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0615 - accuracy: 0.9809 - val_loss: 2.1240 - val_accuracy: 0.6250\n",
      "Epoch 1093/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 2.0333 - val_accuracy: 0.6528\n",
      "Epoch 1094/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0591 - accuracy: 0.9809 - val_loss: 1.9768 - val_accuracy: 0.6354\n",
      "Epoch 1095/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0820 - accuracy: 0.9688 - val_loss: 2.0198 - val_accuracy: 0.6319\n",
      "Epoch 1096/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0557 - accuracy: 0.9800 - val_loss: 1.9698 - val_accuracy: 0.6250\n",
      "Epoch 1097/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0600 - accuracy: 0.9844 - val_loss: 2.1815 - val_accuracy: 0.6215\n",
      "Epoch 1098/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0645 - accuracy: 0.9783 - val_loss: 1.9626 - val_accuracy: 0.6250\n",
      "Epoch 1099/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0576 - accuracy: 0.9826 - val_loss: 1.9993 - val_accuracy: 0.6354\n",
      "Epoch 1100/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0709 - accuracy: 0.9800 - val_loss: 2.0240 - val_accuracy: 0.6111\n",
      "Epoch 1101/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0591 - accuracy: 0.9818 - val_loss: 2.0103 - val_accuracy: 0.6354\n",
      "Epoch 1102/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0602 - accuracy: 0.9835 - val_loss: 2.1276 - val_accuracy: 0.6250\n",
      "Epoch 1103/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0593 - accuracy: 0.9826 - val_loss: 2.0903 - val_accuracy: 0.6076\n",
      "Epoch 1104/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0774 - accuracy: 0.9731 - val_loss: 1.9417 - val_accuracy: 0.6562\n",
      "Epoch 1105/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0656 - accuracy: 0.9774 - val_loss: 1.9619 - val_accuracy: 0.6389\n",
      "Epoch 1106/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0701 - accuracy: 0.9731 - val_loss: 2.1343 - val_accuracy: 0.6215\n",
      "Epoch 1107/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0549 - accuracy: 0.9826 - val_loss: 1.9353 - val_accuracy: 0.6389\n",
      "Epoch 1108/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0793 - accuracy: 0.9783 - val_loss: 2.0200 - val_accuracy: 0.6319\n",
      "Epoch 1109/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0611 - accuracy: 0.9809 - val_loss: 2.0503 - val_accuracy: 0.6111\n",
      "Epoch 1110/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0607 - accuracy: 0.9774 - val_loss: 2.0389 - val_accuracy: 0.6319\n",
      "Epoch 1111/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0691 - accuracy: 0.9852 - val_loss: 2.0043 - val_accuracy: 0.6424\n",
      "Epoch 1112/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0801 - accuracy: 0.9748 - val_loss: 1.9914 - val_accuracy: 0.6354\n",
      "Epoch 1113/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0653 - accuracy: 0.9748 - val_loss: 2.0952 - val_accuracy: 0.6319\n",
      "Epoch 1114/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0615 - accuracy: 0.9800 - val_loss: 2.0742 - val_accuracy: 0.6250\n",
      "Epoch 1115/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0577 - accuracy: 0.9792 - val_loss: 1.9916 - val_accuracy: 0.6458\n",
      "Epoch 1116/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0819 - accuracy: 0.9731 - val_loss: 1.9537 - val_accuracy: 0.6528\n",
      "Epoch 1117/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0550 - accuracy: 0.9818 - val_loss: 1.9627 - val_accuracy: 0.6285\n",
      "Epoch 1118/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0692 - accuracy: 0.9757 - val_loss: 2.1409 - val_accuracy: 0.6146\n",
      "Epoch 1119/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0869 - accuracy: 0.9696 - val_loss: 2.0638 - val_accuracy: 0.6354\n",
      "Epoch 1120/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0619 - accuracy: 0.9826 - val_loss: 1.9914 - val_accuracy: 0.6215\n",
      "Epoch 1121/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 2.2996 - val_accuracy: 0.5833\n",
      "Epoch 1122/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0550 - accuracy: 0.9809 - val_loss: 2.0959 - val_accuracy: 0.6215\n",
      "Epoch 1123/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 2.0096 - val_accuracy: 0.6354\n",
      "Epoch 1124/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0415 - accuracy: 0.9913 - val_loss: 2.1085 - val_accuracy: 0.5972\n",
      "Epoch 1125/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0581 - accuracy: 0.9757 - val_loss: 2.1171 - val_accuracy: 0.6181\n",
      "Epoch 1126/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0491 - accuracy: 0.9826 - val_loss: 2.0757 - val_accuracy: 0.6562\n",
      "Epoch 1127/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0502 - accuracy: 0.9818 - val_loss: 1.9609 - val_accuracy: 0.6562\n",
      "Epoch 1128/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0563 - accuracy: 0.9783 - val_loss: 2.0525 - val_accuracy: 0.6319\n",
      "Epoch 1129/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0537 - accuracy: 0.9861 - val_loss: 2.0846 - val_accuracy: 0.6493\n",
      "Epoch 1130/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0498 - accuracy: 0.9852 - val_loss: 2.1108 - val_accuracy: 0.6319\n",
      "Epoch 1131/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0541 - accuracy: 0.9818 - val_loss: 2.1842 - val_accuracy: 0.6389\n",
      "Epoch 1132/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0609 - accuracy: 0.9818 - val_loss: 2.0556 - val_accuracy: 0.6250\n",
      "Epoch 1133/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0767 - accuracy: 0.9748 - val_loss: 2.0872 - val_accuracy: 0.6076\n",
      "Epoch 1134/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0665 - accuracy: 0.9774 - val_loss: 2.0772 - val_accuracy: 0.6181\n",
      "Epoch 1135/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0660 - accuracy: 0.9783 - val_loss: 1.9760 - val_accuracy: 0.6250\n",
      "Epoch 1136/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0539 - accuracy: 0.9852 - val_loss: 2.0532 - val_accuracy: 0.6215\n",
      "Epoch 1137/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0475 - accuracy: 0.9870 - val_loss: 2.0402 - val_accuracy: 0.6597\n",
      "Epoch 1138/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0614 - accuracy: 0.9809 - val_loss: 2.0874 - val_accuracy: 0.6181\n",
      "Epoch 1139/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0600 - accuracy: 0.9835 - val_loss: 1.9676 - val_accuracy: 0.6354\n",
      "Epoch 1140/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0497 - accuracy: 0.9818 - val_loss: 1.9814 - val_accuracy: 0.6319\n",
      "Epoch 1141/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0649 - accuracy: 0.9757 - val_loss: 2.0896 - val_accuracy: 0.6319\n",
      "Epoch 1142/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0661 - accuracy: 0.9783 - val_loss: 2.1211 - val_accuracy: 0.6250\n",
      "Epoch 1143/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0622 - accuracy: 0.9800 - val_loss: 2.1161 - val_accuracy: 0.6250\n",
      "Epoch 1144/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0615 - accuracy: 0.9774 - val_loss: 2.0299 - val_accuracy: 0.6354\n",
      "Epoch 1145/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 2.1106 - val_accuracy: 0.6319\n",
      "Epoch 1146/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0588 - accuracy: 0.9818 - val_loss: 2.0037 - val_accuracy: 0.6354\n",
      "Epoch 1147/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0580 - accuracy: 0.9835 - val_loss: 2.0186 - val_accuracy: 0.6493\n",
      "Epoch 1148/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0550 - accuracy: 0.9826 - val_loss: 1.9587 - val_accuracy: 0.6562\n",
      "Epoch 1149/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0523 - accuracy: 0.9835 - val_loss: 2.0393 - val_accuracy: 0.6285\n",
      "Epoch 1150/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0482 - accuracy: 0.9835 - val_loss: 2.0926 - val_accuracy: 0.6250\n",
      "Epoch 1151/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0509 - accuracy: 0.9844 - val_loss: 2.1546 - val_accuracy: 0.6215\n",
      "Epoch 1152/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0522 - accuracy: 0.9826 - val_loss: 2.1800 - val_accuracy: 0.6111\n",
      "Epoch 1153/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0604 - accuracy: 0.9870 - val_loss: 2.2138 - val_accuracy: 0.6319\n",
      "Epoch 1154/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0757 - accuracy: 0.9748 - val_loss: 2.0623 - val_accuracy: 0.6528\n",
      "Epoch 1155/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0520 - accuracy: 0.9861 - val_loss: 2.0111 - val_accuracy: 0.6319\n",
      "Epoch 1156/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0716 - accuracy: 0.9740 - val_loss: 2.1753 - val_accuracy: 0.6076\n",
      "Epoch 1157/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 2.0182 - val_accuracy: 0.6389\n",
      "Epoch 1158/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0614 - accuracy: 0.9809 - val_loss: 2.0144 - val_accuracy: 0.6215\n",
      "Epoch 1159/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0702 - accuracy: 0.9809 - val_loss: 2.1908 - val_accuracy: 0.6354\n",
      "Epoch 1160/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0691 - accuracy: 0.9809 - val_loss: 2.2434 - val_accuracy: 0.6007\n",
      "Epoch 1161/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0629 - accuracy: 0.9783 - val_loss: 2.1731 - val_accuracy: 0.6319\n",
      "Epoch 1162/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0432 - accuracy: 0.9887 - val_loss: 2.0896 - val_accuracy: 0.6562\n",
      "Epoch 1163/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0489 - accuracy: 0.9835 - val_loss: 2.1941 - val_accuracy: 0.6146\n",
      "Epoch 1164/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0676 - accuracy: 0.9818 - val_loss: 2.0771 - val_accuracy: 0.6354\n",
      "Epoch 1165/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0521 - accuracy: 0.9826 - val_loss: 2.1282 - val_accuracy: 0.6076\n",
      "Epoch 1166/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0591 - accuracy: 0.9792 - val_loss: 2.0421 - val_accuracy: 0.6354\n",
      "Epoch 1167/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0802 - accuracy: 0.9748 - val_loss: 2.1249 - val_accuracy: 0.6285\n",
      "Epoch 1168/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0604 - accuracy: 0.9844 - val_loss: 1.9992 - val_accuracy: 0.6493\n",
      "Epoch 1169/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0447 - accuracy: 0.9852 - val_loss: 2.0152 - val_accuracy: 0.6528\n",
      "Epoch 1170/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0460 - accuracy: 0.9870 - val_loss: 2.0422 - val_accuracy: 0.6250\n",
      "Epoch 1171/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0591 - accuracy: 0.9766 - val_loss: 2.0693 - val_accuracy: 0.6389\n",
      "Epoch 1172/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0606 - accuracy: 0.9826 - val_loss: 2.0980 - val_accuracy: 0.6389\n",
      "Epoch 1173/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0657 - accuracy: 0.9748 - val_loss: 2.0820 - val_accuracy: 0.6250\n",
      "Epoch 1174/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 2.0203 - val_accuracy: 0.6285\n",
      "Epoch 1175/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0591 - accuracy: 0.9809 - val_loss: 2.1574 - val_accuracy: 0.6181\n",
      "Epoch 1176/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0515 - accuracy: 0.9800 - val_loss: 2.1232 - val_accuracy: 0.6319\n",
      "Epoch 1177/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0555 - accuracy: 0.9818 - val_loss: 2.0805 - val_accuracy: 0.6354\n",
      "Epoch 1178/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0466 - accuracy: 0.9844 - val_loss: 2.2204 - val_accuracy: 0.6181\n",
      "Epoch 1179/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0741 - accuracy: 0.9722 - val_loss: 2.0195 - val_accuracy: 0.6493\n",
      "Epoch 1180/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0485 - accuracy: 0.9852 - val_loss: 2.1540 - val_accuracy: 0.6319\n",
      "Epoch 1181/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0612 - accuracy: 0.9826 - val_loss: 2.1435 - val_accuracy: 0.6319\n",
      "Epoch 1182/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0538 - accuracy: 0.9852 - val_loss: 2.1369 - val_accuracy: 0.6389\n",
      "Epoch 1183/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0694 - accuracy: 0.9740 - val_loss: 2.0223 - val_accuracy: 0.6458\n",
      "Epoch 1184/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0581 - accuracy: 0.9826 - val_loss: 2.1477 - val_accuracy: 0.6146\n",
      "Epoch 1185/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 2.1735 - val_accuracy: 0.6007\n",
      "Epoch 1186/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0551 - accuracy: 0.9818 - val_loss: 2.1788 - val_accuracy: 0.6146\n",
      "Epoch 1187/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0512 - accuracy: 0.9826 - val_loss: 2.1023 - val_accuracy: 0.6215\n",
      "Epoch 1188/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0518 - accuracy: 0.9818 - val_loss: 2.0771 - val_accuracy: 0.6285\n",
      "Epoch 1189/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0680 - accuracy: 0.9757 - val_loss: 2.2134 - val_accuracy: 0.6285\n",
      "Epoch 1190/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0591 - accuracy: 0.9792 - val_loss: 2.1397 - val_accuracy: 0.6285\n",
      "Epoch 1191/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0564 - accuracy: 0.9818 - val_loss: 2.0929 - val_accuracy: 0.6285\n",
      "Epoch 1192/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0470 - accuracy: 0.9870 - val_loss: 2.2043 - val_accuracy: 0.6285\n",
      "Epoch 1193/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0549 - accuracy: 0.9835 - val_loss: 2.1156 - val_accuracy: 0.6458\n",
      "Epoch 1194/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0569 - accuracy: 0.9826 - val_loss: 2.1146 - val_accuracy: 0.6354\n",
      "Epoch 1195/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 2.1293 - val_accuracy: 0.6076\n",
      "Epoch 1196/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0736 - accuracy: 0.9757 - val_loss: 2.1287 - val_accuracy: 0.6111\n",
      "Epoch 1197/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 2.1588 - val_accuracy: 0.6111\n",
      "Epoch 1198/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0428 - accuracy: 0.9861 - val_loss: 2.1356 - val_accuracy: 0.6215\n",
      "Epoch 1199/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0520 - accuracy: 0.9809 - val_loss: 2.0849 - val_accuracy: 0.6424\n",
      "Epoch 1200/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0634 - accuracy: 0.9792 - val_loss: 2.1383 - val_accuracy: 0.6354\n",
      "Epoch 1201/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0624 - accuracy: 0.9835 - val_loss: 2.1055 - val_accuracy: 0.6042\n",
      "Epoch 1202/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0570 - accuracy: 0.9844 - val_loss: 1.9845 - val_accuracy: 0.6458\n",
      "Epoch 1203/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0464 - accuracy: 0.9835 - val_loss: 2.0889 - val_accuracy: 0.6354\n",
      "Epoch 1204/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0591 - accuracy: 0.9792 - val_loss: 2.0255 - val_accuracy: 0.6319\n",
      "Epoch 1205/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0581 - accuracy: 0.9774 - val_loss: 2.0245 - val_accuracy: 0.6458\n",
      "Epoch 1206/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0585 - accuracy: 0.9809 - val_loss: 2.0945 - val_accuracy: 0.6562\n",
      "Epoch 1207/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0573 - accuracy: 0.9844 - val_loss: 2.1615 - val_accuracy: 0.6389\n",
      "Epoch 1208/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0536 - accuracy: 0.9800 - val_loss: 2.0920 - val_accuracy: 0.6285\n",
      "Epoch 1209/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0470 - accuracy: 0.9870 - val_loss: 2.1702 - val_accuracy: 0.6111\n",
      "Epoch 1210/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0429 - accuracy: 0.9844 - val_loss: 2.0575 - val_accuracy: 0.6181\n",
      "Epoch 1211/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0575 - accuracy: 0.9800 - val_loss: 2.0667 - val_accuracy: 0.6389\n",
      "Epoch 1212/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0555 - accuracy: 0.9800 - val_loss: 2.0700 - val_accuracy: 0.6458\n",
      "Epoch 1213/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0498 - accuracy: 0.9818 - val_loss: 2.1461 - val_accuracy: 0.6181\n",
      "Epoch 1214/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0713 - accuracy: 0.9757 - val_loss: 2.2512 - val_accuracy: 0.6458\n",
      "Epoch 1215/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0492 - accuracy: 0.9835 - val_loss: 2.3470 - val_accuracy: 0.6111\n",
      "Epoch 1216/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0533 - accuracy: 0.9792 - val_loss: 2.2381 - val_accuracy: 0.6181\n",
      "Epoch 1217/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 2.1752 - val_accuracy: 0.6285\n",
      "Epoch 1218/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0548 - accuracy: 0.9792 - val_loss: 2.1879 - val_accuracy: 0.6215\n",
      "Epoch 1219/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0492 - accuracy: 0.9870 - val_loss: 2.1436 - val_accuracy: 0.6146\n",
      "Epoch 1220/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0533 - accuracy: 0.9835 - val_loss: 2.2785 - val_accuracy: 0.6215\n",
      "Epoch 1221/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0766 - accuracy: 0.9740 - val_loss: 2.2112 - val_accuracy: 0.6250\n",
      "Epoch 1222/1300\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0619 - accuracy: 0.9783 - val_loss: 2.2032 - val_accuracy: 0.6389\n",
      "Epoch 1223/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0514 - accuracy: 0.9861 - val_loss: 2.0656 - val_accuracy: 0.6354\n",
      "Epoch 1224/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0516 - accuracy: 0.9852 - val_loss: 2.1365 - val_accuracy: 0.6354\n",
      "Epoch 1225/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0612 - accuracy: 0.9792 - val_loss: 2.2367 - val_accuracy: 0.6250\n",
      "Epoch 1226/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0571 - accuracy: 0.9800 - val_loss: 2.0826 - val_accuracy: 0.6146\n",
      "Epoch 1227/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0592 - accuracy: 0.9809 - val_loss: 2.1463 - val_accuracy: 0.6389\n",
      "Epoch 1228/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 2.1218 - val_accuracy: 0.6319\n",
      "Epoch 1229/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0566 - accuracy: 0.9835 - val_loss: 2.0898 - val_accuracy: 0.6285\n",
      "Epoch 1230/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0455 - accuracy: 0.9835 - val_loss: 2.0664 - val_accuracy: 0.6424\n",
      "Epoch 1231/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0557 - accuracy: 0.9774 - val_loss: 2.1550 - val_accuracy: 0.6181\n",
      "Epoch 1232/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0606 - accuracy: 0.9809 - val_loss: 2.3194 - val_accuracy: 0.6181\n",
      "Epoch 1233/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0585 - accuracy: 0.9783 - val_loss: 2.1571 - val_accuracy: 0.6354\n",
      "Epoch 1234/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0561 - accuracy: 0.9844 - val_loss: 2.0533 - val_accuracy: 0.6181\n",
      "Epoch 1235/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0452 - accuracy: 0.9878 - val_loss: 2.1822 - val_accuracy: 0.6111\n",
      "Epoch 1236/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0468 - accuracy: 0.9870 - val_loss: 2.1382 - val_accuracy: 0.6424\n",
      "Epoch 1237/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0558 - accuracy: 0.9774 - val_loss: 2.1249 - val_accuracy: 0.6285\n",
      "Epoch 1238/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0573 - accuracy: 0.9818 - val_loss: 1.9815 - val_accuracy: 0.6354\n",
      "Epoch 1239/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0456 - accuracy: 0.9852 - val_loss: 2.2381 - val_accuracy: 0.6181\n",
      "Epoch 1240/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 2.1767 - val_accuracy: 0.6424\n",
      "Epoch 1241/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0500 - accuracy: 0.9835 - val_loss: 2.0779 - val_accuracy: 0.6562\n",
      "Epoch 1242/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0448 - accuracy: 0.9870 - val_loss: 2.1376 - val_accuracy: 0.6319\n",
      "Epoch 1243/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 2.2257 - val_accuracy: 0.6458\n",
      "Epoch 1244/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0429 - accuracy: 0.9835 - val_loss: 2.1250 - val_accuracy: 0.6354\n",
      "Epoch 1245/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0511 - accuracy: 0.9835 - val_loss: 2.0968 - val_accuracy: 0.6632\n",
      "Epoch 1246/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0442 - accuracy: 0.9852 - val_loss: 2.2212 - val_accuracy: 0.6528\n",
      "Epoch 1247/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0584 - accuracy: 0.9792 - val_loss: 2.1383 - val_accuracy: 0.6597\n",
      "Epoch 1248/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0572 - accuracy: 0.9852 - val_loss: 2.1547 - val_accuracy: 0.6493\n",
      "Epoch 1249/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0527 - accuracy: 0.9809 - val_loss: 2.2161 - val_accuracy: 0.6354\n",
      "Epoch 1250/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0563 - accuracy: 0.9852 - val_loss: 2.2028 - val_accuracy: 0.6250\n",
      "Epoch 1251/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0595 - accuracy: 0.9809 - val_loss: 2.1722 - val_accuracy: 0.6319\n",
      "Epoch 1252/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 2.0774 - val_accuracy: 0.6701\n",
      "Epoch 1253/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0585 - accuracy: 0.9809 - val_loss: 2.0391 - val_accuracy: 0.6250\n",
      "Epoch 1254/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0621 - accuracy: 0.9818 - val_loss: 2.1853 - val_accuracy: 0.6076\n",
      "Epoch 1255/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 2.1941 - val_accuracy: 0.6319\n",
      "Epoch 1256/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0508 - accuracy: 0.9818 - val_loss: 2.3041 - val_accuracy: 0.6250\n",
      "Epoch 1257/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0570 - accuracy: 0.9792 - val_loss: 2.1065 - val_accuracy: 0.6250\n",
      "Epoch 1258/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0693 - accuracy: 0.9774 - val_loss: 2.0679 - val_accuracy: 0.6493\n",
      "Epoch 1259/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0557 - accuracy: 0.9835 - val_loss: 2.0941 - val_accuracy: 0.6562\n",
      "Epoch 1260/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0517 - accuracy: 0.9852 - val_loss: 2.1098 - val_accuracy: 0.6215\n",
      "Epoch 1261/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 2.2219 - val_accuracy: 0.6215\n",
      "Epoch 1262/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0656 - accuracy: 0.9809 - val_loss: 2.0867 - val_accuracy: 0.6181\n",
      "Epoch 1263/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0435 - accuracy: 0.9870 - val_loss: 2.1817 - val_accuracy: 0.6354\n",
      "Epoch 1264/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0584 - accuracy: 0.9792 - val_loss: 2.1753 - val_accuracy: 0.6319\n",
      "Epoch 1265/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0489 - accuracy: 0.9852 - val_loss: 2.0342 - val_accuracy: 0.6250\n",
      "Epoch 1266/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0478 - accuracy: 0.9800 - val_loss: 2.2591 - val_accuracy: 0.6354\n",
      "Epoch 1267/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 2.1348 - val_accuracy: 0.6285\n",
      "Epoch 1268/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 2.2600 - val_accuracy: 0.5972\n",
      "Epoch 1269/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0440 - accuracy: 0.9852 - val_loss: 2.1331 - val_accuracy: 0.6285\n",
      "Epoch 1270/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0720 - accuracy: 0.9757 - val_loss: 2.2267 - val_accuracy: 0.6354\n",
      "Epoch 1271/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0633 - accuracy: 0.9809 - val_loss: 2.2082 - val_accuracy: 0.6424\n",
      "Epoch 1272/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0578 - accuracy: 0.9774 - val_loss: 2.1683 - val_accuracy: 0.6354\n",
      "Epoch 1273/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0496 - accuracy: 0.9809 - val_loss: 2.1596 - val_accuracy: 0.6111\n",
      "Epoch 1274/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0419 - accuracy: 0.9852 - val_loss: 2.4588 - val_accuracy: 0.6146\n",
      "Epoch 1275/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 2.2703 - val_accuracy: 0.6111\n",
      "Epoch 1276/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0672 - accuracy: 0.9774 - val_loss: 2.1154 - val_accuracy: 0.6389\n",
      "Epoch 1277/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0611 - accuracy: 0.9818 - val_loss: 2.0026 - val_accuracy: 0.6528\n",
      "Epoch 1278/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0433 - accuracy: 0.9896 - val_loss: 2.0840 - val_accuracy: 0.6493\n",
      "Epoch 1279/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 2.2032 - val_accuracy: 0.6250\n",
      "Epoch 1280/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0593 - accuracy: 0.9826 - val_loss: 2.1077 - val_accuracy: 0.6250\n",
      "Epoch 1281/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0519 - accuracy: 0.9792 - val_loss: 2.1557 - val_accuracy: 0.6181\n",
      "Epoch 1282/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0508 - accuracy: 0.9861 - val_loss: 2.2043 - val_accuracy: 0.6458\n",
      "Epoch 1283/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0578 - accuracy: 0.9818 - val_loss: 2.1636 - val_accuracy: 0.6458\n",
      "Epoch 1284/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0657 - accuracy: 0.9800 - val_loss: 2.1595 - val_accuracy: 0.6319\n",
      "Epoch 1285/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0785 - accuracy: 0.9740 - val_loss: 2.1392 - val_accuracy: 0.6424\n",
      "Epoch 1286/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0573 - accuracy: 0.9783 - val_loss: 2.1742 - val_accuracy: 0.6215\n",
      "Epoch 1287/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0486 - accuracy: 0.9878 - val_loss: 2.1477 - val_accuracy: 0.6597\n",
      "Epoch 1288/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0448 - accuracy: 0.9844 - val_loss: 2.2587 - val_accuracy: 0.6250\n",
      "Epoch 1289/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0628 - accuracy: 0.9757 - val_loss: 2.2134 - val_accuracy: 0.6181\n",
      "Epoch 1290/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0485 - accuracy: 0.9800 - val_loss: 2.1491 - val_accuracy: 0.6424\n",
      "Epoch 1291/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0595 - accuracy: 0.9783 - val_loss: 2.1690 - val_accuracy: 0.6285\n",
      "Epoch 1292/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0468 - accuracy: 0.9852 - val_loss: 2.1777 - val_accuracy: 0.5972\n",
      "Epoch 1293/1300\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 2.2027 - val_accuracy: 0.6111\n",
      "Epoch 1294/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0453 - accuracy: 0.9826 - val_loss: 2.2522 - val_accuracy: 0.6285\n",
      "Epoch 1295/1300\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0628 - accuracy: 0.9844 - val_loss: 2.1781 - val_accuracy: 0.6250\n",
      "Epoch 1296/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0522 - accuracy: 0.9844 - val_loss: 2.0811 - val_accuracy: 0.6493\n",
      "Epoch 1297/1300\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0454 - accuracy: 0.9870 - val_loss: 2.2416 - val_accuracy: 0.6597\n",
      "Epoch 1298/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0579 - accuracy: 0.9818 - val_loss: 2.1499 - val_accuracy: 0.6042\n",
      "Epoch 1299/1300\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0503 - accuracy: 0.9826 - val_loss: 2.1226 - val_accuracy: 0.6389\n",
      "Epoch 1300/1300\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0539 - accuracy: 0.9818 - val_loss: 2.2432 - val_accuracy: 0.6042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1300, validation_data=(x_testcnn, y_test))\n",
    "#History = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=1150, epochs=30)\n",
    "\n",
    "#cnnhistory=model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "dhxs4EQrvhDm",
    "outputId": "9021dcad-b8e3-4fb1-b8c3-e9e9c85a45be"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3xUVfbAvyedhFATaoAA0gIC0YiKgkhRECyIBRXL6oprWbu/xVURyyr23tvq2rCLAgIqiEqR3ltAJKHXkATS7++PO5OZSWYmk5Ah7Xw/n3zmvXvvu+9MCO+8e+4pYoxBURRFqbuEVLUAiqIoStWiikBRFKWOo4pAURSljqOKQFEUpY6jikBRFKWOo4pAURSljqOKQKlTiMh/ReTRAMduEZHBwZZJUaoaVQSKoih1HFUEilIDEZGwqpZBqT2oIlCqHQ6TzD0iskJEskXkHRFpLiLTRCRTRH4UkcZu488TkdUiclBEZotIN7e+ZBFZ4rhuEhBV4l4jRGSZ49q5ItIzQBmHi8hSETkkImkiMqFE/+mO+Q46+q9xtNcTkWdE5C8RyRCR3xxtA0Qk3cvvYbDjeIKIfCEiH4rIIeAaEekjIvMc99ghIi+LSITb9d1FZKaI7BeRXSLybxFpISKHRaSp27gTRGSPiIQH8t2V2ocqAqW6MgoYAnQGzgWmAf8G4rF/t7cCiEhn4BPgdkffVOA7EYlwPBS/Af4HNAE+d8yL49pk4F3gBqAp8AYwWUQiA5AvG7gKaAQMB24UkQsc87ZzyPuSQ6bewDLHdU8DJwJ9HTL9H1AU4O/kfOALxz0/AgqBO4A44FRgEHCTQ4ZY4EfgB6AVcBzwkzFmJzAbuMRt3iuBT40x+QHKodQyVBEo1ZWXjDG7jDHbgF+BBcaYpcaYHOBrINkx7lJgijFmpuNB9jRQD/ugPQUIB543xuQbY74AFrrdYyzwhjFmgTGm0BjzPpDruM4vxpjZxpiVxpgiY8wKrDI6w9F9OfCjMeYTx333GWOWiUgIcC1wmzFmm+Oec40xuQH+TuYZY75x3POIMWaxMWa+MabAGLMFq8icMowAdhpjnjHG5BhjMo0xCxx97wNjAEQkFLgMqyyVOooqAqW6ssvt+IiX8/qO41bAX84OY0wRkAa0dvRtM56ZFf9yO24H3OUwrRwUkYNAG8d1fhGRk0VklsOkkgH8A/tmjmOOTV4ui8Oaprz1BUJaCRk6i8j3IrLTYS56LAAZAL4FkkSkPXbVlWGM+aOCMim1AFUESk1nO/aBDoCICPYhuA3YAbR2tDlp63acBvzHGNPI7SfaGPNJAPf9GJgMtDHGNAReB5z3SQM6erlmL5Djoy8biHb7HqFYs5I7JVMFvwasAzoZYxpgTWfuMnTwJrhjVfUZdlVwJboaqPOoIlBqOp8Bw0VkkGOz8y6seWcuMA8oAG4VkXARuRDo43btW8A/HG/3IiIxjk3g2ADuGwvsN8bkiEgfrDnIyUfAYBG5RETCRKSpiPR2rFbeBZ4VkVYiEioipzr2JDYAUY77hwP3A2XtVcQCh4AsEekK3OjW9z3QUkRuF5FIEYkVkZPd+j8ArgHOQxVBnUcVgVKjMcasx77ZvoR94z4XONcYk2eMyQMuxD7w9mP3E75yu3YRcD3wMnAASHWMDYSbgIdFJBMYj1VIznm3AudgldJ+7EZxL0f33cBK7F7FfuAJIMQYk+GY823saiYb8PAi8sLdWAWUiVVqk9xkyMSafc4FdgIbgTPd+n/HblIvMca4m8uUOohoYRpFqZuIyM/Ax8aYt6taFqVqUUWgKHUQETkJmInd48isanmUqkVNQ4pSxxCR97ExBrerElBAVwSKoih1Hl0RKIqi1HFqXOKquLg4k5iYWNViKIqi1CgWL1681xhTMjYFqIGKIDExkUWLFlW1GIqiKDUKEfHpJqymIUVRlDqOKgJFUZQ6jioCRVGUOk6N2yPwRn5+Punp6eTk5FS1KEElKiqKhIQEwsO1foiiKJVHrVAE6enpxMbGkpiYiGeiydqDMYZ9+/aRnp5O+/btq1ocRVFqEbXCNJSTk0PTpk1rrRIAEBGaNm1a61c9iqIce2qFIgBqtRJwUhe+o6Iox55aowgURVFqC9m5BXyxOJ1jlQJIFUElcPDgQV599dVyX3fOOedw8ODBIEikKEpN4cFvV5E4bgoAz87cQOK4KUyYvJq7P1/Okq0HALtHeDivIGgyqCKoBHwpgoIC//9wU6dOpVGjRsESS1GUakZOfiELNu/zaHt/ng34LSwyvDY7FaBYAdz39Sp+WruLP/dmkzR+Ou/P3RIUuWqF11BVM27cODZt2kTv3r0JDw8nKiqKxo0bs27dOjZs2MAFF1xAWloaOTk53HbbbYwdOxZwpcvIyspi2LBhnH766cydO5fWrVvz7bffUq9evSr+ZoqilJe8giJSd2eR1KoBAPmFRYSFCCLCHZOWMW3VTv64bxA7DubQo3XD4uuycgtwWoI27ckGYN3OTK5735VSp3FMRFBkrnWK4KHvVrNm+6FKnTOpVQMePLe7z/6JEyeyatUqli1bxuzZsxk+fDirVq0qdvN89913adKkCUeOHOGkk05i1KhRNG3a1GOOjRs38sknn/DWW29xySWX8OWXXzJmzJhK/R6KogSfB75ZxaRFaXx546ms3n6I8d+uplXDKKIjw0jdnQXAtf9dyKptns+pfk/8TEGR/z2BOFUENYc+ffp4+Pq/+OKLfP311wCkpaWxcePGUoqgffv29O7dG4ATTzyRLVu2HDN5FUUJnE/+2ErvNo3o1rKB1/7PFqcBMOq1ecVt2zM83b5LKgGAQzll7wE0ilZFEBD+3tyPFTExMcXHs2fP5scff2TevHlER0czYMAAr7EAkZGRxcehoaEcOXLkmMiqKErg5OQXcu9XKwHo3aYRh3Ly+f6fpxMdYR+lmTn5HK2jz4XJrRk3rCt9HvupVF+rRlFHN7kPgrpZLCJDRWS9iKSKyDgv/e1E5CcRWSEis0UkIZjyBIvY2FgyM71X/MvIyKBx48ZER0ezbt065s+ff4ylUxSlPGw/eISMw/ksTzvIkq0HOJSTz6uzU/lm6Ta6PvBD8bhlaQfZvMdu4q7alsFrszdx/IQZ5b7f30/3zBTw5EU9adYgirj6ETSLtS+IHeJj+PPxc2reikBEQoFXgCFAOrBQRCYbY9a4DXsa+MAY876IDAQeB64MlkzBomnTppx22mn06NGDevXq0bx58+K+oUOH8vrrr9OtWze6dOnCKaecUoWSKopSktyCQjKO5NMsNor8wiL6TvyZFg2i2Hko8Cj+ES/9Vq579mjdgGtPa0/rRvXo074Jg5OaM/rN+TSsF05YqH0/nztuEABb9mUTXz8yqAGlwTQN9QFSjTGbAUTkU+B8wF0RJAF3Oo5nAd8EUZ6g8vHHH3ttj4yMZNq0aV77nPsAcXFxrFq1qrj97rvvrnT5FEXxxBjDB/P+4vPFaazadogvbzyVOyYtByiXEijJRScmMHn5ds5Kas73K3aU6v/fdX04KbEJUeGhxW1tmkQD1sPISUSYVQidm8dWWJZACaZpqDWQ5nae7mhzZzlwoeN4JBArIk1RFEWpBFZty+C3jXu99m3df5gHJ68u3rgd9do8tu4/XO573NC/Q/FxUssGTLzweFZNOJsXRycXt/dq04h7zu7C0O4t6Ncp3kMJADR1eAOddlxcue9fGVT1ZvHdwMsicg0wB9gGFJYcJCJjgbEAbdu2PZbyKYpSwzh4OI+CIkNc/chik83Pd51BYtMYCo3h7s+X071VA3q0aljGTNCvUxy/OhTJ85f2ZuaaXUxZ6fmWf8eQztx7TjdWpB+ke6uGhIa4TDg/33UGTWMiaRjtP3V8VHgoM+/oT+vGVRM7FExFsA1o43ae4GgrxhizHceKQETqA6OMMaVyLhhj3gTeBEhJSTk2yTcURalRfLTgL/74cz8/rd1NVm4BTdx87gc+84vH2G+XbeeEtmVH9V/TN5Exp7Rj465MRvRsyeK/DpQaE+kw4fRMKD1fh/j6Acvf6RiYgHwRTNPQQqCTiLQXkQhgNDDZfYCIxImIU4Z7gXeDKI+iKDWcwiJDTn4hq7ZlcCgnn7d/3cyRvEJSd2dy39er+HbZdrJyrT/+/uw8v3Mt2ep655x99wBaN6rHhSe0ZsvE4fTtaC3UYaEhnN29BbcM7ERYaAgpiY095tgycXityAoctBWBMaZARG4BpgOhwLvGmNUi8jCwyBgzGRgAPC4iBmsaujlY8iiKUvO554vlfLXEw7DA3qw8ercpX86uS1PaMHn5do7kW0t0YlwMv/3rzOKH+sjk1szdtI/2TWM8rju/d2u6tIglrn4kRccoM+ixIKh7BMaYqcDUEm3j3Y6/AL4IpgyKotRc3F07gVJKAOBAdh5rdwSeVmb9o0OJDAvlkQt60OPB6RQUWU8d9zf7i1PaMLxny+JAMXe6tvAeUVyT0eyjlUBF01ADPP/88xw+XH5PBUWpC9z2yTL6/Ocnpq7cQZoPj55Ji9J44aeNHm39O8cDMLhbMwA+uf4U/jW0K/PuHUhkmPXYiQgLYen4IayccLbXeb0pgdpK3fmmQcSpCG666aZyX/v8888zZswYoqOjgyCZotQcCosMkxamcf83Kyky1uPmh9U7AbjpoyXlmuvNK09kb1YuCY2jMcYgIpzasbRnekykPgJBFUGl4J6GesiQITRr1ozPPvuM3NxcRo4cyUMPPUR2djaXXHIJ6enpFBYW8sADD7Br1y62b9/OmWeeSVxcHLNmzarqr6IoVUJ2bgEDnp7Nnszc4rYpXoKxAO4d1pXHp63zO19UeCgJje3LVW3YzA02tU8RTBsHO1dW7pwtjodhE312u6ehnjFjBl988QV//PEHxhjOO+885syZw549e2jVqhVTpthKRBkZGTRs2JBnn32WWbNmERdXNYEkihJM7vl8OYOTmnN29xYe7RlH8rn78+UsTzvIh38/mbOem1Pq2mdmbvA651WnJtK3Yxyvzk7lsZHH89XSbTzy/RoGdm3Gz+t2c3oVBWXVZGqfIqhiZsyYwYwZM0hOtlGFWVlZbNy4kX79+nHXXXfxr3/9ixEjRtCvX78qllRRgktBYRGfL07n88XprH7obKIjQvnf/L9Ys/0Qny50JR3wpgS88eOd/akXEUa9iFCOT2jIa2NOBOBvfRPJzMlnZHJrnryoJ/XV3FNuat9vzM+b+7HAGMO9997LDTfcUKpvyZIlTJ06lfvvv59BgwYxfvx4LzMoSs3h7V8306VFLP06xRe3FRUZRDzz67/w00Z+XLuLzY7KW+XlipPbclwz7wFXISHC7YM7V2hexaJeQ5WAexrqs88+m3fffZesLFuJaNu2bezevZvt27cTHR3NmDFjuOeee1iyZEmpaxWlpvHolLVc+c4fHm33frWS05+Yxe5MV+K2N+dsLlMJ9HLEAlx1arvKF1TxS+1bEVQB7mmohw0bxuWXX86pp54KQP369fnwww9JTU3lnnvuISQkhPDwcF577TUAxo4dy9ChQ2nVqpVuFivVFmMMh44U0DA6nK+XptOtZQP+2ufpzjlnwx6mr97JpEXW7PN3t1q7ZbHwvsHE1Y9gX3YecfUj+cBR0B0gpV1jbhzQsXK+iOIVMTUsOi4lJcUsWuT5B7Z27Vq6detWRRIdW+rSd1Wqnmve+4OExvXo3DyW8d+u5pQOTZi/eX+F5urbsSl/O609139g//9+eN3JjHlnAc0bRLLg34M9xv6yYQ93TlrGxFE9GZLU3Nt0SjkRkcXGmBRvfboiUBSlFL+n7iUxLobZ6/cAFHviVEQJPHlRT9rHxXBSYhMA5o4bSFioEOJw62wSE1nqmjM6x7P4gSEVFV8pJ6oIFEUBYHdmTnEqhyveXuDR91uq95z+3hjRsyVJrRrw5A/rARjYtRlx9V0P+1aNXKmWH7mgBwO7NjsasZVKoNYoAmf0YG2mppnxlJrD1JU7uOmjJZzZJZ5ZjlVARejdphFPX9yLqPDQYkXQsJ7vXPxXnqIbw9WBWuE1FBUVxb59+2r1g9IYw759+4iKiqpqUZRayMIt1uRzNEpgRM+WfHPzaaWqb4WH1orHTK2mVqwIEhISSE9PZ8+eiv8R1wSioqJISEioajGUWsL+7Dze+nUzdw3pXFwft7w8eG4SLRpEMez4lqX6fryzPxt2ZR2tmMoxoFYogvDwcNq3b1/VYihKtWRvVi4pj/7Ia1ecwI0fLaFBVBhLx5/Fg5NX893y7WQcyWeJl8pbJQkLEQqKDNERobx8eTJrd2Ry1amJHqUZ3TmuWazPIDClelErFIGiKL7ZsMsGLL4yOxWwEb9TVu7gu+XbAfh4wdYy5xhzSlvuGtKFH1bvZETPlsRGhTOwq7p11haCarwTkaEisl5EUkVknJf+tiIyS0SWisgKETknmPIoSl0i/cBhtuzNLnbTXLXNVbzliTKyd5YkJjKMxjERXNanLbFR/guxKzWPoK0IRCQUeAUYAqQDC0VksjFmjduw+4HPjDGviUgStppZYrBkUpTaytxNe+nRuiEN3B7S5738u8+6vdsOHvHaPqxHC6at2snsuwew7eAR1u44RF5hEdf0TQyG2Eo1IZimoT5AqjFmM4CIfAqcD7grAgM46741BLYHUR5FqRXsOpTDw9+v4amLehIdEcberFwuf2sBQ5Ka89ZVKezLyuXThWllFm/3xouXJXMgO49mDaJIjIvhNE3pXCcIpmmoNZDmdp7uaHNnAjBGRNKxq4F/eptIRMaKyCIRWVTbPYMUpSye+GEdU1bsKC7csjPDJnfbtNt66Pxnylqemr7e7xxdmsfyztWe2QZuHNCR8NAQmjVQF+W6RlU7+F4G/NcYkwCcA/xPRErJZIx50xiTYoxJiY+PLzWJotQlnD7/zqiZHQ5FIAL/mbKG/YfLXglMv6M/fdrblA9x9SO5f3g3bhvUKSjyKtWfYJqGtgFt3M4THG3uXAcMBTDGzBORKCAO2B1EuRSlWlNQWEROQZHXAiu5BYWk7bf2/bfmbOaZGevZ7SjvuGlPNpv2/OkxfnC35vy4dhcAN5/ZkVdmbSrui40K54ERSQzu1ox2TWOC9XWUGkAwVwQLgU4i0l5EIoDRwOQSY7YCgwBEpBsQBajtR6nT3PbpMno8ON1r37odrtoVG3dnsetQLv4C6hObRvPTXWdwwxkduPusLqX6rzu9vSoBJXgrAmNMgYjcAkwHQoF3jTGrReRhYJExZjJwF/CWiNyBXeleY2pznghFCYApK63tv7DIeARr/bBqJ7kFhQHNsfj+wfyweicXJidQLyKUe4fZ1OWX9WlTvKJQFCdBDSgzxkzFbgK7t413O14DnBZMGRSlJvDN0m38unEvz1zSq7ht1rrdnNiuMY1jIth1KId/fLjY5/WPnN+dfdl5TFqYxo6MHJrWj+SKk0sndHv8wp5BkV+p2WhksaJUA26ftAyAL5ekF7f9/YNFxNWPYOYdZ7Bpj/+cPWNOaYeIcEP/jmTnFfgdqyglUUWgKNWYvVl5JD8ykz6Ooi7u9Elswrt/O4kD2XnFKdjrRYRSLyK01FhF8YcqAkWpIl6dnUr6gSMBRe3+scWzMtgtZx7HjQM6EhMZ5tW7SFHKg/4FKUoVkF9YVFy45YdVO8t9/V1nda71hZiUY4cqAkU5Rvy0dhffLNvO/uxcHjy3e3F7oKkgnru0F307xrFhV6YqAaVSUUWgKEHmxzW7SN2TxUS3jJ//mbLW5/jEptHMvudMEsdNKW67MLk1I5NtUaLmmgJCqWRUEShKEDmUk8/fP1hUqv2XDb7jJp++uFeptn8P71apcimKO1Wda0hRaiVZuQXM27SP75fvKHNsyTKRSa1sQt6f7jqjuC0mQt/ZlOChf12KUslk5Rb4TBEB0KphFNszcoirH8HerDwE2DJxOH/tyyY+NpJox0O/Y3x9nr2kFy/8tJGocH1nU4KHKgJFqWQGPTPbb3+vNo3YnrGTVo3qsTcrj/jYSACvOX8uPCGBC09ICIaYilKMvmYoylFQWGSYtW43BYVFzNu0jwPZeew6lOtz/Pm9WxXHDSS3acT4EUl8eN3Jx0haRfGOrggU5ShYsHkff/vvQvp2bMrcTfv8jp119wASm0YD8PLlyQzu1pyocI0CVqoeVQSKUkGWpx3k8rcXAJSpBJ4YdTzt41ymnxE9WwVVNkUpD6oIFKUCbNmbzfmv/O53zMUnJjDhvO5EhoUQFqpWWKX6oopAUcpBYZHh66XbuPvz5X7H3TqoE7cP6kRIiEYAK9WfoL6miMhQEVkvIqkiMs5L/3Misszxs0FEDgZTHkUpix9W7SDl0Zlk5uQzaeFWStZJuvvz5WUqAYA7h3RWJaDUGIK2IhCRUOAVYAiQDiwUkcmOYjQAGGPucBv/TyA5WPIoSiBMmLyGvVl5PPjtar5auo1/fbmSdY8M5cP5f7Fwy36mr97l9/o2Teox844z/I5RlOpGME1DfYBUY8xmABH5FDgfWONj/GXAg0GUR1HKxJnLbUdGTnHbvM37eNRHbqC/n96eIUnNSWrVgNio8GMhoqJUOsFUBK2BNLfzdMCrw7SItAPaAz/76B8LjAVo27Zt5Uqp1HkO5xWQfuAInZvHFiuAeZtdXkA/rfW+Cphzz5m0bBRFuG4EKzWc6vIXPBr4whjjtTK3MeZNY0yKMSYlPj7+GIum1HZu+XgpZz03h7mpe732f7xga/HxoK7NAOjUrD5tm0arElBqBcFcEWwD2ridJzjavDEauDmIsiiKT+ZusgrAGRNQkiK3/eK3r05h3c7M4rQQilIbCObrzEKgk4i0F5EI7MN+cslBItIVaAzMC6IsiuJBUZHh4wVb2bAr0+9b/UDHCsCJiNCtZQPi6qsiUGoPQVsRGGMKROQWYDoQCrxrjFktIg8Di4wxTqUwGvjUlPTTU5Qg8fXSdO6Y5NsFdETPlny/wqaP3p1p9wwuPKE1yW0bHxP5FOVYE9SAMmPMVGBqibbxJc4nBFMGRXEnJ7/QrxIA6BBfv1TbnUM6k9A4OlhiKUqVojtdSp1hzfZDLN3qO2bx9TEnAjAyuTUAbZtE89JlJ/DAiCRaN6p3TGRUlKpAappFJiUlxSxaVLr0n6I4yS8sIlSEkBAhv7CIjCP5/LhmF+O+WunzmrevSmFwUvPi87mpe2nTJJo2TXQVoNQORGSxMSbFW5/mGlJqHZ3um8YVJ7flPyOPp9N90wK6xl0JAPQ9Li4YoinVldxMyM2CBi2rWpIqQU1DSq2gqMjw4k8bWb09A4CPFmzlSJ7XsBQAOsbH0KV5LOAyBSl1mDfOgGe7Hv08hfmwYUbZ44oKYf00MAZ2rIADfx39vY8CXREoNY59Wbnsy86js+NBDrBiWwbPztzAszM3FLd1G/+D1+sX/HsQzRtEAdYrqHF0RHAFVqoPSz+CxNOhcTvP9v2b7OemnyGsHrQ7tey59m+GtD+g12hX28+PwO8vwN+mQbu+vq9d8DpM/zdc9B588TfbNiGjfN+lEtEVgVLjuPiNeZz13Bxy8gtJ3Z0JWG+gQPjg2j7FSgCgWaymiKgz5B+Bb2+CD873PeZ/I+G9oYHN9/Zg+PoGKCpyte1eZz9zDvm/9qAjWt2pBLyxfJL9OQboikCpcWzekw3AwKdnsz0jhxcvS+azhWk+x/945xmk7T9MbFQYKYlNjpWYSmWxNxU+GW3fsusfRYqZ3Cz7edh/NTmvGGPNOaFuj0znPAVHIMJRfa7QUa86rKxVZgApyr8eaz97XVouUSuCvgop1RZjDAcP55Vq79ayAQDbHQnibv1kKb/5yBP0+pgTOK5Zfc7s2kyVQE3k8H74/TnYtxEWvuV/bG6WfRPPzYLCAsgpYWrJcLyF52XbB7tz/qIAVpNT7oKJbb2/6edlu44LHH+voW6K4MhB2569Dw5sgVdOhgWveb/P/s0woSFs/sXV9mhz+PXZsmU8ClQRKNWWN+dspvfDM9mRccSjvZmPPD8RYSGc2cXzjXFoj7rpBVJjycuGnQ433/2b4cn2sPRDe/7LE5DtUPgFuXaT1Z3HW8PENvZzyp32we002/z5K7w10B6bQvjkMjhywM4/e2JpObJLvFgsegfysyEjDdIXuRQJwJ9zXMfOFUFRgf08chCeaAePxsNTHeCFXrBnne/v/5cj086yj11tBTneZaxE1DSkVFumrLRpHnZm5LBxVxZpBw4THhLCLxv2lBp72nFNmXhhTzKO5DN30z5yC4o0H9CxZut8qNcY4rtUfI7p98Hi9+D2VbBtSen+zJ0QEwdT74El78Mda6ChF6+vJR/Yz5yDEN0Etvzm2b9hGjx1nD2e82Tp65/qCEOfgDZ9YM96V/tHF8OhbTDgXlfbl9fZe3QcCNsW27at862srU4I/LvvWg0/PWSPTZFnX2EuZO2G+s1KX1cJqCJQqiU5+YXsy7LL7D/+3M/j0/y8RQFndI63AWDA+keHkZNfWFxkRvFDURH8+jSccDXENvc97s9f4fBe6D7Ssz0vG357DvrfA++ebdvK4/1yMA1WfQmn3WarAu1YZtu/vgEaeak98t45cOrNVgmAtdN7UwQ43tiPHLAP6YKc0kOcb+2++OFfpdsOORIou68CAOa9Cn+87Tqf/bj/ub3xmpuXUUlFAPD+eXDz/PLPGwBqGlKqBam7s9iTmVt8/rf3FrLtoDUJlaUEABrV89yciwoPJTIstHKFrI2kLYBZ/4HvbvM/7v0R8Pk1pdt/ew7mPAWP+nhTLSqCb2/x/na//FN4vgf8+KA1uQDkOx7Yf/0Oyz8pfU1uBsx+zHVeWHoPyYMjB+xndulV5FGRudPzPHUmrJ9SefOv+qJ02x7vVfIqA1UESrVg8LO/MOCpWcXn7hXCAuFwXhlvd7UVYzzt1SUpKoQ3+sMyLw9VgDyHJ01hrvf+ssg/UrptQkP434XwYjIc2Q9L/wdvnWmDtpwyg33rd+L8Ht7e3P0xe6K934SG3vudiiDNe62JCnPIV2mVmokqAqXakJ1XyKGcfH5e579AvDv3nG3t0f0719HKdd/cCA818mx74wx4vI2NVs09BDuWw+p0bHgAACAASURBVDf/8H59gUMBbPrZ9UBN+8NTufiKei3Is3Zrb2z6yW72um+67lgGc1+y8u4okQF26f9s+4E/fX9Xb6TO9N+/6Wfr8bMvtXzzloU3hdWiZ+XewxtHfCdNPBpUEShVTpFbCbCbP1rCtf8NPKngzWcex5aJw72mjq7xHNgCezf6H+PNfLJjmVUAL/SE3190tTvf3netgdSf7LG3B9o7Q+Cbm+xDfPH7dh4nRUWQvhhWfG6V0MrP/MuXud3zfMb99vON/p7tc57yP09Fmf8qLHy7dPvxF/u+pvOwwOe/ws2EM+ptOO+lwK91Et0ULvkgsLHOCOhKJiBFICJfichwEVHFoVQ62W5mnV83eo8HAJh99wBeuiyZE9s15oS2jYgIq+V/ji/0gpe9JossTWG+9/ZVX7qO571sP989Gz680Nrj8w97v275x9bd8rtbPdv3b4a3B8JXf/duxy7JfB/+8hWh+4Vw88KKXRvbEjq7RQynXOs6vmk+XPejPe77T0g4MfB5myXZzy7nWG+pbucGdt1dG+Cu9XD7SnucdD406277rp3uGjfqHegz1nV+0Hfg5NEQ6P+kV4HLgY0iMlFEAvIPE5GhIrJeRFJFZJyPMZeIyBoRWS0iH3sbo9RuMnP82/fjYyO5fXAnEuNiOLdXK768sS9f3tiXdQ8HmAqgOvHrM6XNIu7s2QA/PeLf7u+NnAz44d9wqMQbuLst2+lTn+sIipr1Hzi0w/ecB72YhF4ux0MSYGMACdhKcvF/4eQbPduGPQUXvQvxna2HUlmEhJc4D4PRbqunem7Bhc26QZuTYPx+GPKI7wCz0V5WXzFxMP4AjHY8usThoBARCwP+7Vu++s0gtoX1jAot4bwZ7pb6vMOZMOxJuG2FDVLLCY5pKCD3UWPMj8CPItIQuMxxnAa8BXxojCn1OiIiocArwBAgHVgoIpONMWvcxnQC7gVOM8YcEJHgOMkq1Zq9Wd43Km8f3Il+neLo3qohUeGeHkAiUvPcQ42Bnx62P75cLD++2JqE+lzvaktfZN/mj78Eup4D+zbBV2NhjNsb+VMd7efeDR7TebhIzn4MIt1MaHNfhK4jjuoreSAh3t0ey0vSBdCyl/UkWve9bTvZ7a144P0uU1LXEfbBHRNn9xmchITBabdC8+42G+jJN0CI23tvWCSc/4qn4gxx/I2V5VbqJKaZncedyFjodRmceA20PQUG/Mvu2exYBrcugxd723He/nhHvWW/V7NuMPJNu68R09T2NWoL9+3y/A6VSMCzikhT4Brg78BS4AXgBMDXbk0fINUYs9kYkwd8CpTM9nQ98Iox5gCAMcbHzpNSWygoLGLhlv3kFxbx+i+byDiSz3MzN3gdO/z4lpzYrkkpJVDjOLzfbsKu+cbVtme9bSsZHetMV/CM26L725th9dfw6WU2b/7sibBtEaz5tvS99m/2L8v0Em+pzgdtZRDmp4pbkw6BzyNix4/+yPeYK76ASz+0Yy7/FDoMsO1O80/T42DQeOgxCi58A1o7ArvaO/YmQsMheQyc8X+l5452PHz73WX3EpzfKyQUxv5i5/X1nURg5OtWCTi56F17TeNE/9+7eXe7GgoNt/mFBt7nOW+QlAAEuCIQka+BLsD/gHONMc715CQR8bWz1xpwN2ilAyeXGNPZMf/v2AL3E4wxpXIHi8hYYCxA27ZegkyUGsMLP23kpZ9TuTSlDZMWpTHRT4xAjagOdjDNvmXX81PY3rnhO+cZV9uayfZz2Uf27bXpcb4TlbmnJHg8wXXszfc/SJuJQNlv/OFR9js4XTbdGfIITLrCHve91a5GSjJoPLQ7LTBZOg0pLRvYh+ilH9mIYG9c+iFsnAkNE7z3A5x0PUQ2sG/2ISHWO2rl59DpLPtAbtUbmnaCtgGkqgZo2tEqFYAbfi079qEKCFTFvGiMSTLGPO6mBADwVfosQMKATsAArMnpLRFpVHKQMeZNY0yKMSYlPr6OugnWEtZst/bpSYs8N73CQ4UZd/Rn2Xj7H3xkcuvqvxLYscIGRD2R6JmK2J2CXLsvAJ4ujLMetZ+pP8Frp8IfbwRV1Arz959db9GN2/sf2+syuMXHe2GUm59/ax/7DG37er5Jl4cQxzutMdBthO9UDFEN4fiL/M8VGgbJV7jewMMi7Lm7OSfpvIplQm3ZExKO5pEZHAJVBEnuD2gRaSwiN5VxzTagjdt5gqPNnXRgsjEm3xjzJ7ABqxiUWsDc1L38uTebK99ZQGaO3Ubylfv/2tPa07l5LI2iI9gycTjPXdr7WIpaMd7o5zp2t0+7M3M8bHR4gRR4Cb7a51gtZO60D7HKjoAti8ETPB/SAOPclHTCiS5vlpJv4e7cnQpDHra2eie9Lncdu2+AGsdmbOsSD8SScpQHp+kneUzF56jDBKoIrjfGFG9XO2z61/sZD7AQ6CQi7UUkAhgNTC4x5hvsagARicOaisowcio1gVXbMrj87QWc+fRsft24l+MnzOD6DxYVp4uOCA3h5cuTSWnXmHHDuvJ/QyuhTGBVkrkDFrzh6a4JsH1pYNfPexlmPVb2uIryj99Kt3U7D06/A/6vRBBXVANrykm6wLO9odt7XYibVbn7SPt2HFJiBdf/btdxfjalaNLec9M8qoH/7+CPhgl2ri7liAFQigk06VyoiIgx1qfN4RHkt/KCMaZARG4BpmPt/+8aY1aLyMPAImPMZEffWSKyBigE7jHGVKBqhFLdyDhS2q995hobMXzTgI7FD/4RPVsdU7mOiun3WY+SoRNtJSt3igphmmPjsccoO/avubDdS44dJ8dfbG3PTrxlwTxaLnrPRus2KJGYrdflrk1P9wd4XGf7eVqJ+AGwppHwaBt70PpEm7bh1mX2ge6Nph3hjtXwy5Oe9vSuIyD5Shj4gOf4SC+KYPiznqsMJSgEqgh+wG4MOw2ZNzja/GKMmQpMLdE23u3YAHc6fpRahL/yjw3qhfvsO6bkH7GRtf42et1xBmQNngCbZ3n2/fac67ioyDXWH6fc5KkI/JHYD7b8GthYd3pcaD/z3ALHTrwGzn3Bc1x0nM0uetLfvUzijGkQ6zWzfYlNubzqy7I9YRomwHmOjeGL3oX4rg7XTbffT3w3m1Atwkt0+EnX+Z9fqRQCVQT/wj78nVEeMwEvcduKYvHn41/eWKmg8dZA2L3G2sT3b7beIN7Ys95TWeRmlh5T5LYC+vbmwO7fKjlwWZ0ujQCDH7I+9iVTJ9w03+b+kRCbLdSdMFedZjoOLD3/4Akw+RbXisCdlr3sZ3wXG9AV7xhzyo2lx/qjxyjv7Vd/Z+Mfgugeqfgn0ICyIuA1x4+ilGLTnixaN6pX7Onz9VLf2Rnbx1UTt9DdjtjGz66EzbPh/j3W/XDph9D9AhscBPBKCVfEKWUsYJcHGCBfVkRcZEObdhlcsjRqB6ffbgPK3Ol9hQ1EatbN+1zuD9kkL8Xbk8dAwknQzMteTa/LbIEVb32VQf34o6tFrBw1gcYRdAIeB5KA4lcLY0w5okSU2kp+YRGDnrE1Vocf37K4spgvzu7e4liI5R1jrM3avYpW2h/2M+egXRlMvgXS5tvI0+Wflp5j7XfHRtZGbWGXo2yjM9rVuBVccXLNFOt6eTSI+H7Q++vzRo9RkBl4Blml6gnUNPQe8CDwHHAm8Dc0c2mdZ/b63czZsJc9bikifCmBD687mTHv2JzwcixzQxhjE7dl74F7NkFGumdhE3AlXju831WcfOmH0Pc2z5z5FaXrCPtQn/+qq22woyTh2Y/ZvYqfH7Hn4w/Y40ZtbbBZsYwO19Nwx3uYM7Dr2hnQtmScpg9Srgs8COpouOjd4N9DqVQCVQT1jDE/OTyH/gImiMhiYHxZFyq1k0M5+VzzXtmZIB+9oAcDusST0DgI5qCCXLsp+8dbcNc6KCywBVYiYmzx729K2LD3rPdvjjmy31UpC+CD8wKXpVmSy9RUktEfwbqpnorg9Nvt56mO/YSwKBtxGhICgx+0bccNtjLs3wxxnWydXGf65BHP29q+CSd5v+dF70F4iZQPI54N/PsodYpAFUGuIwX1RodL6DagFiaAV8piydYDxESE8eJPZeTJd+CuBHq3acTpx1WSK+CCN2FaiSyUjzg2VEe+WVoJgH2LTv3Z95yZOzzt/5k+TFzdzrVZISNi7Iqhx0XWxv6/C7yPB1clMF/0vaV0W6M2cMtiWPJfa6d3f7A3auNy//SG01tIUQIgUEVwGxAN3Ao8gjUPXR0soZTqy4WvzgWgW8vAgn/cawZ8c3OAeWS8sXWBdVV0Flj/9RnPfvd8/FN9pCme+YDdFPbF/NfLluPsx2x++NBwV8K4xNNKrzTiOltPmCaOrKDuCcrOC8C11ElIiGfufEUJAmUqAkfw2KXGmLuBLOz+gFJHKCoyvPv7n6zZcYgNu1xuk5t2+37DvefsLjw1fT0AQiXsBxgD755lH6a3OiJ1s0oUD3cvsJLrI8WzPyUAkP5H2bL0vNQqAbB5Y+5ca4ueOH38m3WHS963+e5DQiDUkaY4IQXuWGMVRoMaFESn1AnKVATGmEIROf1YCKNUPxb8uZ9Hp6wt1Z5XaDcrO8TFALB5ryuFwAXJrTm7ewu+WpJOXEy4zb+fdL7LH7285Dge7Ps3Q9pC2DCt9BhvRdSDQcko1+KHukPh1Wts7fneaNjae7uiVDGBmoaWishk4HOg+H+8MearoEilVAvenLOJemVkAC00hk/HnsIT09aRuieLVdsOEVc/gsiwUJtGoiDPmnHmvQr37/Q7l0+cidgkFN4Z7H3MZ1dVbG47Ma7o2QrS9hToPQb633V08yhKFRCoIogC9gHuIYkGUEVQy7j8rfkczivkyxv78thU37UCnIzt34GWDevx/OhkMg7nk7onk8gwN+XhjLgNtOqTO0cO2rQDTkUQUd+32SdtQfnnd9LzUljhFi/QoLVnicdhT7ryCPkiNBwueKXiMihKFRJoZLHuC9RS8gqKCAsRQkKsaWPuJpvzr+O/p/q7DIAXRvfm/N4uc0fD6HBObNfEc5BzE7es2IF9myCqkS3Nd+Avm4/mmS7Q4nibJRN8K4FAuPBtW3A9ppkNJtvyqy043mOULYruVARtTrE2/k2z4Jt/2LaTb7CKoNUJFb+/olRjAo0sfg8va2djjLoz1GCMMXS+fxpXn9qOh87vwY6Msu3sYSHC1X0TaR8XE1jm0JIrgbzDsH6qfQC7K4eXHA/Zv02D99xSCe9caX8qSlRDu5Jw5sBv39+lCCJiShcpGfOFTedw/MVWEZzkyLb+zyW+i50oSg0nUNOQe2HTKGAksN3HWKWG0P5e+9b//ry/eOj8Hpz6uG8f+x/vPIPG0eHUiwglOiLQPxs83ToBfnwQ/ngTYltAohcfhPcqMZ98syT421S7t+BMCxES6qq0VeCKiKbtqTZtsjOnT2gY3JvuKqjStGPlyaUo1YxATUMe1TZE5BPAS6ULpaby3XL/er1FwyjqR5ZDATgpKqEIshw5aLJ2l3+uQBjysK0KBnDdDNeD3VnTNizS1hgGzzz813rJqu68VlFqORXNF9QJKHOdLCJDRWS9iKSKyDgv/deIyB4RWeb48ZYMXQkC2w56moH++Yn1z7/7LM80xBcmt+bly5MrpgTAtSJwJksLc0THFuTA6/1gztO+6/2WRdPjSrcdclNo4TGu4+4jrZln8EPQcRD0ucEGhymKEvAeQSaeewQ7sTUK/F0TCrwCDMHWJl4oIpONMSUTskwyxniJr1eCyWkTvZuBGkV7Fp4bc2o7TmgbYOEWb7xUYoPVmTStIAd2rrA/Pz9asbmdyqXjQNjk+D79/w8WOCKE3VMvh0fB8Kdd5+cEoRqYotRQAloRGGNijTEN3H46lzQXeaEPkGqM2WyMyQM+BbwkQleCTcaRfAoKXW/d+9yyhZbkpESX18/i+weXrQQ2zfLcBzi0w1au8vWW71wR5Oe4NQbow9/zUu/tJ7vlFYpp6n2Moig+CXRFMBL42RiT4ThvBAwwxnzj57LWgFsqR9IBb/lyR4lIf2ADcIcxJq3kABEZC4wFaNu2bSAiKw6MMfR6aAYXntCaG/p35M+9WezOLK0Inru0FyOTEwB4/tLeNIoOp2n9SP+T71huE62dfCMMm2jbptxpvYIG/lnaxr5nPWxw2OK9lXJM6OM/zUObPrBiUun26KYQ18Vl+1cUpVwEukfwoFMJABhjDmLrExwt3wGJxpie2PKX73sbZIx50xiTYoxJiY/XSkblwZkK4qsl2zj7+Tn848Ml7M/OK+6Pj7UP+xQ3//8LklszoEsArpLOlcBfv7vadjvSUfz8SOkgrE8vt4XUwTNgy0lJ98zRJSp9nXA1jNvqOne6pkbGwo1z4bof7XmfsXYfQFGUgAhUEXgbV9ZqYhvQxu08wdFWjDFmnzHG+Xr6NnBigPIoAfLsjA2l2rbucyVoG5ncmhUTzqJNEx/1AjbNgvfPhaJCz/bCfJerpzPyd/p9rge9N44c9C/s0Mc9zxuUyM0TEmbjApw43T8jYqy7p3NP4Jyn4EoNeleUQAlUESwSkWdFpKPj51lgcRnXLAQ6iUh7EYkARgOT3QeISEu30/OA0tnNlHJhjGH+5n0YY/g9dS9vzNlcasxXbvWEB3ZtRoOocN8TfnEt/DnHVu9yJyPdFlIBWzaxsMC7ucdJUb7/6OLbV9qqXO37u9qiS0Qpl7y+kcNMGBGDoigVJ1BF8E8gD5iE3fTNAW72d4ExpgC4BZiOfcB/ZoxZLSIPi4iz9NOtIrJaRJZjax1cU/6voLjz2aI0Rr85n+9X7OCKt/3n39kycTindPCyubpzlWsF4PS1Lyyxr7DXrTBNQQ58GUCQuXPlUJLuI10P9YvdrIP1GttVQEnqO2oeX/YJXPoR1GtU9r0VRfFJoAFl2UCpOIAArpsKTC3RNt7t+F7g3vLOq/jmz73W7PPk9LITxnnlYBq8fpq1s5/zlI3KBVtq8eSx9tgY+Phiz+vWfFtBiYEQtxVJdBNHErhJNjWEhAIFtjavk5vm2RVKTBx0G1Hx+yqKAgS4IhCRmQ5PIed5YxGZHjyxlIryW6p9607bX8H8/M68/ssnQeZOVwEY97KQi//rf44OAyp2byfnvwL/+suagpwRwc27u/qjm0Ccl2AyRVEqRKDhonEOTyEAjDEHREQzcFUTiooMXcf/QF5B2RG6U2/tx/L0g/RK8GFOcdr9czNs9k93CvJgyh2w9EP/N+k4yHoPOdNJeOPOtfBsN8c9S5idQsNd5p5Rb8MvT7hy/iiKUukEukdQJCLFDvwikshRV/JQKou8wqKAlMAbnReRNOUCLuvTlqRWPmoOl3wou7Puu7KVANiqXTfNL3vMBa/Z44I83+O6jYB//OoZJawoSqUS6IrgPuA3EfkFW86pH44AL6VqyTicT3ZeAdHkEEoRmfh+cz5767PeO+Y8bf3+H9jr/6H8RYBZx6MaQVhU2eOcAWf52f7HKYoSVAJNMfEDkAKsBz4B7gKOUZFYxR+9Hp7B0OfnMC/yFlZGuXL2nZTYmGv6JgY2yS9P2M+0BaWLwleEiBhPRXC9j/TWTTrYzwN/Hf09FUWpMIGmmPg7cBs2KGwZcAowD8/Slcox5kiedfE8lFNAwyhXkNhJiY354NqTqRcRSlZuAV8sTufJUT1hio+JnPsC/x1ePgEueA3anQapM2GKW63eiGhPU07rE+GUm2H+K/B/f7ru19RR5L1kcRhFUY4pgRpebwNOAv4yxpwJJANlhIkqwWTzniwmL/eSpgH4/B99qRdh3T77dYoDoGvLEnl/dq6CuS+Vry5Aj1Ge50nnQ+N20PsKiHFL/RHhJefPWY/Cfbusx0+sIw4gLALu3w0DHwhcBkVRKp1A9whyjDE5IoKIRBpj1olIl7IvU4LFwGd+8dr+8PndPc7P792afp3iaRLjll567ksw4357nFSOhLDOQC4nzoje8HpwTyo81hrysrx7+ISEQIiXfYOwMhLbKYoSdAJdEaQ74gi+AWaKyLeAGnaDjSOXTn5hEYVFLiet2et9v8Wf6SVZnIcSAJcSAMgJoCB88pX2M9TtveGcp0uPcyah05QPilKjCDSyeKTjcIKIzAIaAl5q+ylHhTGwL9UmVvtzDnx5HVw/i04v7QDgzC7x3D8iiYe/96ztM7BrM9hij9s0KGclsYx07+1jvoKt8yH5CkhfBEv/57LpA/S5vvQ1bfrYovDq868oNYpy1x80xni3SShHz/xXYfq/PZp+nTUFsFW+Zq3fw6z1nr/+X65syqSV+1wNeVmQOg+6nGMjcwsLYMFr0OFM7/f8ZLT39tYnwHGOVM6N2kH95rbY/GQ/xeRGfwz7N7lWDrcs8r5foChKtaKChWiVoJBWOkncjLV7fQ6ff+8gWjzXHI+s/3Nfgt+ehfNftRuzC9+xXj3l4a71NuGbExFo36/s66IaQKtk13lcJ99jFUWpNqgiqApWfmHt/8lXeLab0sHaRT62ce4I+4IWnz9fuuM3R9DYgS3w7U0Vky+2RdljFEWpNagiqAq+vM5+llIEpdNEFFE6h79QxG1hX9nin77Iq2C07uCHKnadoig1FlUE1QkvK4JQXMqhAVk0lGx+jbyj7Lnmv+K7Lzwa8g977zv9dv/zXvZp6VrEiqLUaFQRVCVrJkPXEdbHfttith/IpFWJIfWwLqThFLAiaixbiyqhZnNsS7upWxG6DDv6+yuKUq0IakpHERkqIutFJFVEfBa2EZFRImJEJCWY8lQ7PrsS/ngDpo2DtwbSavecUkPqYdMxNOEQAG1DfFT5Kg8li8QrilKnCZoiEJFQ4BVgGJAEXCYiSV7GxWJTWPivq1jT2Ztqs3yWNP/MuN+6d/rgzvAvOLVRBveGf1x5ssR3gXAN+lIUxRLMFUEfINUYs9kYk4etdewtn8EjwBPYOsi1i9+es5W+wMYH/PyIZ1QvQFFBmdN8knMjF4TO9T/oNB+2/VsW20Ixvce42uo1hvu2u84nZMAJV3uPFlYUpdYTzD2C1kCa23k6cLL7ABE5AWhjjJkiIvfgAxEZi6P+Qdu2bX0Nq378OMF+9rwEwh15dua9HJx7hYTa+r6m0LM9Ihqu/Ao2/gjLHEVlnHWIr5lik88BnPdicORSFKXaU2WbxSISAjwLXFPWWGPMm8CbACkpKTWjMpq7CejNAbBjWYWmyTDRNJTD0LwH7Frl6giNcKVzBut6KiEuRdDvbmjU1lYCswNcY0MciiDxdPujKEqdJpimoW1AG7fzBEebk1igBzBbRLZgaxxMrpEbxjuWQ9pC2LPe1bbRLZq3gkrgcOOuREc4dPVZj3h2jkuDE65ynRvjmUl00ANw4tWu83y3OkLOFYGiKArBVQQLgU4i0l5EIoDRwGRnpzEmwxgTZ4xJNMYkAvOB84wxi4IoU3B4oz+8Mxhe6WPP8w7Dxxf7v6Zkbv+SxHcj+safCQ91/BOF1XP1NT/empo6utcFMq4awN5o7paeuqPWE1IUxUXQFIExpgC4BZgOrAU+M8asFpGHReS8YN33mLP4/dJt/grAO9ia/H9kd7ZJXX8u7A3AewVnuwbUa+yZztk9b/8NzsRzblHHxthCL75o2hEePGh/2pxUpnyKotQdgrpHYIyZCkwt0Tbex9gBwZQlaHx3q+f5f0dA/7tLj+v7T5vOees8VjQcyHlvbeKpsH1cHAbTivpwbb5NHTc3eiBv5f3Ltbksjod9WBSc/wocOeiy8YubHnfWCD5jHDTr6l1WKZ2uQlEURSOLj4acQ6Xbtvxqf0oS27L4rX7Dfusymo99oIfj8vQJSTgR2t3nZv93PLzDoyDZzQUUPBWBMzXEmfeW+2soilK3UUVQEXIyIHOna08gEGJbFtv5c0w4AGtMIgDbjK0r3Ll5fZ69NBki3Uw37iuCkjj7Og/TqmCKolQYVQQV4b3hsGtluS7ZGpJA7v58OgHZ2If6h4WDWVXUnmXmOAASGkcTE1nyn8TxsA/x8k9VvCKoGR61iqJUT4Kaa6jWkbnLRguXRwlcNRnuTmXU14dI32XzBO00TRydwjJzHK+PsRXIQryZ8M9wlJ2JbFC6z6kIvKSvVhRFCRRVBOXhsytd0cK+6Fmi9GPDBKgfz76sXOLFFop3moIAzu7enAZR1lTUvIEX88/JN9gUEOHeTEMaD6AoytGjpqGymPxPQGwKBveAMV/0vAQOboWtNjfQXV+uYsmhNIqMq7bAqqL2ANx3Tjeu798BYwxPjurJub1KJqEugw5nQMp10O+u8l2nKIrihiqCsljygf0870XIOVj2+NBwTGhYsYf/r5sz2e34Nf8z/xZ6yWYyo1qwctxA6jv2A0SES05q42NC//dixLPlv05RFMUNVQSBUpjvv79JB9i/GULC2JVVQAvgzYLh7MZVBD7VJJBqEvj++lOIdZiDFEVRqhrdI/BHbqbr+AefdXUsTh//Jh3IyLPrgQVFpQO7zuwST4/WDStLQkVRlKNGFYE/ZroFQa+b4n/sqbfA/XsgtgVLW10OwIqijh5D4upH8p+Rx1e2lIqiKEeFmob8kb3XdZy5w//Y0AgOHsln9sptjFvamHF4VhS7Y3BnbhvcKQhCKoqiHB2qCHyxcxWsnVz2OMB0GEDPCTPIziugyEts1/LxZ9EwWvcEFEWpnqhpyBcrPw94aN7Jt5KZ610JAKoEFEWp1qgi8MXuNQEPPeyn7PDPd51RCcIoiqIED1UEvtg4I/Che3N89nWIr18Z0iiKogSNoO4RiMhQ4AUgFHjbGDOxRP8/gJuBQiALGGuMCfxVPFi4l3X0Q27DjkRmbOI/P6QCNnHc+BFJdGxWn6YxEbRs6CUthKIoSjUjaIpAREKBV4AhQDqwUEQml3jQf2yMed0x/jxsMfuhwZIpIPIOw2N+Uj0kj4GlHwKQW1BIJFDgqCvw2MjjAF0i4gAADSBJREFUuaxPG0QLwCiKUoMIpmmoD5BqjNlsjMkDPgXOdx9gjHGv7BJDVedTXvsdPNbSU4w7VkNvV0EYc97Lxcd7M61JyKkIBnZtpkpAUZQaRzAVQWsgze083dHmgYjcLCKbgCeBW0v2O8aMFZFFIrJoz549QRGW/Zth0pjS7Q0TPEpP5hUWMTL3IfrlPoc4FEYBoVzfrz0t1BSkKEoNpMo3i40xrxhjOgL/Au73MeZNY0yKMSYlPj4+OIK8mFy67SpHHEGUKyXEkbxClppOpJnmxYnl3rj6ZP59TrfgyKUoihJkgqkItgHuKTUTHG2++BS4IIjy+KbIR2GXVg7l4FYUJjuvsNSwpjERahJSFKXGEkxFsBDoJCLtRSQCGA14hOqKiHvOheHAxiDK48nW+bbWgDGQvdv7mAiH62eoa099RZorFbXTNNQ4JjJoYiqKogSboHkNGWMKROQWYDrWffRdY8xqEXkYWGSMmQzcIiKDgXzgAHB1sOQpxUeXQG4GDH7IM6eQOyEuPflI/hWsKOrIwo+WFLe1ahgJmVBcV1hRFKUGEtQ4AmPMVGBqibbxbse3BfP+fqkfbxVBRhrkZnkd8taczZzSoSmL/trPO4XDPfoW/HsQ4VN7wbo0iIg5FhIriqIEhbqbdK5+c9iXCqu/wZfX6n+mrvXafu+wrra+8Mg3YOdKqN8siIIqiqIEl7qrCJz2/9/KV+pxy0S3lUFkfWh3aiUKpSiKcuypcvfRKiO8XrkvGdyteRAEURRFqVrq7oogPLpcw28b1Il/DjwuSMIoiqJUHXVrRVBYAHnZjpPyZbO4dVAnwkLr1q9LUZS6Qd16sn15rSuhXGGe36F35N3ocR4aoi6iiqLUTuqWaWjNt/Yz55Dr2Ae/FR3P62NOYNqqneQX+og8VhRFqQXULUXg5LtbocitrNity0gvbETCK4kA9Mx5k0PUZ1C35gzt0bJqZFQURTlG1C3TkJP9mz1O82Nbc/7ri4rPD2FdS8N1T0BRlDpA3XzShXguhK56bwn7sv3vGSiKotRW6qZpqIQimLd5HwBXhT9DVHZ6VUikKIpSZdRNRZC2oPjwgtyHi48bdTiRyctbMiSpOVed2q4qJFMURTnm1E3TkBvLjA0SG9S1Gc1ibTrpUSck0K9TkArgKIqiVDPq5orAwccFZxYfvzbmRAqLDG2aRHNWkqaSUBSl7lBnFcH1eXcysyil+DwizC6Oru6bWEUSKYqiVA1BNQ2JyFARWS8iqSIyzkv/nSKyRkRWiMhPInLMDPOzinofq1spiqJUa4KmCEQkFHgFGAYkAZeJSFKJYUuBFGNMT+AL4MlgyVOSgrq7GFIURfEgmE/DPkCqMWYzgIh8CpwPrHEOMMbMchs/HxgTRHm88vVNfTl4OP9Y31ZRFKXaEExF0BpIcztPB072M/46YFoQ5SnF+BFJJLdtfCxvqSiKUu2oFvYRERkDpABn+OgfC4wFaNu27VHf7y9jS0s6N4gVRVHqMsF8Em4D2ridJzjaPBCRwcB9wHnGmFxvExlj3jTGpBhjUuLjj96/P73IzhHviBtQFEWpywRTESwEOolIexGJAEYDk90HiEgy8AZWCewOoiweHHAklUtoXP5ylYqiKLWNoCkCY0wBcAswHVgLfGaMWS0iD4vIeY5hTwH1gc9FZJmITPYxXWUIVHx40DgVQfnKVSqKotRGgrpHYIyZCkwt0Tbe7XhwMO/vwZbfig+dgWQN64Ufs9sriqJUV+rObmnqjwAsbn4xvxT1qmJhFEVRqg/VwmvomHDabZidK3hxh3VMmn57/yoWSFEUpXpQd1YE0U34tsfL/LK/CQBdWsRWsUCKoijVg7qjCICvlpbyXlUURanz1ClFsHlPFgD9OsVVsSSKoijVhzqlCLJzCxjcrTlvXZVS9mBFUZQ6Qt1SBHmFdGwWQ1R4aFWLoiiKUm2oM4ogr6CIvIIiYiPrjqOUoihKINQZRZCdWwBAjCoCRVEUD+qMIshyKIL6qggURVE8qDOKYPvBIwA0axBVxZIoiqJUL+qMIkh1uI4e16x+FUuiKIpSvagziiC+fiRnJTWnpa4IFEVRPKgzBvOzurfgrO4tqloMRVGUakedWREoiqIo3lFFoCiKUscJqiIQkaEisl5EUkVknJf+/iKyREQKROSiYMqiKIqieCdoikBEQoFXgGFAEnCZiCSVGLYVuAb4OFhyKIqiKP4J5mbx/7d3tzFy1VUcx78/qRahpg9aSS2EttL4gJGCFVvRhMiDpiHiC4wFxAab8IZEMCZq4wORxBcmxoKJwRJFERogYCtNQ6yykia8sO2uVqwt2OVBWULtYmoVEwwPxxf/M+tlCnZ3dmdn597fJ5l07v/+O/mfOd2evffOnHsuMBwRTwBIuhu4FNjfmhART+W+V7q4DjMz+z+6eWpoMfB0ZXskxyZM0jWSBiUNjo6OTsnizMys6IuLxRFxa0SsjIiVCxcu7PVyzMxqpZuF4BngtMr2qTlmZmYzSDevEewBlktaSikAa4ErJvuiQ0NDz0n6S4d//W3Ac5NdQ59xzM3gmJthMjGf/no7FBEdvubxSVoD3AScANwWEd+WdCMwGBHbJH0Q2ArMB14ADkXEmV1cz2BENOr2ZI65GRxzM3Qr5q62mIiIB4AH2sa+WXm+h3LKyMzMeqQvLhabmVn3NK0Q3NrrBfSAY24Gx9wMXYm5q9cIzMxs5mvaEYGZmbVxITAza7jGFILjdULtV5JOk/SQpP2S/iTpuhxfIOnXkg7mn/NzXJK+n+/DI5LO6W0EnZF0gqTfS9qe20sl7cq47pH0phyfndvDuX9JL9fdKUnzJN0n6VFJByStbkCOv5j/pvdJukvSiXXMs6TbJB2WtK8yNuHcSlqX8w9KWjeRNTSiEIyzE2q/egn4UkS8F1gFXJuxfRUYiIjlwEBuQ3kPlufjGuCW6V/ylLgOOFDZ/g6wMSLOAI4A63N8PXAkxzfmvH50M/DLiHg3cBYl9trmWNJi4AvAyoh4H+W7SGupZ55/CnyibWxCuZW0ALgB+BCl4ecNreIxLhFR+wewGthR2d4AbOj1uroU6/3ARcBjwKIcWwQ8ls83AZdX5o/N65cH5bsnA8DHgO2AKN+2nNWeb2AHsDqfz8p56nUME4x3LvBk+7prnuNW08oFmbftwMfrmmdgCbCv09wClwObKuOvmne8RyOOCJjCTqgzWR4Onw3sAk6JiGdz1yHglHxeh/fiJuDLQKt9+VuBf0TES7ldjWks3tx/NOf3k6XAKPCTPB32I0knU+McR8QzwHcp9yx5lpK3Ieqd56qJ5nZSOW9KIag9SXOAnwPXR8Q/q/ui/IpQi88JS7oEOBwRQ71eyzSaBZwD3BIRZwP/5n+nCoB65RggT2tcSimC7wBO5tjTJ40wHbltSiGodSdUSW+kFIHNEbElh/8maVHuXwQczvF+fy/OAz4p6SngbsrpoZuBeZJaLVOqMY3Fm/vnAn+fzgVPgRFgJCJ25fZ9lMJQ1xwDXAg8GRGjEfEisIWS+zrnuWqiuZ1UzptSCMY6oeanDNYC23q8pikhScCPgQMR8b3Krm1A65MD6yjXDlrjn8tPH6wCjlYOQWe8iNgQEadGxBJKHn8TEVcCDwGt+163x9t6Hy7L+X31m3NEHAKelvSuHLqAcqe/WuY4/RVYJemk/Dfeirm2eW4z0dzuAC6WND+Ppi7OsfHp9UWSabwYswb4M/A48LVer2cK4/oI5bDxEWBvPtZQzo8OAAeBB4EFOV+UT1A9DvyR8qmMnsfRYeznA9vz+TJgNzAM3AvMzvETc3s49y/r9bo7jHUFMJh5/gWlY2+tcwx8C3gU2AfcAcyuY56BuyjXQV6kHP2t7yS3wOcz/mHg6omswS0mzMwarimnhszM7HW4EJiZNZwLgZlZw7kQmJk1nAuBmVnDuRCYTSNJ57c6pprNFC4EZmYN50Jg9hokfVbSbkl7JW3K+x88L2lj9sgfkLQw566Q9NvsD7+10jv+DEkPSvqDpN9Jeme+/JzKvQU25zdnzXrGhcCsjaT3AJ8BzouIFcDLwJWUxmeDEXEmsJPS/x3gZ8BXIuL9lG97tsY3Az+IiLOAD1O+PQqlQ+z1lHtjLKP00DHrmVnHn2LWOBcAHwD25C/rb6Y0/XoFuCfn3AlskTQXmBcRO3P8duBeSW8BFkfEVoCIeAEgX293RIzk9l5KL/qHux+W2WtzITA7loDbI2LDqwalb7TN67Q/y38qz1/GP4fWYz41ZHasAeAySW+HsfvHnk75eWl1vrwCeDgijgJHJH00x68CdkbEv4ARSZ/K15gt6aRpjcJsnPybiFmbiNgv6evAryS9gdIV8lrKDWHOzX2HKdcRoLQJ/mH+R/8EcHWOXwVsknRjvsanpzEMs3Fz91GzcZL0fETM6fU6zKaaTw2ZmTWcjwjMzBrORwRmZg3nQmBm1nAuBGZmDedCYGbWcC4EZmYN919N1bJHlwJnFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUnp10fz01lP",
    "outputId": "bcdc6721-8188-48ee-f319-5cb0b7a0003e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /content/drive/My Drive/Save_model/Emotion_Voice_Detection_Model.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "save_dir = '/content/drive/My Drive/Save_model'\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "i3EbPsZn2Eh3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoJv3LLV1S6x",
    "outputId": "717e593c-2af1-49c9-c857-ee148a2145dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 40, 128)           768       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 40, 128)           0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 128)            82048     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 1, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1, 128)            82048     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1, 128)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 1032      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,896\n",
      "Trainable params: 165,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "loaded_model = keras.models.load_model('/content/drive/My Drive/Save_model/Emotion_Voice_Detection_Model.h5')\n",
    "loaded_model.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SpeechHelper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
